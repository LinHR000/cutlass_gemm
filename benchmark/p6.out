Namespace(m=1024, n=12288, k=4608, num_iters=10)
==========M=1==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06268024444580078
TIME INT8 * INT8 -> FP16 (per token): 0.07176399230957031
TIME INT8 * INT8 -> FP16 (per channel) 0.06551742553710938
TIME INT8 * INT8 -> FP16 (per token per channel): 0.06573200225830078
TIME INT8 * FP16 -> Fp16 (WO bias): 0.06585121154785156
TIME INT8 * FP16 -> Fp16 (WI bias): 0.06580352783203125
TIME Linear: 0.11894702911376953
Speed Up INT8 * INT8 -> FP16 (per tensor):47.3%
Speed Up INT8 * INT8 -> FP16 (per token):39.67%
Speed Up INT8 * INT8 -> FP16 (per channel):44.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):44.74%
Speed Up INT8 * FP16 -> Fp16 (WO bias):44.64%
Speed Up INT8 * FP16 -> Fp16 (WI bias):44.68%
==========M=32==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06413459777832031
TIME INT8 * INT8 -> FP16 (per token): 0.072479248046875
TIME INT8 * INT8 -> FP16 (per channel) 0.06957054138183594
TIME INT8 * INT8 -> FP16 (per token per channel): 0.06945133209228516
TIME INT8 * FP16 -> Fp16 (WO bias): 0.0715494155883789
TIME INT8 * FP16 -> Fp16 (WI bias): 0.07166862487792969
TIME Linear: 0.17790794372558594
Speed Up INT8 * INT8 -> FP16 (per tensor):63.95%
Speed Up INT8 * INT8 -> FP16 (per token):59.26%
Speed Up INT8 * INT8 -> FP16 (per channel):60.9%
Speed Up INT8 * INT8 -> FP16 (per token per channel):60.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):59.78%
Speed Up INT8 * FP16 -> Fp16 (WI bias):59.72%
==========M=63==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06711483001708984
TIME INT8 * INT8 -> FP16 (per token): 0.08013248443603516
TIME INT8 * INT8 -> FP16 (per channel) 0.07932186126708984
TIME INT8 * INT8 -> FP16 (per token per channel): 0.08130073547363281
TIME INT8 * FP16 -> Fp16 (WO bias): 0.07605552673339844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.07481575012207031
TIME Linear: 0.1219034194946289
Speed Up INT8 * INT8 -> FP16 (per tensor):44.94%
Speed Up INT8 * INT8 -> FP16 (per token):34.27%
Speed Up INT8 * INT8 -> FP16 (per channel):34.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):33.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):37.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):38.63%
==========M=94==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.09059906005859375
TIME INT8 * INT8 -> FP16 (per token): 0.09775161743164062
TIME INT8 * INT8 -> FP16 (per channel) 0.09486675262451172
TIME INT8 * INT8 -> FP16 (per token per channel): 0.09529590606689453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.10259151458740234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1024484634399414
TIME Linear: 0.12950897216796875
Speed Up INT8 * INT8 -> FP16 (per tensor):30.04%
Speed Up INT8 * INT8 -> FP16 (per token):24.52%
Speed Up INT8 * INT8 -> FP16 (per channel):26.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):26.42%
Speed Up INT8 * FP16 -> Fp16 (WO bias):20.78%
Speed Up INT8 * FP16 -> Fp16 (WI bias):20.89%
==========M=125==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.0898122787475586
TIME INT8 * INT8 -> FP16 (per token): 0.11355876922607422
TIME INT8 * INT8 -> FP16 (per channel) 0.11134147644042969
TIME INT8 * INT8 -> FP16 (per token per channel): 0.11289119720458984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.10638236999511719
TIME INT8 * FP16 -> Fp16 (WI bias): 0.10747909545898438
TIME Linear: 0.13709068298339844
Speed Up INT8 * INT8 -> FP16 (per tensor):34.49%
Speed Up INT8 * INT8 -> FP16 (per token):17.17%
Speed Up INT8 * INT8 -> FP16 (per channel):18.78%
Speed Up INT8 * INT8 -> FP16 (per token per channel):17.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):22.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):21.6%
==========M=156==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12054443359375
TIME INT8 * INT8 -> FP16 (per token): 0.13098716735839844
TIME INT8 * INT8 -> FP16 (per channel) 0.12886524200439453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.12969970703125
TIME INT8 * FP16 -> Fp16 (WO bias): 0.15082359313964844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.14798641204833984
TIME Linear: 0.1825571060180664
Speed Up INT8 * INT8 -> FP16 (per tensor):33.97%
Speed Up INT8 * INT8 -> FP16 (per token):28.25%
Speed Up INT8 * INT8 -> FP16 (per channel):29.41%
Speed Up INT8 * INT8 -> FP16 (per token per channel):28.95%
Speed Up INT8 * FP16 -> Fp16 (WO bias):17.38%
Speed Up INT8 * FP16 -> Fp16 (WI bias):18.94%
==========M=187==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12161731719970703
TIME INT8 * INT8 -> FP16 (per token): 0.14553070068359375
TIME INT8 * INT8 -> FP16 (per channel) 0.14405250549316406
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1458883285522461
TIME INT8 * FP16 -> Fp16 (WO bias): 0.15490055084228516
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1489400863647461
TIME Linear: 0.18436908721923828
Speed Up INT8 * INT8 -> FP16 (per tensor):34.04%
Speed Up INT8 * INT8 -> FP16 (per token):21.07%
Speed Up INT8 * INT8 -> FP16 (per channel):21.87%
Speed Up INT8 * INT8 -> FP16 (per token per channel):20.87%
Speed Up INT8 * FP16 -> Fp16 (WO bias):15.98%
Speed Up INT8 * FP16 -> Fp16 (WI bias):19.22%
==========M=218==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12595653533935547
TIME INT8 * INT8 -> FP16 (per token): 0.16052722930908203
TIME INT8 * INT8 -> FP16 (per channel) 0.1592874526977539
TIME INT8 * INT8 -> FP16 (per token per channel): 0.16031265258789062
TIME INT8 * FP16 -> Fp16 (WO bias): 0.1791238784790039
TIME INT8 * FP16 -> Fp16 (WI bias): 0.17979145050048828
TIME Linear: 0.19028186798095703
Speed Up INT8 * INT8 -> FP16 (per tensor):33.81%
Speed Up INT8 * INT8 -> FP16 (per token):15.64%
Speed Up INT8 * INT8 -> FP16 (per channel):16.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):15.75%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.86%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.51%
==========M=249==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1553058624267578
TIME INT8 * INT8 -> FP16 (per token): 0.1777172088623047
TIME INT8 * INT8 -> FP16 (per channel) 0.17616748809814453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.17616748809814453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.18105506896972656
TIME INT8 * FP16 -> Fp16 (WI bias): 0.18210411071777344
TIME Linear: 0.1840829849243164
Speed Up INT8 * INT8 -> FP16 (per tensor):15.63%
Speed Up INT8 * INT8 -> FP16 (per token):3.46%
Speed Up INT8 * INT8 -> FP16 (per channel):4.3%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):1.64%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.07%
==========M=280==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18885135650634766
TIME INT8 * INT8 -> FP16 (per token): 0.19123554229736328
TIME INT8 * INT8 -> FP16 (per channel) 0.18792152404785156
TIME INT8 * INT8 -> FP16 (per token per channel): 0.18999576568603516
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3229856491088867
TIME INT8 * FP16 -> Fp16 (WI bias): 0.31914710998535156
TIME Linear: 0.2717256546020508
Speed Up INT8 * INT8 -> FP16 (per tensor):30.5%
Speed Up INT8 * INT8 -> FP16 (per token):29.62%
Speed Up INT8 * INT8 -> FP16 (per channel):30.84%
Speed Up INT8 * INT8 -> FP16 (per token per channel):30.08%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.86%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-17.45%
==========M=311==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1878499984741211
TIME INT8 * INT8 -> FP16 (per token): 0.20415782928466797
TIME INT8 * INT8 -> FP16 (per channel) 0.20153522491455078
TIME INT8 * INT8 -> FP16 (per token per channel): 0.20322799682617188
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3275632858276367
TIME INT8 * FP16 -> Fp16 (WI bias): 0.32296180725097656
TIME Linear: 0.2717733383178711
Speed Up INT8 * INT8 -> FP16 (per tensor):30.88%
Speed Up INT8 * INT8 -> FP16 (per token):24.88%
Speed Up INT8 * INT8 -> FP16 (per channel):25.84%
Speed Up INT8 * INT8 -> FP16 (per token per channel):25.22%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.83%
==========M=342==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2187490463256836
TIME INT8 * INT8 -> FP16 (per token): 0.22242069244384766
TIME INT8 * INT8 -> FP16 (per channel) 0.22110939025878906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.22175312042236328
TIME INT8 * FP16 -> Fp16 (WO bias): 0.32749176025390625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.33016204833984375
TIME Linear: 0.27358531951904297
Speed Up INT8 * INT8 -> FP16 (per tensor):20.04%
Speed Up INT8 * INT8 -> FP16 (per token):18.7%
Speed Up INT8 * INT8 -> FP16 (per channel):19.18%
Speed Up INT8 * INT8 -> FP16 (per token per channel):18.95%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.7%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.68%
==========M=373==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.21991729736328125
TIME INT8 * INT8 -> FP16 (per token): 0.2469778060913086
TIME INT8 * INT8 -> FP16 (per channel) 0.24411678314208984
TIME INT8 * INT8 -> FP16 (per token per channel): 0.24445056915283203
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3332853317260742
TIME INT8 * FP16 -> Fp16 (WI bias): 0.32837390899658203
TIME Linear: 0.27313232421875
Speed Up INT8 * INT8 -> FP16 (per tensor):19.48%
Speed Up INT8 * INT8 -> FP16 (per token):9.58%
Speed Up INT8 * INT8 -> FP16 (per channel):10.62%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.5%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.02%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.23%
==========M=404==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.19214153289794922
TIME INT8 * INT8 -> FP16 (per token): 0.26307106018066406
TIME INT8 * INT8 -> FP16 (per channel) 0.26175975799560547
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2622842788696289
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3142356872558594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.313568115234375
TIME Linear: 0.3538846969604492
Speed Up INT8 * INT8 -> FP16 (per tensor):45.71%
Speed Up INT8 * INT8 -> FP16 (per token):25.66%
Speed Up INT8 * INT8 -> FP16 (per channel):26.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):25.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):11.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):11.39%
==========M=435==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2076864242553711
TIME INT8 * INT8 -> FP16 (per token): 0.2876758575439453
TIME INT8 * INT8 -> FP16 (per channel) 0.27675628662109375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.27234554290771484
TIME INT8 * FP16 -> Fp16 (WO bias): 0.41196346282958984
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4046440124511719
TIME Linear: 0.3512144088745117
Speed Up INT8 * INT8 -> FP16 (per tensor):40.87%
Speed Up INT8 * INT8 -> FP16 (per token):18.09%
Speed Up INT8 * INT8 -> FP16 (per channel):21.2%
Speed Up INT8 * INT8 -> FP16 (per token per channel):22.46%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-17.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.21%
==========M=466==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.22518634796142578
TIME INT8 * INT8 -> FP16 (per token): 0.2891063690185547
TIME INT8 * INT8 -> FP16 (per channel) 0.2887248992919922
TIME INT8 * INT8 -> FP16 (per token per channel): 0.28836727142333984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3755331039428711
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5135297775268555
TIME Linear: 0.3569602966308594
Speed Up INT8 * INT8 -> FP16 (per tensor):36.92%
Speed Up INT8 * INT8 -> FP16 (per token):19.01%
Speed Up INT8 * INT8 -> FP16 (per channel):19.12%
Speed Up INT8 * INT8 -> FP16 (per token per channel):19.22%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-43.86%
==========M=497==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2276897430419922
TIME INT8 * INT8 -> FP16 (per token): 0.3111839294433594
TIME INT8 * INT8 -> FP16 (per channel) 0.31151771545410156
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3053426742553711
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4321575164794922
TIME INT8 * FP16 -> Fp16 (WI bias): 0.42438507080078125
TIME Linear: 0.3595590591430664
Speed Up INT8 * INT8 -> FP16 (per tensor):36.68%
Speed Up INT8 * INT8 -> FP16 (per token):13.45%
Speed Up INT8 * INT8 -> FP16 (per channel):13.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):15.08%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.19%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.03%
==========M=528==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.23233890533447266
TIME INT8 * INT8 -> FP16 (per token): 0.32546520233154297
TIME INT8 * INT8 -> FP16 (per channel) 0.32405853271484375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3268241882324219
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3375530242919922
TIME INT8 * FP16 -> Fp16 (WI bias): 0.34508705139160156
TIME Linear: 0.3943204879760742
Speed Up INT8 * INT8 -> FP16 (per tensor):41.08%
Speed Up INT8 * INT8 -> FP16 (per token):17.46%
Speed Up INT8 * INT8 -> FP16 (per channel):17.82%
Speed Up INT8 * INT8 -> FP16 (per token per channel):17.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):14.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):12.49%
==========M=559==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.23472309112548828
TIME INT8 * INT8 -> FP16 (per token): 0.34470558166503906
TIME INT8 * INT8 -> FP16 (per channel) 0.34470558166503906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.34363269805908203
TIME INT8 * FP16 -> Fp16 (WO bias): 0.33757686614990234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.34525394439697266
TIME Linear: 0.3942251205444336
Speed Up INT8 * INT8 -> FP16 (per tensor):40.46%
Speed Up INT8 * INT8 -> FP16 (per token):12.56%
Speed Up INT8 * INT8 -> FP16 (per channel):12.56%
Speed Up INT8 * INT8 -> FP16 (per token per channel):12.83%
Speed Up INT8 * FP16 -> Fp16 (WO bias):14.37%
Speed Up INT8 * FP16 -> Fp16 (WI bias):12.42%
==========M=590==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27277469635009766
TIME INT8 * INT8 -> FP16 (per token): 0.35164356231689453
TIME INT8 * INT8 -> FP16 (per channel) 0.3492593765258789
TIME INT8 * INT8 -> FP16 (per token per channel): 0.35114288330078125
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3729820251464844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3736734390258789
TIME Linear: 0.39703845977783203
Speed Up INT8 * INT8 -> FP16 (per tensor):31.3%
Speed Up INT8 * INT8 -> FP16 (per token):11.43%
Speed Up INT8 * INT8 -> FP16 (per channel):12.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):6.06%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.88%
==========M=621==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2651214599609375
TIME INT8 * INT8 -> FP16 (per token): 0.3696441650390625
TIME INT8 * INT8 -> FP16 (per channel) 0.36695003509521484
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3679990768432617
TIME INT8 * FP16 -> Fp16 (WO bias): 0.37534236907958984
TIME INT8 * FP16 -> Fp16 (WI bias): 0.37415027618408203
TIME Linear: 0.3952503204345703
Speed Up INT8 * INT8 -> FP16 (per tensor):32.92%
Speed Up INT8 * INT8 -> FP16 (per token):6.48%
Speed Up INT8 * INT8 -> FP16 (per channel):7.16%
Speed Up INT8 * INT8 -> FP16 (per token per channel):6.89%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.04%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.34%
==========M=652==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2810239791870117
TIME INT8 * INT8 -> FP16 (per token): 0.3837108612060547
TIME INT8 * INT8 -> FP16 (per channel) 0.3828763961791992
TIME INT8 * INT8 -> FP16 (per token per channel): 0.38187503814697266
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6358623504638672
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6320476531982422
TIME Linear: 0.46770572662353516
Speed Up INT8 * INT8 -> FP16 (per tensor):39.91%
Speed Up INT8 * INT8 -> FP16 (per token):17.96%
Speed Up INT8 * INT8 -> FP16 (per channel):18.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):18.35%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-35.95%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-35.14%
==========M=683==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.28340816497802734
TIME INT8 * INT8 -> FP16 (per token): 0.397491455078125
TIME INT8 * INT8 -> FP16 (per channel) 0.39780139923095703
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3967761993408203
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6376028060913086
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6345510482788086
TIME Linear: 0.46448707580566406
Speed Up INT8 * INT8 -> FP16 (per tensor):38.98%
Speed Up INT8 * INT8 -> FP16 (per token):14.42%
Speed Up INT8 * INT8 -> FP16 (per channel):14.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):14.58%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-36.61%
==========M=714==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.30579566955566406
TIME INT8 * INT8 -> FP16 (per token): 0.4298686981201172
TIME INT8 * INT8 -> FP16 (per channel) 0.42877197265625
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4285097122192383
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6397247314453125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6360054016113281
TIME Linear: 0.46672821044921875
Speed Up INT8 * INT8 -> FP16 (per tensor):34.48%
Speed Up INT8 * INT8 -> FP16 (per token):7.9%
Speed Up INT8 * INT8 -> FP16 (per channel):8.13%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.19%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.07%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-36.27%
==========M=745==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.31440258026123047
TIME INT8 * INT8 -> FP16 (per token): 0.4478931427001953
TIME INT8 * INT8 -> FP16 (per channel) 0.44384002685546875
TIME INT8 * INT8 -> FP16 (per token per channel): 0.44345855712890625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6435155868530273
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6423234939575195
TIME Linear: 0.45630931854248047
Speed Up INT8 * INT8 -> FP16 (per tensor):31.1%
Speed Up INT8 * INT8 -> FP16 (per token):1.84%
Speed Up INT8 * INT8 -> FP16 (per channel):2.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.82%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-41.03%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-40.76%
==========M=776==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3340005874633789
TIME INT8 * INT8 -> FP16 (per token): 0.46133995056152344
TIME INT8 * INT8 -> FP16 (per channel) 0.4599571228027344
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4606962203979492
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8201360702514648
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8200645446777344
TIME Linear: 0.5266189575195312
Speed Up INT8 * INT8 -> FP16 (per tensor):36.58%
Speed Up INT8 * INT8 -> FP16 (per token):12.4%
Speed Up INT8 * INT8 -> FP16 (per channel):12.66%
Speed Up INT8 * INT8 -> FP16 (per token per channel):12.52%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-55.74%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-55.72%
==========M=807==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3312110900878906
TIME INT8 * INT8 -> FP16 (per token): 0.4799842834472656
TIME INT8 * INT8 -> FP16 (per channel) 0.47631263732910156
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4773855209350586
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8266687393188477
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8194446563720703
TIME Linear: 0.5269765853881836
Speed Up INT8 * INT8 -> FP16 (per tensor):37.15%
Speed Up INT8 * INT8 -> FP16 (per token):8.92%
Speed Up INT8 * INT8 -> FP16 (per channel):9.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.41%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-56.87%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-55.5%
==========M=838==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3337860107421875
TIME INT8 * INT8 -> FP16 (per token): 0.49712657928466797
TIME INT8 * INT8 -> FP16 (per channel) 0.49445629119873047
TIME INT8 * INT8 -> FP16 (per token per channel): 0.49436092376708984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6078243255615234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6070613861083984
TIME Linear: 0.5259037017822266
Speed Up INT8 * INT8 -> FP16 (per tensor):36.53%
Speed Up INT8 * INT8 -> FP16 (per token):5.47%
Speed Up INT8 * INT8 -> FP16 (per channel):5.98%
Speed Up INT8 * INT8 -> FP16 (per token per channel):6.0%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.58%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.43%
==========M=869==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.34332275390625
TIME INT8 * INT8 -> FP16 (per token): 0.5002975463867188
TIME INT8 * INT8 -> FP16 (per channel) 0.4984140396118164
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4997730255126953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.840449333190918
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8347988128662109
TIME Linear: 0.5249261856079102
Speed Up INT8 * INT8 -> FP16 (per tensor):34.6%
Speed Up INT8 * INT8 -> FP16 (per token):4.69%
Speed Up INT8 * INT8 -> FP16 (per channel):5.05%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-60.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-59.03%
==========M=900==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.35636425018310547
TIME INT8 * INT8 -> FP16 (per token): 0.5281686782836914
TIME INT8 * INT8 -> FP16 (per channel) 0.527501106262207
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5269527435302734
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6196022033691406
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6255865097045898
TIME Linear: 0.5957365036010742
Speed Up INT8 * INT8 -> FP16 (per tensor):40.18%
Speed Up INT8 * INT8 -> FP16 (per token):11.34%
Speed Up INT8 * INT8 -> FP16 (per channel):11.45%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.55%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.01%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.01%
==========M=931==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3586292266845703
TIME INT8 * INT8 -> FP16 (per token): 0.5467653274536133
TIME INT8 * INT8 -> FP16 (per channel) 0.5480051040649414
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5443811416625977
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6120920181274414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6141185760498047
TIME Linear: 0.5954742431640625
Speed Up INT8 * INT8 -> FP16 (per tensor):39.77%
Speed Up INT8 * INT8 -> FP16 (per token):8.18%
Speed Up INT8 * INT8 -> FP16 (per channel):7.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.58%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.13%
==========M=962==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.38318634033203125
TIME INT8 * INT8 -> FP16 (per token): 0.564885139465332
TIME INT8 * INT8 -> FP16 (per channel) 0.561976432800293
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5620718002319336
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6333351135253906
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6345987319946289
TIME Linear: 0.594639778137207
Speed Up INT8 * INT8 -> FP16 (per tensor):35.56%
Speed Up INT8 * INT8 -> FP16 (per token):5.0%
Speed Up INT8 * INT8 -> FP16 (per channel):5.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.51%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.72%
==========M=993==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.380706787109375
TIME INT8 * INT8 -> FP16 (per token): 0.5814313888549805
TIME INT8 * INT8 -> FP16 (per channel) 0.5793571472167969
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5782127380371094
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6334781646728516
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6301164627075195
TIME Linear: 0.6102800369262695
Speed Up INT8 * INT8 -> FP16 (per tensor):37.62%
Speed Up INT8 * INT8 -> FP16 (per token):4.73%
Speed Up INT8 * INT8 -> FP16 (per channel):5.07%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.8%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.25%
Namespace(m=4096, n=12288, k=4608, num_iters=10)
==========M=1==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06053447723388672
TIME INT8 * INT8 -> FP16 (per token): 0.07288455963134766
TIME INT8 * INT8 -> FP16 (per channel) 0.06561279296875
TIME INT8 * INT8 -> FP16 (per token per channel): 0.06482601165771484
TIME INT8 * FP16 -> Fp16 (WO bias): 0.06487369537353516
TIME INT8 * FP16 -> Fp16 (WI bias): 0.06597042083740234
TIME Linear: 0.1192331314086914
Speed Up INT8 * INT8 -> FP16 (per tensor):49.23%
Speed Up INT8 * INT8 -> FP16 (per token):38.87%
Speed Up INT8 * INT8 -> FP16 (per channel):44.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):45.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):45.59%
Speed Up INT8 * FP16 -> Fp16 (WI bias):44.67%
==========M=32==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06470680236816406
TIME INT8 * INT8 -> FP16 (per token): 0.0698089599609375
TIME INT8 * INT8 -> FP16 (per channel) 0.06847381591796875
TIME INT8 * INT8 -> FP16 (per token per channel): 0.06821155548095703
TIME INT8 * FP16 -> Fp16 (WO bias): 0.07090568542480469
TIME INT8 * FP16 -> Fp16 (WI bias): 0.07145404815673828
TIME Linear: 0.15060901641845703
Speed Up INT8 * INT8 -> FP16 (per tensor):57.04%
Speed Up INT8 * INT8 -> FP16 (per token):53.65%
Speed Up INT8 * INT8 -> FP16 (per channel):54.54%
Speed Up INT8 * INT8 -> FP16 (per token per channel):54.71%
Speed Up INT8 * FP16 -> Fp16 (WO bias):52.92%
Speed Up INT8 * FP16 -> Fp16 (WI bias):52.56%
==========M=63==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06518363952636719
TIME INT8 * INT8 -> FP16 (per token): 0.0787496566772461
TIME INT8 * INT8 -> FP16 (per channel) 0.07984638214111328
TIME INT8 * INT8 -> FP16 (per token per channel): 0.07872581481933594
TIME INT8 * FP16 -> Fp16 (WO bias): 0.07419586181640625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.07452964782714844
TIME Linear: 0.1140594482421875
Speed Up INT8 * INT8 -> FP16 (per tensor):42.85%
Speed Up INT8 * INT8 -> FP16 (per token):30.96%
Speed Up INT8 * INT8 -> FP16 (per channel):30.0%
Speed Up INT8 * INT8 -> FP16 (per token per channel):30.98%
Speed Up INT8 * FP16 -> Fp16 (WO bias):34.95%
Speed Up INT8 * FP16 -> Fp16 (WI bias):34.66%
==========M=94==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.08845329284667969
TIME INT8 * INT8 -> FP16 (per token): 0.09517669677734375
TIME INT8 * INT8 -> FP16 (per channel) 0.09377002716064453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.09489059448242188
TIME INT8 * FP16 -> Fp16 (WO bias): 0.1020669937133789
TIME INT8 * FP16 -> Fp16 (WI bias): 0.10418891906738281
TIME Linear: 0.13074874877929688
Speed Up INT8 * INT8 -> FP16 (per tensor):32.35%
Speed Up INT8 * INT8 -> FP16 (per token):27.21%
Speed Up INT8 * INT8 -> FP16 (per channel):28.28%
Speed Up INT8 * INT8 -> FP16 (per token per channel):27.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):21.94%
Speed Up INT8 * FP16 -> Fp16 (WI bias):20.31%
==========M=125==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.08771419525146484
TIME INT8 * INT8 -> FP16 (per token): 0.11301040649414062
TIME INT8 * INT8 -> FP16 (per channel) 0.11057853698730469
TIME INT8 * INT8 -> FP16 (per token per channel): 0.11148452758789062
TIME INT8 * FP16 -> Fp16 (WO bias): 0.10671615600585938
TIME INT8 * FP16 -> Fp16 (WI bias): 0.10781288146972656
TIME Linear: 0.1400470733642578
Speed Up INT8 * INT8 -> FP16 (per tensor):37.37%
Speed Up INT8 * INT8 -> FP16 (per token):19.31%
Speed Up INT8 * INT8 -> FP16 (per channel):21.04%
Speed Up INT8 * INT8 -> FP16 (per token per channel):20.39%
Speed Up INT8 * FP16 -> Fp16 (WO bias):23.8%
Speed Up INT8 * FP16 -> Fp16 (WI bias):23.02%
==========M=156==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1199960708618164
TIME INT8 * INT8 -> FP16 (per token): 0.130462646484375
TIME INT8 * INT8 -> FP16 (per channel) 0.1283884048461914
TIME INT8 * INT8 -> FP16 (per token per channel): 0.12996196746826172
TIME INT8 * FP16 -> Fp16 (WO bias): 0.1516103744506836
TIME INT8 * FP16 -> Fp16 (WI bias): 0.14743804931640625
TIME Linear: 0.18093585968017578
Speed Up INT8 * INT8 -> FP16 (per tensor):33.68%
Speed Up INT8 * INT8 -> FP16 (per token):27.9%
Speed Up INT8 * INT8 -> FP16 (per channel):29.04%
Speed Up INT8 * INT8 -> FP16 (per token per channel):28.17%
Speed Up INT8 * FP16 -> Fp16 (WO bias):16.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):18.51%
==========M=187==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12116432189941406
TIME INT8 * INT8 -> FP16 (per token): 0.14417171478271484
TIME INT8 * INT8 -> FP16 (per channel) 0.14302730560302734
TIME INT8 * INT8 -> FP16 (per token per channel): 0.14481544494628906
TIME INT8 * FP16 -> Fp16 (WO bias): 0.15337467193603516
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1489400863647461
TIME Linear: 0.18138885498046875
Speed Up INT8 * INT8 -> FP16 (per tensor):33.2%
Speed Up INT8 * INT8 -> FP16 (per token):20.52%
Speed Up INT8 * INT8 -> FP16 (per channel):21.15%
Speed Up INT8 * INT8 -> FP16 (per token per channel):20.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):15.44%
Speed Up INT8 * FP16 -> Fp16 (WI bias):17.89%
==========M=218==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12395381927490234
TIME INT8 * INT8 -> FP16 (per token): 0.15957355499267578
TIME INT8 * INT8 -> FP16 (per channel) 0.15828609466552734
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1584768295288086
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17926692962646484
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1796722412109375
TIME Linear: 0.18339157104492188
Speed Up INT8 * INT8 -> FP16 (per tensor):32.41%
Speed Up INT8 * INT8 -> FP16 (per token):12.99%
Speed Up INT8 * INT8 -> FP16 (per channel):13.69%
Speed Up INT8 * INT8 -> FP16 (per token per channel):13.59%
Speed Up INT8 * FP16 -> Fp16 (WO bias):2.25%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.03%
==========M=249==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1541614532470703
TIME INT8 * INT8 -> FP16 (per token): 0.17611980438232422
TIME INT8 * INT8 -> FP16 (per channel) 0.17349720001220703
TIME INT8 * INT8 -> FP16 (per token per channel): 0.17426013946533203
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17893314361572266
TIME INT8 * FP16 -> Fp16 (WI bias): 0.18248558044433594
TIME Linear: 0.1820087432861328
Speed Up INT8 * INT8 -> FP16 (per tensor):15.3%
Speed Up INT8 * INT8 -> FP16 (per token):3.24%
Speed Up INT8 * INT8 -> FP16 (per channel):4.68%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.26%
Speed Up INT8 * FP16 -> Fp16 (WO bias):1.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.26%
==========M=280==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18587112426757812
TIME INT8 * INT8 -> FP16 (per token): 0.18856525421142578
TIME INT8 * INT8 -> FP16 (per channel) 0.1870870590209961
TIME INT8 * INT8 -> FP16 (per token per channel): 0.18880367279052734
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3211021423339844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.31888484954833984
TIME Linear: 0.2693653106689453
Speed Up INT8 * INT8 -> FP16 (per tensor):31.0%
Speed Up INT8 * INT8 -> FP16 (per token):30.0%
Speed Up INT8 * INT8 -> FP16 (per channel):30.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):29.91%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.38%
==========M=311==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1869678497314453
TIME INT8 * INT8 -> FP16 (per token): 0.20232200622558594
TIME INT8 * INT8 -> FP16 (per channel) 0.2002716064453125
TIME INT8 * INT8 -> FP16 (per token per channel): 0.20227432250976562
TIME INT8 * FP16 -> Fp16 (WO bias): 0.32813549041748047
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3222227096557617
TIME Linear: 0.27549266815185547
Speed Up INT8 * INT8 -> FP16 (per tensor):32.13%
Speed Up INT8 * INT8 -> FP16 (per token):26.56%
Speed Up INT8 * INT8 -> FP16 (per channel):27.3%
Speed Up INT8 * INT8 -> FP16 (per token per channel):26.58%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-16.96%
==========M=342==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.21905899047851562
TIME INT8 * INT8 -> FP16 (per token): 0.2219676971435547
TIME INT8 * INT8 -> FP16 (per channel) 0.22039413452148438
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2215862274169922
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3274679183959961
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3241539001464844
TIME Linear: 0.2704143524169922
Speed Up INT8 * INT8 -> FP16 (per tensor):18.99%
Speed Up INT8 * INT8 -> FP16 (per token):17.92%
Speed Up INT8 * INT8 -> FP16 (per channel):18.5%
Speed Up INT8 * INT8 -> FP16 (per token per channel):18.06%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.1%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-19.87%
==========M=373==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.21877288818359375
TIME INT8 * INT8 -> FP16 (per token): 0.2445220947265625
TIME INT8 * INT8 -> FP16 (per channel) 0.2443075180053711
TIME INT8 * INT8 -> FP16 (per token per channel): 0.24521350860595703
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3311634063720703
TIME INT8 * FP16 -> Fp16 (WI bias): 0.32806396484375
TIME Linear: 0.27136802673339844
Speed Up INT8 * INT8 -> FP16 (per tensor):19.38%
Speed Up INT8 * INT8 -> FP16 (per token):9.89%
Speed Up INT8 * INT8 -> FP16 (per channel):9.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.64%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.03%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.89%
==========M=404==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1901865005493164
TIME INT8 * INT8 -> FP16 (per token): 0.2611398696899414
TIME INT8 * INT8 -> FP16 (per channel) 0.2598762512207031
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2608776092529297
TIME INT8 * FP16 -> Fp16 (WO bias): 0.312042236328125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.31280517578125
TIME Linear: 0.3489971160888672
Speed Up INT8 * INT8 -> FP16 (per tensor):45.5%
Speed Up INT8 * INT8 -> FP16 (per token):25.17%
Speed Up INT8 * INT8 -> FP16 (per channel):25.54%
Speed Up INT8 * INT8 -> FP16 (per token per channel):25.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):10.59%
Speed Up INT8 * FP16 -> Fp16 (WI bias):10.37%
==========M=435==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20687580108642578
TIME INT8 * INT8 -> FP16 (per token): 0.27158260345458984
TIME INT8 * INT8 -> FP16 (per channel) 0.27153491973876953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2717256546020508
TIME INT8 * FP16 -> Fp16 (WO bias): 0.41136741638183594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.40488243103027344
TIME Linear: 0.3525733947753906
Speed Up INT8 * INT8 -> FP16 (per tensor):41.32%
Speed Up INT8 * INT8 -> FP16 (per token):22.97%
Speed Up INT8 * INT8 -> FP16 (per channel):22.98%
Speed Up INT8 * INT8 -> FP16 (per token per channel):22.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.68%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.84%
==========M=466==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.22296905517578125
TIME INT8 * INT8 -> FP16 (per token): 0.28793811798095703
TIME INT8 * INT8 -> FP16 (per channel) 0.2882242202758789
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2869606018066406
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3744363784790039
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3726005554199219
TIME Linear: 0.3518342971801758
Speed Up INT8 * INT8 -> FP16 (per tensor):36.63%
Speed Up INT8 * INT8 -> FP16 (per token):18.16%
Speed Up INT8 * INT8 -> FP16 (per channel):18.08%
Speed Up INT8 * INT8 -> FP16 (per token per channel):18.44%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.9%
==========M=497==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.22466182708740234
TIME INT8 * INT8 -> FP16 (per token): 0.3068685531616211
TIME INT8 * INT8 -> FP16 (per channel) 0.3072500228881836
TIME INT8 * INT8 -> FP16 (per token per channel): 0.30548572540283203
TIME INT8 * FP16 -> Fp16 (WO bias): 0.42777061462402344
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4225492477416992
TIME Linear: 0.3531932830810547
Speed Up INT8 * INT8 -> FP16 (per tensor):36.39%
Speed Up INT8 * INT8 -> FP16 (per token):13.12%
Speed Up INT8 * INT8 -> FP16 (per channel):13.01%
Speed Up INT8 * INT8 -> FP16 (per token per channel):13.51%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.12%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-19.64%
==========M=528==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.23097991943359375
TIME INT8 * INT8 -> FP16 (per token): 0.32494068145751953
TIME INT8 * INT8 -> FP16 (per channel) 0.32355785369873047
TIME INT8 * INT8 -> FP16 (per token per channel): 0.32389163970947266
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3360748291015625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3446340560913086
TIME Linear: 0.39861202239990234
Speed Up INT8 * INT8 -> FP16 (per tensor):42.05%
Speed Up INT8 * INT8 -> FP16 (per token):18.48%
Speed Up INT8 * INT8 -> FP16 (per channel):18.83%
Speed Up INT8 * INT8 -> FP16 (per token per channel):18.75%
Speed Up INT8 * FP16 -> Fp16 (WO bias):15.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.54%
==========M=559==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2345561981201172
TIME INT8 * INT8 -> FP16 (per token): 0.3444194793701172
TIME INT8 * INT8 -> FP16 (per channel) 0.3442049026489258
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3474712371826172
TIME INT8 * FP16 -> Fp16 (WO bias): 0.33681392669677734
TIME INT8 * FP16 -> Fp16 (WI bias): 0.34487247467041016
TIME Linear: 0.3940105438232422
Speed Up INT8 * INT8 -> FP16 (per tensor):40.47%
Speed Up INT8 * INT8 -> FP16 (per token):12.59%
Speed Up INT8 * INT8 -> FP16 (per channel):12.64%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):14.52%
Speed Up INT8 * FP16 -> Fp16 (WI bias):12.47%
==========M=590==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2722740173339844
TIME INT8 * INT8 -> FP16 (per token): 0.35037994384765625
TIME INT8 * INT8 -> FP16 (per channel) 0.3493785858154297
TIME INT8 * INT8 -> FP16 (per token per channel): 0.34999847412109375
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3729581832885742
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3743410110473633
TIME Linear: 0.39322376251220703
Speed Up INT8 * INT8 -> FP16 (per tensor):30.76%
Speed Up INT8 * INT8 -> FP16 (per token):10.9%
Speed Up INT8 * INT8 -> FP16 (per channel):11.15%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.99%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.15%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.8%
==========M=621==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2631187438964844
TIME INT8 * INT8 -> FP16 (per token): 0.3681659698486328
TIME INT8 * INT8 -> FP16 (per channel) 0.36520957946777344
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3672361373901367
TIME INT8 * FP16 -> Fp16 (WO bias): 0.37474632263183594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.37314891815185547
TIME Linear: 0.39589405059814453
Speed Up INT8 * INT8 -> FP16 (per tensor):33.54%
Speed Up INT8 * INT8 -> FP16 (per token):7.0%
Speed Up INT8 * INT8 -> FP16 (per channel):7.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.34%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.75%
==========M=652==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27968883514404297
TIME INT8 * INT8 -> FP16 (per token): 0.3833770751953125
TIME INT8 * INT8 -> FP16 (per channel) 0.38139820098876953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.38199424743652344
TIME INT8 * FP16 -> Fp16 (WO bias): 0.635838508605957
TIME INT8 * FP16 -> Fp16 (WI bias): 0.631403923034668
TIME Linear: 0.4626750946044922
Speed Up INT8 * INT8 -> FP16 (per tensor):39.55%
Speed Up INT8 * INT8 -> FP16 (per token):17.14%
Speed Up INT8 * INT8 -> FP16 (per channel):17.57%
Speed Up INT8 * INT8 -> FP16 (per token per channel):17.44%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.43%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-36.47%
==========M=683==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.28438568115234375
TIME INT8 * INT8 -> FP16 (per token): 0.3991365432739258
TIME INT8 * INT8 -> FP16 (per channel) 0.3969430923461914
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3972053527832031
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6374359130859375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6334066390991211
TIME Linear: 0.4658937454223633
Speed Up INT8 * INT8 -> FP16 (per tensor):38.96%
Speed Up INT8 * INT8 -> FP16 (per token):14.33%
Speed Up INT8 * INT8 -> FP16 (per channel):14.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):14.74%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.82%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-35.96%
==========M=714==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.30481815338134766
TIME INT8 * INT8 -> FP16 (per token): 0.4297494888305664
TIME INT8 * INT8 -> FP16 (per channel) 0.4273414611816406
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4269838333129883
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6395339965820312
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6363630294799805
TIME Linear: 0.4640817642211914
Speed Up INT8 * INT8 -> FP16 (per tensor):34.32%
Speed Up INT8 * INT8 -> FP16 (per token):7.4%
Speed Up INT8 * INT8 -> FP16 (per channel):7.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.99%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.81%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-37.12%
==========M=745==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3149986267089844
TIME INT8 * INT8 -> FP16 (per token): 0.44438838958740234
TIME INT8 * INT8 -> FP16 (per channel) 0.44400691986083984
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4433155059814453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6428956985473633
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6393909454345703
TIME Linear: 0.4588127136230469
Speed Up INT8 * INT8 -> FP16 (per tensor):31.34%
Speed Up INT8 * INT8 -> FP16 (per token):3.14%
Speed Up INT8 * INT8 -> FP16 (per channel):3.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):3.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-40.12%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.36%
==========M=776==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.33087730407714844
TIME INT8 * INT8 -> FP16 (per token): 0.46133995056152344
TIME INT8 * INT8 -> FP16 (per channel) 0.4587888717651367
TIME INT8 * INT8 -> FP16 (per token per channel): 0.45986175537109375
TIME INT8 * FP16 -> Fp16 (WO bias): 0.81939697265625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8113861083984375
TIME Linear: 0.5260705947875977
Speed Up INT8 * INT8 -> FP16 (per tensor):37.1%
Speed Up INT8 * INT8 -> FP16 (per token):12.3%
Speed Up INT8 * INT8 -> FP16 (per channel):12.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):12.59%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-55.76%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-54.24%
==========M=807==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.330352783203125
TIME INT8 * INT8 -> FP16 (per token): 0.47905445098876953
TIME INT8 * INT8 -> FP16 (per channel) 0.47752857208251953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4768848419189453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.82550048828125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8180618286132812
TIME Linear: 0.5273580551147461
Speed Up INT8 * INT8 -> FP16 (per tensor):37.36%
Speed Up INT8 * INT8 -> FP16 (per token):9.16%
Speed Up INT8 * INT8 -> FP16 (per channel):9.45%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.57%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-56.54%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-55.12%
==========M=838==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3340005874633789
TIME INT8 * INT8 -> FP16 (per token): 0.4954814910888672
TIME INT8 * INT8 -> FP16 (per channel) 0.4936695098876953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4931211471557617
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6071329116821289
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6073236465454102
TIME Linear: 0.52642822265625
Speed Up INT8 * INT8 -> FP16 (per tensor):36.55%
Speed Up INT8 * INT8 -> FP16 (per token):5.88%
Speed Up INT8 * INT8 -> FP16 (per channel):6.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):6.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.33%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.37%
==========M=869==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.33550262451171875
TIME INT8 * INT8 -> FP16 (per token): 0.49948692321777344
TIME INT8 * INT8 -> FP16 (per channel) 0.4982471466064453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4999876022338867
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8401632308959961
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8337020874023438
TIME Linear: 0.5245447158813477
Speed Up INT8 * INT8 -> FP16 (per tensor):36.04%
Speed Up INT8 * INT8 -> FP16 (per token):4.78%
Speed Up INT8 * INT8 -> FP16 (per channel):5.01%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.68%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-60.17%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-58.94%
==========M=900==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3552675247192383
TIME INT8 * INT8 -> FP16 (per token): 0.5277395248413086
TIME INT8 * INT8 -> FP16 (per channel) 0.5259990692138672
TIME INT8 * INT8 -> FP16 (per token per channel): 0.525212287902832
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6183862686157227
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6143569946289062
TIME Linear: 0.5951404571533203
Speed Up INT8 * INT8 -> FP16 (per tensor):40.31%
Speed Up INT8 * INT8 -> FP16 (per token):11.33%
Speed Up INT8 * INT8 -> FP16 (per channel):11.62%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.75%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.91%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.23%
==========M=931==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3565788269042969
TIME INT8 * INT8 -> FP16 (per token): 0.5445957183837891
TIME INT8 * INT8 -> FP16 (per channel) 0.545048713684082
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5440711975097656
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6200790405273438
TIME INT8 * FP16 -> Fp16 (WI bias): 0.613856315612793
TIME Linear: 0.5954980850219727
Speed Up INT8 * INT8 -> FP16 (per tensor):40.12%
Speed Up INT8 * INT8 -> FP16 (per token):8.55%
Speed Up INT8 * INT8 -> FP16 (per channel):8.47%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.64%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.13%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.08%
==========M=962==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3779411315917969
TIME INT8 * INT8 -> FP16 (per token): 0.5641937255859375
TIME INT8 * INT8 -> FP16 (per channel) 0.5627155303955078
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5622625350952148
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6348848342895508
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6299257278442383
TIME Linear: 0.5985498428344727
Speed Up INT8 * INT8 -> FP16 (per tensor):36.86%
Speed Up INT8 * INT8 -> FP16 (per token):5.74%
Speed Up INT8 * INT8 -> FP16 (per channel):5.99%
Speed Up INT8 * INT8 -> FP16 (per token per channel):6.06%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.07%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.24%
==========M=993==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.37872791290283203
TIME INT8 * INT8 -> FP16 (per token): 0.5792617797851562
TIME INT8 * INT8 -> FP16 (per channel) 0.5789518356323242
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5766153335571289
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6329536437988281
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6299972534179688
TIME Linear: 0.5963563919067383
Speed Up INT8 * INT8 -> FP16 (per tensor):36.49%
Speed Up INT8 * INT8 -> FP16 (per token):2.87%
Speed Up INT8 * INT8 -> FP16 (per channel):2.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):3.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.14%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.64%
==========M=1024==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3823995590209961
TIME INT8 * INT8 -> FP16 (per token): 0.5849599838256836
TIME INT8 * INT8 -> FP16 (per channel) 0.5861282348632812
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5829811096191406
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6345748901367188
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6309032440185547
TIME Linear: 0.5990266799926758
Speed Up INT8 * INT8 -> FP16 (per tensor):36.16%
Speed Up INT8 * INT8 -> FP16 (per token):2.35%
Speed Up INT8 * INT8 -> FP16 (per channel):2.15%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.68%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.32%
==========M=1055==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4008293151855469
TIME INT8 * INT8 -> FP16 (per token): 0.601506233215332
TIME INT8 * INT8 -> FP16 (per channel) 0.600123405456543
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5974054336547852
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6831884384155273
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6886720657348633
TIME Linear: 0.6127595901489258
Speed Up INT8 * INT8 -> FP16 (per tensor):34.59%
Speed Up INT8 * INT8 -> FP16 (per token):1.84%
Speed Up INT8 * INT8 -> FP16 (per channel):2.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.51%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.49%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-12.39%
==========M=1086==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4053354263305664
TIME INT8 * INT8 -> FP16 (per token): 0.615692138671875
TIME INT8 * INT8 -> FP16 (per channel) 0.6151914596557617
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6146669387817383
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6842851638793945
TIME INT8 * FP16 -> Fp16 (WI bias): 0.690460205078125
TIME Linear: 0.6119251251220703
Speed Up INT8 * INT8 -> FP16 (per tensor):33.76%
Speed Up INT8 * INT8 -> FP16 (per token):-0.62%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.53%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.45%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.82%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-12.83%
==========M=1117==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4216909408569336
TIME INT8 * INT8 -> FP16 (per token): 0.6326436996459961
TIME INT8 * INT8 -> FP16 (per channel) 0.6315946578979492
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6297826766967773
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6845712661743164
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6909370422363281
TIME Linear: 0.6113529205322266
Speed Up INT8 * INT8 -> FP16 (per tensor):31.02%
Speed Up INT8 * INT8 -> FP16 (per token):-3.48%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.31%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.98%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.02%
==========M=1148==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4259347915649414
TIME INT8 * INT8 -> FP16 (per token): 0.6512641906738281
TIME INT8 * INT8 -> FP16 (per channel) 0.650477409362793
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6478309631347656
TIME INT8 * FP16 -> Fp16 (WO bias): 0.685882568359375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6909608840942383
TIME Linear: 0.6140708923339844
Speed Up INT8 * INT8 -> FP16 (per tensor):30.64%
Speed Up INT8 * INT8 -> FP16 (per token):-6.06%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.5%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-12.52%
==========M=1179==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4470348358154297
TIME INT8 * INT8 -> FP16 (per token): 0.6572961807250977
TIME INT8 * INT8 -> FP16 (per channel) 0.6583213806152344
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6572961807250977
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7620811462402344
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7719039916992188
TIME Linear: 0.7497310638427734
Speed Up INT8 * INT8 -> FP16 (per tensor):40.37%
Speed Up INT8 * INT8 -> FP16 (per token):12.33%
Speed Up INT8 * INT8 -> FP16 (per channel):12.19%
Speed Up INT8 * INT8 -> FP16 (per token per channel):12.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.96%
==========M=1210==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4511594772338867
TIME INT8 * INT8 -> FP16 (per token): 0.6681203842163086
TIME INT8 * INT8 -> FP16 (per channel) 0.6657838821411133
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6672859191894531
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7628202438354492
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7716894149780273
TIME Linear: 0.7521867752075195
Speed Up INT8 * INT8 -> FP16 (per tensor):40.02%
Speed Up INT8 * INT8 -> FP16 (per token):11.18%
Speed Up INT8 * INT8 -> FP16 (per channel):11.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.29%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.59%
==========M=1241==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46570301055908203
TIME INT8 * INT8 -> FP16 (per token): 0.6850481033325195
TIME INT8 * INT8 -> FP16 (per channel) 0.6830692291259766
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6828546524047852
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7125139236450195
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7152795791625977
TIME Linear: 0.7539510726928711
Speed Up INT8 * INT8 -> FP16 (per tensor):38.23%
Speed Up INT8 * INT8 -> FP16 (per token):9.14%
Speed Up INT8 * INT8 -> FP16 (per channel):9.4%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.5%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.13%
==========M=1272==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.47194957733154297
TIME INT8 * INT8 -> FP16 (per token): 0.715327262878418
TIME INT8 * INT8 -> FP16 (per channel) 0.7166624069213867
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7138729095458984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7134199142456055
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7163286209106445
TIME Linear: 0.7514476776123047
Speed Up INT8 * INT8 -> FP16 (per tensor):37.19%
Speed Up INT8 * INT8 -> FP16 (per token):4.81%
Speed Up INT8 * INT8 -> FP16 (per channel):4.63%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.0%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.06%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.67%
==========M=1303==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4597187042236328
TIME INT8 * INT8 -> FP16 (per token): 0.7204294204711914
TIME INT8 * INT8 -> FP16 (per channel) 0.7192850112915039
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7187128067016602
TIME INT8 * FP16 -> Fp16 (WO bias): 0.83770751953125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8421421051025391
TIME Linear: 0.7572412490844727
Speed Up INT8 * INT8 -> FP16 (per tensor):39.29%
Speed Up INT8 * INT8 -> FP16 (per token):4.86%
Speed Up INT8 * INT8 -> FP16 (per channel):5.01%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.09%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-10.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-11.21%
==========M=1334==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.45981407165527344
TIME INT8 * INT8 -> FP16 (per token): 0.7376670837402344
TIME INT8 * INT8 -> FP16 (per channel) 0.7367134094238281
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7358789443969727
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8352994918823242
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8419275283813477
TIME Linear: 0.7563114166259766
Speed Up INT8 * INT8 -> FP16 (per tensor):39.2%
Speed Up INT8 * INT8 -> FP16 (per token):2.47%
Speed Up INT8 * INT8 -> FP16 (per channel):2.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.7%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-10.44%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-11.32%
==========M=1365==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4603862762451172
TIME INT8 * INT8 -> FP16 (per token): 0.7534503936767578
TIME INT8 * INT8 -> FP16 (per channel) 0.7505655288696289
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7504940032958984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7785797119140625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7798671722412109
TIME Linear: 0.759124755859375
Speed Up INT8 * INT8 -> FP16 (per tensor):39.35%
Speed Up INT8 * INT8 -> FP16 (per token):0.75%
Speed Up INT8 * INT8 -> FP16 (per channel):1.13%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.14%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.56%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.73%
==========M=1396==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46913623809814453
TIME INT8 * INT8 -> FP16 (per token): 0.7696628570556641
TIME INT8 * INT8 -> FP16 (per channel) 0.7650375366210938
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7655620574951172
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7781505584716797
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7803916931152344
TIME Linear: 0.7576704025268555
Speed Up INT8 * INT8 -> FP16 (per tensor):38.08%
Speed Up INT8 * INT8 -> FP16 (per token):-1.58%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.04%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.7%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.0%
==========M=1427==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5126714706420898
TIME INT8 * INT8 -> FP16 (per token): 0.8037328720092773
TIME INT8 * INT8 -> FP16 (per channel) 0.8012771606445312
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8000373840332031
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2368440628051758
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2320756912231445
TIME Linear: 0.9006023406982422
Speed Up INT8 * INT8 -> FP16 (per tensor):43.07%
Speed Up INT8 * INT8 -> FP16 (per token):10.76%
Speed Up INT8 * INT8 -> FP16 (per channel):11.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.17%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.34%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-36.81%
==========M=1458==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.506138801574707
TIME INT8 * INT8 -> FP16 (per token): 0.8193016052246094
TIME INT8 * INT8 -> FP16 (per channel) 0.8181333541870117
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8165836334228516
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2414216995239258
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2428522109985352
TIME Linear: 0.9124755859375
Speed Up INT8 * INT8 -> FP16 (per tensor):44.53%
Speed Up INT8 * INT8 -> FP16 (per token):10.21%
Speed Up INT8 * INT8 -> FP16 (per channel):10.34%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.51%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.05%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-36.21%
==========M=1489==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5147933959960938
TIME INT8 * INT8 -> FP16 (per token): 0.8357048034667969
TIME INT8 * INT8 -> FP16 (per channel) 0.8342266082763672
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8341789245605469
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2446880340576172
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2455224990844727
TIME Linear: 0.9030580520629883
Speed Up INT8 * INT8 -> FP16 (per tensor):42.99%
Speed Up INT8 * INT8 -> FP16 (per token):7.46%
Speed Up INT8 * INT8 -> FP16 (per channel):7.62%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.83%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-37.92%
==========M=1520==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5156993865966797
TIME INT8 * INT8 -> FP16 (per token): 0.8539438247680664
TIME INT8 * INT8 -> FP16 (per channel) 0.8527517318725586
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8536100387573242
TIME INT8 * FP16 -> Fp16 (WO bias): 1.253819465637207
TIME INT8 * FP16 -> Fp16 (WI bias): 1.256108283996582
TIME Linear: 0.9017229080200195
Speed Up INT8 * INT8 -> FP16 (per tensor):42.81%
Speed Up INT8 * INT8 -> FP16 (per token):5.3%
Speed Up INT8 * INT8 -> FP16 (per channel):5.43%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.34%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-39.05%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.3%
==========M=1551==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.547027587890625
TIME INT8 * INT8 -> FP16 (per token): 0.8706092834472656
TIME INT8 * INT8 -> FP16 (per channel) 0.8691310882568359
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8689641952514648
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0694503784179688
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0717391967773438
TIME Linear: 0.8926868438720703
Speed Up INT8 * INT8 -> FP16 (per tensor):38.72%
Speed Up INT8 * INT8 -> FP16 (per token):2.47%
Speed Up INT8 * INT8 -> FP16 (per channel):2.64%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.66%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.8%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.06%
==========M=1582==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5531072616577148
TIME INT8 * INT8 -> FP16 (per token): 0.8900642395019531
TIME INT8 * INT8 -> FP16 (per channel) 0.888371467590332
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8888483047485352
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9256362915039062
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9288549423217773
TIME Linear: 0.8945703506469727
Speed Up INT8 * INT8 -> FP16 (per tensor):38.17%
Speed Up INT8 * INT8 -> FP16 (per token):0.5%
Speed Up INT8 * INT8 -> FP16 (per channel):0.69%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.64%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.47%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.83%
==========M=1613==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5461931228637695
TIME INT8 * INT8 -> FP16 (per token): 0.909113883972168
TIME INT8 * INT8 -> FP16 (per channel) 0.9054183959960938
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9073019027709961
TIME INT8 * FP16 -> Fp16 (WO bias): 1.186227798461914
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1808395385742188
TIME Linear: 0.8955240249633789
Speed Up INT8 * INT8 -> FP16 (per tensor):39.01%
Speed Up INT8 * INT8 -> FP16 (per token):-1.52%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.1%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.32%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-32.46%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-31.86%
==========M=1644==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5470514297485352
TIME INT8 * INT8 -> FP16 (per token): 0.922846794128418
TIME INT8 * INT8 -> FP16 (per channel) 0.9221315383911133
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9211063385009766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9273052215576172
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9298086166381836
TIME Linear: 0.8959531784057617
Speed Up INT8 * INT8 -> FP16 (per tensor):38.94%
Speed Up INT8 * INT8 -> FP16 (per token):-3.0%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.5%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.78%
==========M=1675==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5704402923583984
TIME INT8 * INT8 -> FP16 (per token): 0.939488410949707
TIME INT8 * INT8 -> FP16 (per channel) 0.9402990341186523
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9375572204589844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9509801864624023
TIME INT8 * FP16 -> Fp16 (WI bias): 0.973820686340332
TIME Linear: 1.0502099990844727
Speed Up INT8 * INT8 -> FP16 (per tensor):45.68%
Speed Up INT8 * INT8 -> FP16 (per token):10.54%
Speed Up INT8 * INT8 -> FP16 (per channel):10.47%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.73%
Speed Up INT8 * FP16 -> Fp16 (WO bias):9.45%
Speed Up INT8 * FP16 -> Fp16 (WI bias):7.27%
==========M=1706==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5753517150878906
TIME INT8 * INT8 -> FP16 (per token): 0.9584903717041016
TIME INT8 * INT8 -> FP16 (per channel) 0.9586334228515625
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9573459625244141
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9510517120361328
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9828329086303711
TIME Linear: 1.056671142578125
Speed Up INT8 * INT8 -> FP16 (per tensor):45.55%
Speed Up INT8 * INT8 -> FP16 (per token):9.29%
Speed Up INT8 * INT8 -> FP16 (per channel):9.28%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):10.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.99%
==========M=1737==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6689310073852539
TIME INT8 * INT8 -> FP16 (per token): 0.9500265121459961
TIME INT8 * INT8 -> FP16 (per channel) 0.9454250335693359
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9472370147705078
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2610197067260742
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2607574462890625
TIME Linear: 1.0515689849853516
Speed Up INT8 * INT8 -> FP16 (per tensor):36.39%
Speed Up INT8 * INT8 -> FP16 (per token):9.66%
Speed Up INT8 * INT8 -> FP16 (per channel):10.09%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.92%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.92%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-19.89%
==========M=1768==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6711483001708984
TIME INT8 * INT8 -> FP16 (per token): 0.9702682495117188
TIME INT8 * INT8 -> FP16 (per channel) 0.9670257568359375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9677886962890625
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2620925903320312
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2623071670532227
TIME Linear: 1.052260398864746
Speed Up INT8 * INT8 -> FP16 (per tensor):36.22%
Speed Up INT8 * INT8 -> FP16 (per token):7.79%
Speed Up INT8 * INT8 -> FP16 (per channel):8.1%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.03%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.94%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-19.96%
==========M=1799==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6868839263916016
TIME INT8 * INT8 -> FP16 (per token): 0.983738899230957
TIME INT8 * INT8 -> FP16 (per channel) 0.979924201965332
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9801387786865234
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5278339385986328
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5197992324829102
TIME Linear: 1.0329961776733398
Speed Up INT8 * INT8 -> FP16 (per tensor):33.51%
Speed Up INT8 * INT8 -> FP16 (per token):4.77%
Speed Up INT8 * INT8 -> FP16 (per channel):5.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-47.9%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.13%
==========M=1830==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6917953491210938
TIME INT8 * INT8 -> FP16 (per token): 1.0225296020507812
TIME INT8 * INT8 -> FP16 (per channel) 1.0219097137451172
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0210275650024414
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5314817428588867
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5227079391479492
TIME Linear: 1.0338306427001953
Speed Up INT8 * INT8 -> FP16 (per tensor):33.08%
Speed Up INT8 * INT8 -> FP16 (per token):1.09%
Speed Up INT8 * INT8 -> FP16 (per channel):1.15%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-48.14%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.29%
==========M=1861==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7127761840820312
TIME INT8 * INT8 -> FP16 (per token): 1.020669937133789
TIME INT8 * INT8 -> FP16 (per channel) 1.0181427001953125
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0181665420532227
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5366554260253906
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5288352966308594
TIME Linear: 1.0384798049926758
Speed Up INT8 * INT8 -> FP16 (per tensor):31.36%
Speed Up INT8 * INT8 -> FP16 (per token):1.71%
Speed Up INT8 * INT8 -> FP16 (per channel):1.96%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-47.97%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.22%
==========M=1892==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7170915603637695
TIME INT8 * INT8 -> FP16 (per token): 1.0357141494750977
TIME INT8 * INT8 -> FP16 (per channel) 1.0322093963623047
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0346412658691406
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5401363372802734
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5314102172851562
TIME Linear: 1.0329961776733398
Speed Up INT8 * INT8 -> FP16 (per tensor):30.58%
Speed Up INT8 * INT8 -> FP16 (per token):-0.26%
Speed Up INT8 * INT8 -> FP16 (per channel):0.08%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-49.09%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-48.25%
==========M=1923==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7338285446166992
TIME INT8 * INT8 -> FP16 (per token): 1.0528564453125
TIME INT8 * INT8 -> FP16 (per channel) 1.0508060455322266
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0510683059692383
TIME INT8 * FP16 -> Fp16 (WO bias): 1.8383502960205078
TIME INT8 * FP16 -> Fp16 (WI bias): 1.8230199813842773
TIME Linear: 1.138925552368164
Speed Up INT8 * INT8 -> FP16 (per tensor):35.57%
Speed Up INT8 * INT8 -> FP16 (per token):7.56%
Speed Up INT8 * INT8 -> FP16 (per channel):7.74%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.71%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-61.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-60.06%
==========M=1954==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7400751113891602
TIME INT8 * INT8 -> FP16 (per token): 1.0699748992919922
TIME INT8 * INT8 -> FP16 (per channel) 1.0667800903320312
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0683774948120117
TIME INT8 * FP16 -> Fp16 (WO bias): 1.8479347229003906
TIME INT8 * FP16 -> Fp16 (WI bias): 1.830601692199707
TIME Linear: 1.0070323944091797
Speed Up INT8 * INT8 -> FP16 (per tensor):26.51%
Speed Up INT8 * INT8 -> FP16 (per token):-6.25%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.09%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-83.5%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-81.78%
==========M=1985==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.751185417175293
TIME INT8 * INT8 -> FP16 (per token): 1.1069059371948242
TIME INT8 * INT8 -> FP16 (per channel) 1.1050224304199219
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1063814163208008
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1576652526855469
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1569976806640625
TIME Linear: 1.1659860610961914
Speed Up INT8 * INT8 -> FP16 (per tensor):35.58%
Speed Up INT8 * INT8 -> FP16 (per token):5.07%
Speed Up INT8 * INT8 -> FP16 (per channel):5.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.11%
Speed Up INT8 * FP16 -> Fp16 (WO bias):0.71%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.77%
==========M=2016==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7513761520385742
TIME INT8 * INT8 -> FP16 (per token): 1.113271713256836
TIME INT8 * INT8 -> FP16 (per channel) 1.1142730712890625
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1118888854980469
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1569023132324219
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1559724807739258
TIME Linear: 1.2005329132080078
Speed Up INT8 * INT8 -> FP16 (per tensor):37.41%
Speed Up INT8 * INT8 -> FP16 (per token):7.27%
Speed Up INT8 * INT8 -> FP16 (per channel):7.19%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):3.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.71%
==========M=2047==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7555246353149414
TIME INT8 * INT8 -> FP16 (per token): 1.1107921600341797
TIME INT8 * INT8 -> FP16 (per channel) 1.1079072952270508
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1088132858276367
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1563539505004883
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1567354202270508
TIME Linear: 1.2000799179077148
Speed Up INT8 * INT8 -> FP16 (per tensor):37.04%
Speed Up INT8 * INT8 -> FP16 (per token):7.44%
Speed Up INT8 * INT8 -> FP16 (per channel):7.68%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.61%
Speed Up INT8 * FP16 -> Fp16 (WO bias):3.64%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.61%
==========M=2078==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7753133773803711
TIME INT8 * INT8 -> FP16 (per token): 1.1432409286499023
TIME INT8 * INT8 -> FP16 (per channel) 1.1432886123657227
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2166261672973633
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2861013412475586
TIME INT8 * FP16 -> Fp16 (WI bias): 1.298379898071289
TIME Linear: 1.1731624603271484
Speed Up INT8 * INT8 -> FP16 (per tensor):33.91%
Speed Up INT8 * INT8 -> FP16 (per token):2.55%
Speed Up INT8 * INT8 -> FP16 (per channel):2.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.7%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-9.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-10.67%
==========M=2109==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7156133651733398
TIME INT8 * INT8 -> FP16 (per token): 1.1652469635009766
TIME INT8 * INT8 -> FP16 (per channel) 1.1643409729003906
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1640071868896484
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2866735458374023
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2996912002563477
TIME Linear: 1.1826753616333008
Speed Up INT8 * INT8 -> FP16 (per tensor):39.49%
Speed Up INT8 * INT8 -> FP16 (per token):1.47%
Speed Up INT8 * INT8 -> FP16 (per channel):1.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.58%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.89%
==========M=2140==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7167339324951172
TIME INT8 * INT8 -> FP16 (per token): 1.1622190475463867
TIME INT8 * INT8 -> FP16 (per channel) 1.1584043502807617
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1595964431762695
TIME INT8 * FP16 -> Fp16 (WO bias): 1.454019546508789
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4541864395141602
TIME Linear: 1.1721372604370117
Speed Up INT8 * INT8 -> FP16 (per tensor):38.85%
Speed Up INT8 * INT8 -> FP16 (per token):0.85%
Speed Up INT8 * INT8 -> FP16 (per channel):1.17%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.07%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.05%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-24.06%
==========M=2171==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7283926010131836
TIME INT8 * INT8 -> FP16 (per token): 1.2014150619506836
TIME INT8 * INT8 -> FP16 (per channel) 1.2004613876342773
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2023448944091797
TIME INT8 * FP16 -> Fp16 (WO bias): 1.8909454345703125
TIME INT8 * FP16 -> Fp16 (WI bias): 1.8645286560058594
TIME Linear: 0.9863138198852539
Speed Up INT8 * INT8 -> FP16 (per tensor):26.15%
Speed Up INT8 * INT8 -> FP16 (per token):-21.81%
Speed Up INT8 * INT8 -> FP16 (per channel):-21.71%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.9%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-91.72%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-89.04%
==========M=2202==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7229328155517578
TIME INT8 * INT8 -> FP16 (per token): 1.2158632278442383
TIME INT8 * INT8 -> FP16 (per channel) 1.2135982513427734
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2127399444580078
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3359785079956055
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3541936874389648
TIME Linear: 1.0864496231079102
Speed Up INT8 * INT8 -> FP16 (per tensor):33.46%
Speed Up INT8 * INT8 -> FP16 (per token):-11.91%
Speed Up INT8 * INT8 -> FP16 (per channel):-11.7%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.62%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.97%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-24.64%
==========M=2233==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7236242294311523
TIME INT8 * INT8 -> FP16 (per token): 1.234602928161621
TIME INT8 * INT8 -> FP16 (per channel) 1.2341737747192383
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2334346771240234
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3361215591430664
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3495206832885742
TIME Linear: 1.067495346069336
Speed Up INT8 * INT8 -> FP16 (per tensor):32.21%
Speed Up INT8 * INT8 -> FP16 (per token):-15.65%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.54%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.16%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-26.42%
==========M=2264==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7345676422119141
TIME INT8 * INT8 -> FP16 (per token): 1.251983642578125
TIME INT8 * INT8 -> FP16 (per channel) 1.2493610382080078
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2486457824707031
TIME INT8 * FP16 -> Fp16 (WO bias): 1.336836814880371
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3501882553100586
TIME Linear: 1.0699033737182617
Speed Up INT8 * INT8 -> FP16 (per tensor):31.34%
Speed Up INT8 * INT8 -> FP16 (per token):-17.02%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.77%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.71%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.95%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-26.2%
==========M=2295==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7268190383911133
TIME INT8 * INT8 -> FP16 (per token): 1.262807846069336
TIME INT8 * INT8 -> FP16 (per channel) 1.261305809020996
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2624502182006836
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3391971588134766
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3525724411010742
TIME Linear: 1.183772087097168
Speed Up INT8 * INT8 -> FP16 (per tensor):38.6%
Speed Up INT8 * INT8 -> FP16 (per token):-6.68%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-13.13%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.26%
==========M=2326==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7656574249267578
TIME INT8 * INT8 -> FP16 (per token): 1.2563467025756836
TIME INT8 * INT8 -> FP16 (per channel) 1.2537956237792969
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2549161911010742
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2868642807006836
TIME INT8 * FP16 -> Fp16 (WI bias): 1.286625862121582
TIME Linear: 1.3160467147827148
Speed Up INT8 * INT8 -> FP16 (per tensor):41.82%
Speed Up INT8 * INT8 -> FP16 (per token):4.54%
Speed Up INT8 * INT8 -> FP16 (per channel):4.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):2.22%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.24%
==========M=2357==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7669448852539062
TIME INT8 * INT8 -> FP16 (per token): 1.275467872619629
TIME INT8 * INT8 -> FP16 (per channel) 1.2725830078125
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2741804122924805
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2867450714111328
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2871503829956055
TIME Linear: 1.180863380432129
Speed Up INT8 * INT8 -> FP16 (per tensor):35.05%
Speed Up INT8 * INT8 -> FP16 (per token):-8.01%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.77%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.9%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.97%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.0%
==========M=2388==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6920337677001953
TIME INT8 * INT8 -> FP16 (per token): 1.2904882431030273
TIME INT8 * INT8 -> FP16 (per channel) 1.2883186340332031
TIME INT8 * INT8 -> FP16 (per token per channel): 1.292109489440918
TIME INT8 * FP16 -> Fp16 (WO bias): 1.734161376953125
TIME INT8 * FP16 -> Fp16 (WI bias): 1.7290353775024414
TIME Linear: 1.1754035949707031
Speed Up INT8 * INT8 -> FP16 (per tensor):41.12%
Speed Up INT8 * INT8 -> FP16 (per token):-9.79%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-47.54%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.1%
==========M=2419==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8148193359375
TIME INT8 * INT8 -> FP16 (per token): 1.3339757919311523
TIME INT8 * INT8 -> FP16 (per channel) 1.3347148895263672
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3358831405639648
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4176368713378906
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4345169067382812
TIME Linear: 1.321268081665039
Speed Up INT8 * INT8 -> FP16 (per tensor):38.33%
Speed Up INT8 * INT8 -> FP16 (per token):-0.96%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.11%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.29%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-8.57%
==========M=2450==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9270429611206055
TIME INT8 * INT8 -> FP16 (per token): 1.3264179229736328
TIME INT8 * INT8 -> FP16 (per channel) 1.323533058166504
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3250112533569336
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5182733535766602
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5250205993652344
TIME Linear: 1.319265365600586
Speed Up INT8 * INT8 -> FP16 (per tensor):29.73%
Speed Up INT8 * INT8 -> FP16 (per token):-0.54%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.32%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.44%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.08%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.6%
==========M=2481==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9327173233032227
TIME INT8 * INT8 -> FP16 (per token): 1.3434171676635742
TIME INT8 * INT8 -> FP16 (per channel) 1.3404607772827148
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3405799865722656
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5109539031982422
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5256404876708984
TIME Linear: 1.1261701583862305
Speed Up INT8 * INT8 -> FP16 (per tensor):17.18%
Speed Up INT8 * INT8 -> FP16 (per token):-19.29%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.04%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-34.17%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-35.47%
==========M=2512==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9509801864624023
TIME INT8 * INT8 -> FP16 (per token): 1.3842105865478516
TIME INT8 * INT8 -> FP16 (per channel) 1.3818025588989258
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3805389404296875
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3744115829467773
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3793468475341797
TIME Linear: 1.0908126831054688
Speed Up INT8 * INT8 -> FP16 (per tensor):12.82%
Speed Up INT8 * INT8 -> FP16 (per token):-26.9%
Speed Up INT8 * INT8 -> FP16 (per channel):-26.68%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-26.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-26.45%
==========M=2543==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9926557540893555
TIME INT8 * INT8 -> FP16 (per token): 1.3987541198730469
TIME INT8 * INT8 -> FP16 (per channel) 1.3982295989990234
TIME INT8 * INT8 -> FP16 (per token per channel): 1.396942138671875
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3751745223999023
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3793468475341797
TIME Linear: 1.090693473815918
Speed Up INT8 * INT8 -> FP16 (per tensor):8.99%
Speed Up INT8 * INT8 -> FP16 (per token):-28.24%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.2%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-28.08%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.08%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-26.47%
==========M=2574==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8520603179931641
TIME INT8 * INT8 -> FP16 (per token): 1.4158010482788086
TIME INT8 * INT8 -> FP16 (per channel) 1.4155864715576172
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4127254486083984
TIME INT8 * FP16 -> Fp16 (WO bias): 2.1219730377197266
TIME INT8 * FP16 -> Fp16 (WI bias): 2.1106481552124023
TIME Linear: 1.2104511260986328
Speed Up INT8 * INT8 -> FP16 (per tensor):29.61%
Speed Up INT8 * INT8 -> FP16 (per token):-16.96%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.95%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.71%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-75.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-74.37%
==========M=2605==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7827997207641602
TIME INT8 * INT8 -> FP16 (per token): 1.4136075973510742
TIME INT8 * INT8 -> FP16 (per channel) 1.4106512069702148
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4112472534179688
TIME INT8 * FP16 -> Fp16 (WO bias): 2.126955986022949
TIME INT8 * FP16 -> Fp16 (WI bias): 2.010488510131836
TIME Linear: 1.3337373733520508
Speed Up INT8 * INT8 -> FP16 (per tensor):41.31%
Speed Up INT8 * INT8 -> FP16 (per token):-5.99%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.77%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-59.47%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-50.74%
==========M=2636==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8528232574462891
TIME INT8 * INT8 -> FP16 (per token): 1.4264345169067383
TIME INT8 * INT8 -> FP16 (per channel) 1.425027847290039
TIME INT8 * INT8 -> FP16 (per token per channel): 1.424241065979004
TIME INT8 * FP16 -> Fp16 (WO bias): 2.1303892135620117
TIME INT8 * FP16 -> Fp16 (WI bias): 2.1188974380493164
TIME Linear: 1.4527320861816406
Speed Up INT8 * INT8 -> FP16 (per tensor):41.3%
Speed Up INT8 * INT8 -> FP16 (per token):1.81%
Speed Up INT8 * INT8 -> FP16 (per channel):1.91%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-46.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-45.86%
==========M=2667==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8538007736206055
TIME INT8 * INT8 -> FP16 (per token): 1.4485597610473633
TIME INT8 * INT8 -> FP16 (per channel) 1.4458656311035156
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4455795288085938
TIME INT8 * FP16 -> Fp16 (WO bias): 2.1372556686401367
TIME INT8 * FP16 -> Fp16 (WI bias): 2.1271467208862305
TIME Linear: 1.2050867080688477
Speed Up INT8 * INT8 -> FP16 (per tensor):29.15%
Speed Up INT8 * INT8 -> FP16 (per token):-20.2%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.98%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-77.35%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-76.51%
==========M=2698==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8909940719604492
TIME INT8 * INT8 -> FP16 (per token): 1.462697982788086
TIME INT8 * INT8 -> FP16 (per channel) 1.4605522155761719
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4607429504394531
TIME INT8 * FP16 -> Fp16 (WO bias): 1.629042625427246
TIME INT8 * FP16 -> Fp16 (WI bias): 1.6222000122070312
TIME Linear: 1.2163639068603516
Speed Up INT8 * INT8 -> FP16 (per tensor):26.75%
Speed Up INT8 * INT8 -> FP16 (per token):-20.25%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.08%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.09%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-33.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-33.36%
==========M=2729==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8923530578613281
TIME INT8 * INT8 -> FP16 (per token): 1.4800071716308594
TIME INT8 * INT8 -> FP16 (per channel) 1.4789104461669922
TIME INT8 * INT8 -> FP16 (per token per channel): 1.481795310974121
TIME INT8 * FP16 -> Fp16 (WO bias): 1.6287565231323242
TIME INT8 * FP16 -> Fp16 (WI bias): 1.6228675842285156
TIME Linear: 1.2069940567016602
Speed Up INT8 * INT8 -> FP16 (per tensor):26.07%
Speed Up INT8 * INT8 -> FP16 (per token):-22.62%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.53%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.77%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-34.94%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-34.46%
==========M=2760==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8312463760375977
TIME INT8 * INT8 -> FP16 (per token): 1.494145393371582
TIME INT8 * INT8 -> FP16 (per channel) 1.4938831329345703
TIME INT8 * INT8 -> FP16 (per token per channel): 1.491689682006836
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0093441009521484
TIME INT8 * FP16 -> Fp16 (WI bias): 2.003049850463867
TIME Linear: 1.2035131454467773
Speed Up INT8 * INT8 -> FP16 (per tensor):30.93%
Speed Up INT8 * INT8 -> FP16 (per token):-24.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-24.13%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.94%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-66.96%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-66.43%
==========M=2791==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8941888809204102
TIME INT8 * INT8 -> FP16 (per token): 1.5131235122680664
TIME INT8 * INT8 -> FP16 (per channel) 1.5105962753295898
TIME INT8 * INT8 -> FP16 (per token per channel): 1.5110254287719727
TIME INT8 * FP16 -> Fp16 (WO bias): 1.523280143737793
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5282154083251953
TIME Linear: 1.4553308486938477
Speed Up INT8 * INT8 -> FP16 (per tensor):38.56%
Speed Up INT8 * INT8 -> FP16 (per token):-3.97%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.83%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.67%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.01%
==========M=2822==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9360551834106445
TIME INT8 * INT8 -> FP16 (per token): 1.5476465225219727
TIME INT8 * INT8 -> FP16 (per channel) 1.545548439025879
TIME INT8 * INT8 -> FP16 (per token per channel): 1.545095443725586
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5677690505981445
TIME INT8 * FP16 -> Fp16 (WI bias): 1.6039848327636719
TIME Linear: 1.3213396072387695
Speed Up INT8 * INT8 -> FP16 (per tensor):29.16%
Speed Up INT8 * INT8 -> FP16 (per token):-17.13%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-21.39%
==========M=2853==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9528875350952148
TIME INT8 * INT8 -> FP16 (per token): 1.5703678131103516
TIME INT8 * INT8 -> FP16 (per channel) 1.579594612121582
TIME INT8 * INT8 -> FP16 (per token per channel): 1.5877723693847656
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5926599502563477
TIME INT8 * FP16 -> Fp16 (WI bias): 1.6319513320922852
TIME Linear: 1.3159751892089844
Speed Up INT8 * INT8 -> FP16 (per tensor):27.59%
Speed Up INT8 * INT8 -> FP16 (per token):-19.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.03%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-24.01%
==========M=2884==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9374380111694336
TIME INT8 * INT8 -> FP16 (per token): 1.5803098678588867
TIME INT8 * INT8 -> FP16 (per channel) 1.5794038772583008
TIME INT8 * INT8 -> FP16 (per token per channel): 1.5784978866577148
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0032405853271484
TIME INT8 * FP16 -> Fp16 (WI bias): 2.0049571990966797
TIME Linear: 1.5918731689453125
Speed Up INT8 * INT8 -> FP16 (per tensor):41.11%
Speed Up INT8 * INT8 -> FP16 (per token):0.73%
Speed Up INT8 * INT8 -> FP16 (per channel):0.78%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.84%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.84%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-25.95%
==========M=2915==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9525060653686523
TIME INT8 * INT8 -> FP16 (per token): 1.5958547592163086
TIME INT8 * INT8 -> FP16 (per channel) 1.5947341918945312
TIME INT8 * INT8 -> FP16 (per token per channel): 1.593613624572754
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0374059677124023
TIME INT8 * FP16 -> Fp16 (WI bias): 2.038407325744629
TIME Linear: 1.317739486694336
Speed Up INT8 * INT8 -> FP16 (per tensor):27.72%
Speed Up INT8 * INT8 -> FP16 (per token):-21.11%
Speed Up INT8 * INT8 -> FP16 (per channel):-21.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.94%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-54.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-54.69%
==========M=2946==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8266925811767578
TIME INT8 * INT8 -> FP16 (per token): 1.614689826965332
TIME INT8 * INT8 -> FP16 (per channel) 1.6121387481689453
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6111373901367188
TIME INT8 * FP16 -> Fp16 (WO bias): 2.4255990982055664
TIME INT8 * FP16 -> Fp16 (WI bias): 2.285623550415039
TIME Linear: 1.3173818588256836
Speed Up INT8 * INT8 -> FP16 (per tensor):37.25%
Speed Up INT8 * INT8 -> FP16 (per token):-22.57%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.37%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-84.12%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-73.5%
==========M=2977==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9772062301635742
TIME INT8 * INT8 -> FP16 (per token): 1.6318082809448242
TIME INT8 * INT8 -> FP16 (per channel) 1.6283988952636719
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6284465789794922
TIME INT8 * FP16 -> Fp16 (WO bias): 2.437162399291992
TIME INT8 * FP16 -> Fp16 (WI bias): 2.4185657501220703
TIME Linear: 1.3304948806762695
Speed Up INT8 * INT8 -> FP16 (per tensor):26.55%
Speed Up INT8 * INT8 -> FP16 (per token):-22.65%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.39%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.39%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-83.18%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-81.78%
==========M=3008==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9787082672119141
TIME INT8 * INT8 -> FP16 (per token): 1.6342401504516602
TIME INT8 * INT8 -> FP16 (per channel) 1.6329050064086914
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6322135925292969
TIME INT8 * FP16 -> Fp16 (WO bias): 2.4332523345947266
TIME INT8 * FP16 -> Fp16 (WI bias): 2.4210453033447266
TIME Linear: 1.3180255889892578
Speed Up INT8 * INT8 -> FP16 (per tensor):25.74%
Speed Up INT8 * INT8 -> FP16 (per token):-23.99%
Speed Up INT8 * INT8 -> FP16 (per channel):-23.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.84%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-84.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-83.69%
==========M=3039==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9792327880859375
TIME INT8 * INT8 -> FP16 (per token): 1.6312360763549805
TIME INT8 * INT8 -> FP16 (per channel) 1.6309499740600586
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6289949417114258
TIME INT8 * FP16 -> Fp16 (WO bias): 2.440476417541504
TIME INT8 * FP16 -> Fp16 (WI bias): 2.428603172302246
TIME Linear: 1.5926837921142578
Speed Up INT8 * INT8 -> FP16 (per tensor):38.52%
Speed Up INT8 * INT8 -> FP16 (per token):-2.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.4%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.28%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-53.23%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-52.48%
==========M=3070==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9822368621826172
TIME INT8 * INT8 -> FP16 (per token): 1.6686677932739258
TIME INT8 * INT8 -> FP16 (per channel) 1.666259765625
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6660690307617188
TIME INT8 * FP16 -> Fp16 (WO bias): 2.443552017211914
TIME INT8 * FP16 -> Fp16 (WI bias): 2.4312973022460938
TIME Linear: 1.317453384399414
Speed Up INT8 * INT8 -> FP16 (per tensor):25.44%
Speed Up INT8 * INT8 -> FP16 (per token):-26.66%
Speed Up INT8 * INT8 -> FP16 (per channel):-26.48%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-26.46%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-85.48%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-84.55%
==========M=3101==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.927424430847168
TIME INT8 * INT8 -> FP16 (per token): 1.6849279403686523
TIME INT8 * INT8 -> FP16 (per channel) 1.6847610473632812
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6817808151245117
TIME INT8 * FP16 -> Fp16 (WO bias): 2.7629852294921875
TIME INT8 * FP16 -> Fp16 (WI bias): 2.591586112976074
TIME Linear: 1.5753507614135742
Speed Up INT8 * INT8 -> FP16 (per tensor):41.13%
Speed Up INT8 * INT8 -> FP16 (per token):-6.96%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.95%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-75.39%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-64.51%
==========M=3132==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0222673416137695
TIME INT8 * INT8 -> FP16 (per token): 1.7077445983886719
TIME INT8 * INT8 -> FP16 (per channel) 1.7066240310668945
TIME INT8 * INT8 -> FP16 (per token per channel): 1.7050743103027344
TIME INT8 * FP16 -> Fp16 (WO bias): 2.8572559356689453
TIME INT8 * FP16 -> Fp16 (WI bias): 2.83052921295166
TIME Linear: 1.4308691024780273
Speed Up INT8 * INT8 -> FP16 (per tensor):28.56%
Speed Up INT8 * INT8 -> FP16 (per token):-19.35%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.27%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-99.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-97.82%
==========M=3163==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9289264678955078
TIME INT8 * INT8 -> FP16 (per token): 1.7215490341186523
TIME INT8 * INT8 -> FP16 (per channel) 1.7222881317138672
TIME INT8 * INT8 -> FP16 (per token per channel): 1.7196893692016602
TIME INT8 * FP16 -> Fp16 (WO bias): 2.3403406143188477
TIME INT8 * FP16 -> Fp16 (WI bias): 2.096724510192871
TIME Linear: 1.4467477798461914
Speed Up INT8 * INT8 -> FP16 (per tensor):35.79%
Speed Up INT8 * INT8 -> FP16 (per token):-18.99%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.05%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.87%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-61.77%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-44.93%
==========M=3194==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0246515274047852
TIME INT8 * INT8 -> FP16 (per token): 1.7160654067993164
TIME INT8 * INT8 -> FP16 (per channel) 1.714158058166504
TIME INT8 * INT8 -> FP16 (per token per channel): 1.7130613327026367
TIME INT8 * FP16 -> Fp16 (WO bias): 2.875542640686035
TIME INT8 * FP16 -> Fp16 (WI bias): 2.8482437133789062
TIME Linear: 1.43280029296875
Speed Up INT8 * INT8 -> FP16 (per tensor):28.49%
Speed Up INT8 * INT8 -> FP16 (per token):-19.77%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.64%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-100.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-98.79%
==========M=3225==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9531497955322266
TIME INT8 * INT8 -> FP16 (per token): 1.7307758331298828
TIME INT8 * INT8 -> FP16 (per channel) 1.7287731170654297
TIME INT8 * INT8 -> FP16 (per token per channel): 1.7281770706176758
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9632339477539062
TIME INT8 * FP16 -> Fp16 (WI bias): 1.8872261047363281
TIME Linear: 1.432037353515625
Speed Up INT8 * INT8 -> FP16 (per tensor):33.44%
Speed Up INT8 * INT8 -> FP16 (per token):-20.86%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.72%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.68%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.09%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-31.79%
==========M=3256==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0627508163452148
TIME INT8 * INT8 -> FP16 (per token): 1.7675399780273438
TIME INT8 * INT8 -> FP16 (per channel) 1.7687559127807617
TIME INT8 * INT8 -> FP16 (per token per channel): 1.7660140991210938
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9618511199951172
TIME INT8 * FP16 -> Fp16 (WI bias): 1.9849061965942383
TIME Linear: 1.4322519302368164
Speed Up INT8 * INT8 -> FP16 (per tensor):25.8%
Speed Up INT8 * INT8 -> FP16 (per token):-23.41%
Speed Up INT8 * INT8 -> FP16 (per channel):-23.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.98%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-38.59%
==========M=3287==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0639429092407227
TIME INT8 * INT8 -> FP16 (per token): 1.781153678894043
TIME INT8 * INT8 -> FP16 (per channel) 1.781010627746582
TIME INT8 * INT8 -> FP16 (per token per channel): 1.7807483673095703
TIME INT8 * FP16 -> Fp16 (WO bias): 2.261066436767578
TIME INT8 * FP16 -> Fp16 (WI bias): 2.270054817199707
TIME Linear: 1.4347076416015625
Speed Up INT8 * INT8 -> FP16 (per tensor):25.84%
Speed Up INT8 * INT8 -> FP16 (per token):-24.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-24.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-24.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-57.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-58.22%
==========M=3318==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0813713073730469
TIME INT8 * INT8 -> FP16 (per token): 1.8063783645629883
TIME INT8 * INT8 -> FP16 (per channel) 1.804947853088379
TIME INT8 * INT8 -> FP16 (per token per channel): 1.8042325973510742
TIME INT8 * FP16 -> Fp16 (WO bias): 1.8579721450805664
TIME INT8 * FP16 -> Fp16 (WI bias): 1.8585443496704102
TIME Linear: 1.4455556869506836
Speed Up INT8 * INT8 -> FP16 (per tensor):25.19%
Speed Up INT8 * INT8 -> FP16 (per token):-24.96%
Speed Up INT8 * INT8 -> FP16 (per channel):-24.86%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-24.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-28.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-28.57%
==========M=3349==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.058363914489746
TIME INT8 * INT8 -> FP16 (per token): 1.8269777297973633
TIME INT8 * INT8 -> FP16 (per channel) 1.825571060180664
TIME INT8 * INT8 -> FP16 (per token per channel): 1.8187522888183594
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9881963729858398
TIME INT8 * FP16 -> Fp16 (WI bias): 2.0112037658691406
TIME Linear: 1.4388322830200195
Speed Up INT8 * INT8 -> FP16 (per tensor):26.44%
Speed Up INT8 * INT8 -> FP16 (per token):-26.98%
Speed Up INT8 * INT8 -> FP16 (per channel):-26.88%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-26.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-38.18%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.78%
==========M=3380==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0875701904296875
TIME INT8 * INT8 -> FP16 (per token): 1.8355131149291992
TIME INT8 * INT8 -> FP16 (per channel) 1.8383979797363281
TIME INT8 * INT8 -> FP16 (per token per channel): 1.8334150314331055
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9881963729858398
TIME INT8 * FP16 -> Fp16 (WI bias): 2.0108938217163086
TIME Linear: 1.4417409896850586
Speed Up INT8 * INT8 -> FP16 (per tensor):24.57%
Speed Up INT8 * INT8 -> FP16 (per token):-27.31%
Speed Up INT8 * INT8 -> FP16 (per channel):-27.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-27.17%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.9%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.48%
==========M=3411==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9979724884033203
TIME INT8 * INT8 -> FP16 (per token): 1.849985122680664
TIME INT8 * INT8 -> FP16 (per channel) 1.8514394760131836
TIME INT8 * INT8 -> FP16 (per token per channel): 1.848769187927246
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9890546798706055
TIME INT8 * FP16 -> Fp16 (WI bias): 2.014446258544922
TIME Linear: 1.445150375366211
Speed Up INT8 * INT8 -> FP16 (per tensor):30.94%
Speed Up INT8 * INT8 -> FP16 (per token):-28.01%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.11%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-27.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.64%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.39%
==========M=3442==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0753631591796875
TIME INT8 * INT8 -> FP16 (per token): 1.8723249435424805
TIME INT8 * INT8 -> FP16 (per channel) 1.873922348022461
TIME INT8 * INT8 -> FP16 (per token per channel): 1.871347427368164
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9891738891601562
TIME INT8 * FP16 -> Fp16 (WI bias): 2.0132064819335938
TIME Linear: 1.439809799194336
Speed Up INT8 * INT8 -> FP16 (per tensor):25.31%
Speed Up INT8 * INT8 -> FP16 (per token):-30.04%
Speed Up INT8 * INT8 -> FP16 (per channel):-30.15%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-29.97%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-38.16%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.82%
==========M=3473==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0028600692749023
TIME INT8 * INT8 -> FP16 (per token): 1.8663644790649414
TIME INT8 * INT8 -> FP16 (per channel) 1.8651962280273438
TIME INT8 * INT8 -> FP16 (per token per channel): 1.86614990234375
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0663022994995117
TIME INT8 * FP16 -> Fp16 (WI bias): 1.9742012023925781
TIME Linear: 1.6403436660766602
Speed Up INT8 * INT8 -> FP16 (per tensor):38.86%
Speed Up INT8 * INT8 -> FP16 (per token):-13.78%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.71%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.77%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.97%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.35%
==========M=3504==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2142419815063477
TIME INT8 * INT8 -> FP16 (per token): 1.880478858947754
TIME INT8 * INT8 -> FP16 (per channel) 1.8807172775268555
TIME INT8 * INT8 -> FP16 (per token per channel): 1.8784523010253906
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0674943923950195
TIME INT8 * FP16 -> Fp16 (WI bias): 2.0886659622192383
TIME Linear: 1.6418218612670898
Speed Up INT8 * INT8 -> FP16 (per tensor):26.04%
Speed Up INT8 * INT8 -> FP16 (per token):-14.54%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.41%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-27.22%
==========M=3535==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0510683059692383
TIME INT8 * INT8 -> FP16 (per token): 1.898503303527832
TIME INT8 * INT8 -> FP16 (per channel) 1.89666748046875
TIME INT8 * INT8 -> FP16 (per token per channel): 1.8958330154418945
TIME INT8 * FP16 -> Fp16 (WO bias): 2.4363040924072266
TIME INT8 * FP16 -> Fp16 (WI bias): 2.375054359436035
TIME Linear: 1.8451690673828125
Speed Up INT8 * INT8 -> FP16 (per tensor):43.04%
Speed Up INT8 * INT8 -> FP16 (per token):-2.89%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.75%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-32.04%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-28.72%
==========M=3566==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.1153697967529297
TIME INT8 * INT8 -> FP16 (per token): 1.908254623413086
TIME INT8 * INT8 -> FP16 (per channel) 1.9075870513916016
TIME INT8 * INT8 -> FP16 (per token per channel): 1.9066095352172852
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0671606063842773
TIME INT8 * FP16 -> Fp16 (WI bias): 2.0904541015625
TIME Linear: 1.638031005859375
Speed Up INT8 * INT8 -> FP16 (per tensor):31.91%
Speed Up INT8 * INT8 -> FP16 (per token):-16.5%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.46%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-27.62%
==========M=3597==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.153564453125
TIME INT8 * INT8 -> FP16 (per token): 1.9542217254638672
TIME INT8 * INT8 -> FP16 (per channel) 1.9526004791259766
TIME INT8 * INT8 -> FP16 (per token per channel): 1.9530057907104492
TIME INT8 * FP16 -> Fp16 (WO bias): 2.189040184020996
TIME INT8 * FP16 -> Fp16 (WI bias): 2.209806442260742
TIME Linear: 1.552581787109375
Speed Up INT8 * INT8 -> FP16 (per tensor):25.7%
Speed Up INT8 * INT8 -> FP16 (per token):-25.87%
Speed Up INT8 * INT8 -> FP16 (per channel):-25.76%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-25.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-40.99%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-42.33%
==========M=3628==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0380029678344727
TIME INT8 * INT8 -> FP16 (per token): 1.973581314086914
TIME INT8 * INT8 -> FP16 (per channel) 1.9724369049072266
TIME INT8 * INT8 -> FP16 (per token per channel): 1.973414421081543
TIME INT8 * FP16 -> Fp16 (WO bias): 2.1877288818359375
TIME INT8 * FP16 -> Fp16 (WI bias): 2.16219425201416
TIME Linear: 1.5530586242675781
Speed Up INT8 * INT8 -> FP16 (per tensor):33.16%
Speed Up INT8 * INT8 -> FP16 (per token):-27.08%
Speed Up INT8 * INT8 -> FP16 (per channel):-27.0%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-27.07%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-40.87%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.22%
==========M=3659==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.1734247207641602
TIME INT8 * INT8 -> FP16 (per token): 1.9918203353881836
TIME INT8 * INT8 -> FP16 (per channel) 1.9910573959350586
TIME INT8 * INT8 -> FP16 (per token per channel): 1.9895315170288086
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9713401794433594
TIME INT8 * FP16 -> Fp16 (WI bias): 1.9771099090576172
TIME Linear: 1.5547752380371094
Speed Up INT8 * INT8 -> FP16 (per tensor):24.53%
Speed Up INT8 * INT8 -> FP16 (per token):-28.11%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-27.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-27.16%
==========M=3690==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0929584503173828
TIME INT8 * INT8 -> FP16 (per token): 2.008986473083496
TIME INT8 * INT8 -> FP16 (per channel) 2.0079612731933594
TIME INT8 * INT8 -> FP16 (per token per channel): 2.007007598876953
TIME INT8 * FP16 -> Fp16 (WO bias): 1.8563032150268555
TIME INT8 * FP16 -> Fp16 (WI bias): 1.8373489379882812
TIME Linear: 1.721334457397461
Speed Up INT8 * INT8 -> FP16 (per tensor):36.51%
Speed Up INT8 * INT8 -> FP16 (per token):-16.71%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.65%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.6%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.84%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.74%
==========M=3721==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.197052001953125
TIME INT8 * INT8 -> FP16 (per token): 2.0305395126342773
TIME INT8 * INT8 -> FP16 (per channel) 2.0262956619262695
TIME INT8 * INT8 -> FP16 (per token per channel): 2.0252227783203125
TIME INT8 * FP16 -> Fp16 (WO bias): 3.020501136779785
TIME INT8 * FP16 -> Fp16 (WI bias): 3.0039310455322266
TIME Linear: 1.7624378204345703
Speed Up INT8 * INT8 -> FP16 (per tensor):32.08%
Speed Up INT8 * INT8 -> FP16 (per token):-15.21%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.91%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-71.38%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-70.44%
==========M=3752==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2164592742919922
TIME INT8 * INT8 -> FP16 (per token): 2.018117904663086
TIME INT8 * INT8 -> FP16 (per channel) 2.018308639526367
TIME INT8 * INT8 -> FP16 (per token per channel): 2.0171642303466797
TIME INT8 * FP16 -> Fp16 (WO bias): 3.0242919921875
TIME INT8 * FP16 -> Fp16 (WI bias): 3.0104637145996094
TIME Linear: 1.7611503601074219
Speed Up INT8 * INT8 -> FP16 (per tensor):30.93%
Speed Up INT8 * INT8 -> FP16 (per token):-14.59%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.54%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-71.72%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-70.94%
==========M=3783==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.1460065841674805
TIME INT8 * INT8 -> FP16 (per token): 2.0616531372070312
TIME INT8 * INT8 -> FP16 (per channel) 2.0625829696655273
TIME INT8 * INT8 -> FP16 (per token per channel): 2.0596981048583984
TIME INT8 * FP16 -> Fp16 (WO bias): 2.8600692749023438
TIME INT8 * FP16 -> Fp16 (WI bias): 2.8463125228881836
TIME Linear: 2.0031213760375977
Speed Up INT8 * INT8 -> FP16 (per tensor):42.79%
Speed Up INT8 * INT8 -> FP16 (per token):-2.92%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.82%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-42.78%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-42.09%
==========M=3814==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.0187387466430664
TIME INT8 * INT8 -> FP16 (per token): 2.0791053771972656
TIME INT8 * INT8 -> FP16 (per channel) 2.080392837524414
TIME INT8 * INT8 -> FP16 (per token per channel): 2.0804643630981445
TIME INT8 * FP16 -> Fp16 (WO bias): 3.0369043350219727
TIME INT8 * FP16 -> Fp16 (WI bias): 2.928304672241211
TIME Linear: 1.6018152236938477
Speed Up INT8 * INT8 -> FP16 (per tensor):36.4%
Speed Up INT8 * INT8 -> FP16 (per token):-29.8%
Speed Up INT8 * INT8 -> FP16 (per channel):-29.88%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-29.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-89.59%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-82.81%
==========M=3845==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2388229370117188
TIME INT8 * INT8 -> FP16 (per token): 2.0943403244018555
TIME INT8 * INT8 -> FP16 (per channel) 2.0952463150024414
TIME INT8 * INT8 -> FP16 (per token per channel): 2.093362808227539
TIME INT8 * FP16 -> Fp16 (WO bias): 2.7153491973876953
TIME INT8 * FP16 -> Fp16 (WI bias): 2.722501754760742
TIME Linear: 1.8221616744995117
Speed Up INT8 * INT8 -> FP16 (per tensor):32.01%
Speed Up INT8 * INT8 -> FP16 (per token):-14.94%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.99%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-49.02%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-49.41%
==========M=3876==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2401580810546875
TIME INT8 * INT8 -> FP16 (per token): 2.1155834197998047
TIME INT8 * INT8 -> FP16 (per channel) 2.1145105361938477
TIME INT8 * INT8 -> FP16 (per token per channel): 2.114725112915039
TIME INT8 * FP16 -> Fp16 (WO bias): 3.370952606201172
TIME INT8 * FP16 -> Fp16 (WI bias): 3.3273696899414062
TIME Linear: 1.6354084014892578
Speed Up INT8 * INT8 -> FP16 (per tensor):24.17%
Speed Up INT8 * INT8 -> FP16 (per token):-29.36%
Speed Up INT8 * INT8 -> FP16 (per channel):-29.3%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-29.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-106.12%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-103.46%
==========M=3907==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.166224479675293
TIME INT8 * INT8 -> FP16 (per token): 2.127528190612793
TIME INT8 * INT8 -> FP16 (per channel) 2.124452590942383
TIME INT8 * INT8 -> FP16 (per token per channel): 2.125239372253418
TIME INT8 * FP16 -> Fp16 (WO bias): 2.673649787902832
TIME INT8 * FP16 -> Fp16 (WI bias): 2.666640281677246
TIME Linear: 1.8680572509765625
Speed Up INT8 * INT8 -> FP16 (per tensor):37.57%
Speed Up INT8 * INT8 -> FP16 (per token):-13.89%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.77%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-43.12%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-42.75%
==========M=3938==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.1476755142211914
TIME INT8 * INT8 -> FP16 (per token): 2.147245407104492
TIME INT8 * INT8 -> FP16 (per channel) 2.1448135375976562
TIME INT8 * INT8 -> FP16 (per token per channel): 2.143073081970215
TIME INT8 * FP16 -> Fp16 (WO bias): 3.0606985092163086
TIME INT8 * FP16 -> Fp16 (WI bias): 2.94039249420166
TIME Linear: 1.636338233947754
Speed Up INT8 * INT8 -> FP16 (per tensor):29.86%
Speed Up INT8 * INT8 -> FP16 (per token):-31.22%
Speed Up INT8 * INT8 -> FP16 (per channel):-31.07%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-30.97%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-87.05%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-79.69%
==========M=3969==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.3019561767578125
TIME INT8 * INT8 -> FP16 (per token): 2.169060707092285
TIME INT8 * INT8 -> FP16 (per channel) 2.1686315536499023
TIME INT8 * INT8 -> FP16 (per token per channel): 2.1678686141967773
TIME INT8 * FP16 -> Fp16 (WO bias): 2.1860837936401367
TIME INT8 * FP16 -> Fp16 (WI bias): 2.237391471862793
TIME Linear: 1.8846511840820312
Speed Up INT8 * INT8 -> FP16 (per tensor):30.92%
Speed Up INT8 * INT8 -> FP16 (per token):-15.09%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.07%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.03%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.99%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.72%
==========M=4000==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2826919555664062
TIME INT8 * INT8 -> FP16 (per token): 2.1717071533203125
TIME INT8 * INT8 -> FP16 (per channel) 2.170133590698242
TIME INT8 * INT8 -> FP16 (per token per channel): 2.168703079223633
TIME INT8 * FP16 -> Fp16 (WO bias): 2.187514305114746
TIME INT8 * FP16 -> Fp16 (WI bias): 2.2421836853027344
TIME Linear: 1.6926765441894531
Speed Up INT8 * INT8 -> FP16 (per tensor):24.22%
Speed Up INT8 * INT8 -> FP16 (per token):-28.3%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.21%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-28.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.23%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-32.46%
==========M=4031==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2873411178588867
TIME INT8 * INT8 -> FP16 (per token): 2.186727523803711
TIME INT8 * INT8 -> FP16 (per channel) 2.184128761291504
TIME INT8 * INT8 -> FP16 (per token per channel): 2.172565460205078
TIME INT8 * FP16 -> Fp16 (WO bias): 2.1636247634887695
TIME INT8 * FP16 -> Fp16 (WI bias): 2.2141218185424805
TIME Linear: 2.023148536682129
Speed Up INT8 * INT8 -> FP16 (per tensor):36.37%
Speed Up INT8 * INT8 -> FP16 (per token):-8.09%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.96%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.39%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.94%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.44%
==========M=4062==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.2883901596069336
TIME INT8 * INT8 -> FP16 (per token): 2.1749496459960938
TIME INT8 * INT8 -> FP16 (per channel) 2.1788835525512695
TIME INT8 * INT8 -> FP16 (per token per channel): 2.173471450805664
TIME INT8 * FP16 -> Fp16 (WO bias): 2.2087812423706055
TIME INT8 * FP16 -> Fp16 (WI bias): 2.184009552001953
TIME Linear: 1.6936302185058594
Speed Up INT8 * INT8 -> FP16 (per tensor):23.93%
Speed Up INT8 * INT8 -> FP16 (per token):-28.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.65%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-28.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-30.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-28.95%
==========M=4093==========
TIME INT8 * INT8 -> FP16 (per tensor): 1.3005733489990234
TIME INT8 * INT8 -> FP16 (per token): 2.195906639099121
TIME INT8 * INT8 -> FP16 (per channel) 2.194690704345703
TIME INT8 * INT8 -> FP16 (per token per channel): 2.1918773651123047
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0052194595336914
TIME INT8 * FP16 -> Fp16 (WI bias): 2.113962173461914
TIME Linear: 1.8651485443115234
Speed Up INT8 * INT8 -> FP16 (per tensor):30.27%
Speed Up INT8 * INT8 -> FP16 (per token):-17.73%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.67%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.52%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.51%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.34%
