Namespace(m=8192, n=8192, k=2048, num_iters=10)
==========M=8==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.03535747528076172
TIME INT8 * INT8 -> FP16 (per token): 0.04565715789794922
TIME INT8 * INT8 -> FP16 (per channel) 0.04191398620605469
TIME INT8 * INT8 -> FP16 (per token per channel): 0.04088878631591797
TIME INT8 * FP16 -> Fp16 (WO bias): 0.04858970642089844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.041747093200683594
TIME Linear: 0.07390975952148438
Speed Up INT8 * INT8 -> FP16 (per tensor):52.16%
Speed Up INT8 * INT8 -> FP16 (per token):38.23%
Speed Up INT8 * INT8 -> FP16 (per channel):43.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):44.68%
Speed Up INT8 * FP16 -> Fp16 (WO bias):34.26%
Speed Up INT8 * FP16 -> Fp16 (WI bias):43.52%
==========M=40==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.035452842712402344
TIME INT8 * INT8 -> FP16 (per token): 0.049591064453125
TIME INT8 * INT8 -> FP16 (per channel) 0.04715919494628906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.048232078552246094
TIME INT8 * FP16 -> Fp16 (WO bias): 0.05886554718017578
TIME INT8 * FP16 -> Fp16 (WI bias): 0.05047321319580078
TIME Linear: 0.06968975067138672
Speed Up INT8 * INT8 -> FP16 (per tensor):49.13%
Speed Up INT8 * INT8 -> FP16 (per token):28.84%
Speed Up INT8 * INT8 -> FP16 (per channel):32.33%
Speed Up INT8 * INT8 -> FP16 (per token per channel):30.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):15.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):27.57%
==========M=72==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.05123615264892578
TIME INT8 * INT8 -> FP16 (per token): 0.052928924560546875
TIME INT8 * INT8 -> FP16 (per channel) 0.050520896911621094
TIME INT8 * INT8 -> FP16 (per token per channel): 0.051856040954589844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.05893707275390625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.05009174346923828
TIME Linear: 0.07388591766357422
Speed Up INT8 * INT8 -> FP16 (per tensor):30.66%
Speed Up INT8 * INT8 -> FP16 (per token):28.36%
Speed Up INT8 * INT8 -> FP16 (per channel):31.62%
Speed Up INT8 * INT8 -> FP16 (per token per channel):29.82%
Speed Up INT8 * FP16 -> Fp16 (WO bias):20.23%
Speed Up INT8 * FP16 -> Fp16 (WI bias):32.2%
==========M=104==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.05230903625488281
TIME INT8 * INT8 -> FP16 (per token): 0.06194114685058594
TIME INT8 * INT8 -> FP16 (per channel) 0.06020069122314453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.06034374237060547
TIME INT8 * FP16 -> Fp16 (WO bias): 0.0646829605102539
TIME INT8 * FP16 -> Fp16 (WI bias): 0.05638599395751953
TIME Linear: 0.07338523864746094
Speed Up INT8 * INT8 -> FP16 (per tensor):28.72%
Speed Up INT8 * INT8 -> FP16 (per token):15.59%
Speed Up INT8 * INT8 -> FP16 (per channel):17.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):17.77%
Speed Up INT8 * FP16 -> Fp16 (WO bias):11.86%
Speed Up INT8 * FP16 -> Fp16 (WI bias):23.16%
==========M=136==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.054073333740234375
TIME INT8 * INT8 -> FP16 (per token): 0.06406307220458984
TIME INT8 * INT8 -> FP16 (per channel) 0.06287097930908203
TIME INT8 * INT8 -> FP16 (per token per channel): 0.06351470947265625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.0688791275024414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.059151649475097656
TIME Linear: 0.10721683502197266
Speed Up INT8 * INT8 -> FP16 (per tensor):49.57%
Speed Up INT8 * INT8 -> FP16 (per token):40.25%
Speed Up INT8 * INT8 -> FP16 (per channel):41.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):40.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):35.76%
Speed Up INT8 * FP16 -> Fp16 (WI bias):44.83%
==========M=168==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.04684925079345703
TIME INT8 * INT8 -> FP16 (per token): 0.07281303405761719
TIME INT8 * INT8 -> FP16 (per channel) 0.07171630859375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.07195472717285156
TIME INT8 * FP16 -> Fp16 (WO bias): 0.07202625274658203
TIME INT8 * FP16 -> Fp16 (WI bias): 0.0621795654296875
TIME Linear: 0.07598400115966797
Speed Up INT8 * INT8 -> FP16 (per tensor):38.34%
Speed Up INT8 * INT8 -> FP16 (per token):4.17%
Speed Up INT8 * INT8 -> FP16 (per channel):5.62%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):5.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):18.17%
==========M=200==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06911754608154297
TIME INT8 * INT8 -> FP16 (per token): 0.0825643539428711
TIME INT8 * INT8 -> FP16 (per channel) 0.08177757263183594
TIME INT8 * INT8 -> FP16 (per token per channel): 0.08196830749511719
TIME INT8 * FP16 -> Fp16 (WO bias): 0.08933544158935547
TIME INT8 * FP16 -> Fp16 (WI bias): 0.07867813110351562
TIME Linear: 0.10461807250976562
Speed Up INT8 * INT8 -> FP16 (per tensor):33.93%
Speed Up INT8 * INT8 -> FP16 (per token):21.08%
Speed Up INT8 * INT8 -> FP16 (per channel):21.83%
Speed Up INT8 * INT8 -> FP16 (per token per channel):21.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):14.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):24.79%
==========M=232==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.06971359252929688
TIME INT8 * INT8 -> FP16 (per token): 0.08633136749267578
TIME INT8 * INT8 -> FP16 (per channel) 0.08466243743896484
TIME INT8 * INT8 -> FP16 (per token per channel): 0.08475780487060547
TIME INT8 * FP16 -> Fp16 (WO bias): 0.10190010070800781
TIME INT8 * FP16 -> Fp16 (WI bias): 0.07877349853515625
TIME Linear: 0.10886192321777344
Speed Up INT8 * INT8 -> FP16 (per tensor):35.96%
Speed Up INT8 * INT8 -> FP16 (per token):20.7%
Speed Up INT8 * INT8 -> FP16 (per channel):22.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):22.14%
Speed Up INT8 * FP16 -> Fp16 (WO bias):6.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):27.64%
==========M=264==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.07176399230957031
TIME INT8 * INT8 -> FP16 (per token): 0.0929117202758789
TIME INT8 * INT8 -> FP16 (per channel) 0.09038448333740234
TIME INT8 * INT8 -> FP16 (per token per channel): 0.09241104125976562
TIME INT8 * FP16 -> Fp16 (WO bias): 0.09245872497558594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.0783681869506836
TIME Linear: 0.10459423065185547
Speed Up INT8 * INT8 -> FP16 (per tensor):31.39%
Speed Up INT8 * INT8 -> FP16 (per token):11.17%
Speed Up INT8 * INT8 -> FP16 (per channel):13.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):11.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):25.07%
==========M=296==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.07925033569335938
TIME INT8 * INT8 -> FP16 (per token): 0.0978708267211914
TIME INT8 * INT8 -> FP16 (per channel) 0.09377002716064453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.09458065032958984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.09682178497314453
TIME INT8 * FP16 -> Fp16 (WI bias): 0.08313655853271484
TIME Linear: 0.10602474212646484
Speed Up INT8 * INT8 -> FP16 (per tensor):25.25%
Speed Up INT8 * INT8 -> FP16 (per token):7.69%
Speed Up INT8 * INT8 -> FP16 (per channel):11.56%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):8.68%
Speed Up INT8 * FP16 -> Fp16 (WI bias):21.59%
==========M=328==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.08857250213623047
TIME INT8 * INT8 -> FP16 (per token): 0.10437965393066406
TIME INT8 * INT8 -> FP16 (per channel) 0.1020669937133789
TIME INT8 * INT8 -> FP16 (per token per channel): 0.10497570037841797
TIME INT8 * FP16 -> Fp16 (WO bias): 0.1112222671508789
TIME INT8 * FP16 -> Fp16 (WI bias): 0.09565353393554688
TIME Linear: 0.10530948638916016
Speed Up INT8 * INT8 -> FP16 (per tensor):15.89%
Speed Up INT8 * INT8 -> FP16 (per token):0.88%
Speed Up INT8 * INT8 -> FP16 (per channel):3.08%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.32%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):9.17%
==========M=360==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.08974075317382812
TIME INT8 * INT8 -> FP16 (per token): 0.11043548583984375
TIME INT8 * INT8 -> FP16 (per channel) 0.10952949523925781
TIME INT8 * INT8 -> FP16 (per token per channel): 0.11036396026611328
TIME INT8 * FP16 -> Fp16 (WO bias): 0.11272430419921875
TIME INT8 * FP16 -> Fp16 (WI bias): 0.09670257568359375
TIME Linear: 0.1051187515258789
Speed Up INT8 * INT8 -> FP16 (per tensor):14.63%
Speed Up INT8 * INT8 -> FP16 (per token):-5.06%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.2%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.99%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.24%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.01%
==========M=392==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.084686279296875
TIME INT8 * INT8 -> FP16 (per token): 0.11615753173828125
TIME INT8 * INT8 -> FP16 (per channel) 0.11339187622070312
TIME INT8 * INT8 -> FP16 (per token per channel): 0.11565685272216797
TIME INT8 * FP16 -> Fp16 (WO bias): 0.13234615325927734
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1131296157836914
TIME Linear: 0.13349056243896484
Speed Up INT8 * INT8 -> FP16 (per tensor):36.56%
Speed Up INT8 * INT8 -> FP16 (per token):12.98%
Speed Up INT8 * INT8 -> FP16 (per channel):15.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):13.36%
Speed Up INT8 * FP16 -> Fp16 (WO bias):0.86%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.25%
==========M=424==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.08933544158935547
TIME INT8 * INT8 -> FP16 (per token): 0.1230478286743164
TIME INT8 * INT8 -> FP16 (per channel) 0.11935234069824219
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1224517822265625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.1329660415649414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1130819320678711
TIME Linear: 0.1327991485595703
Speed Up INT8 * INT8 -> FP16 (per tensor):32.73%
Speed Up INT8 * INT8 -> FP16 (per token):7.34%
Speed Up INT8 * INT8 -> FP16 (per channel):10.13%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.13%
Speed Up INT8 * FP16 -> Fp16 (WI bias):14.85%
==========M=456==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.09953975677490234
TIME INT8 * INT8 -> FP16 (per token): 0.1302957534790039
TIME INT8 * INT8 -> FP16 (per channel) 0.12390613555908203
TIME INT8 * INT8 -> FP16 (per token per channel): 0.12929439544677734
TIME INT8 * FP16 -> Fp16 (WO bias): 0.14896392822265625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.13103485107421875
TIME Linear: 0.13322830200195312
Speed Up INT8 * INT8 -> FP16 (per tensor):25.29%
Speed Up INT8 * INT8 -> FP16 (per token):2.2%
Speed Up INT8 * INT8 -> FP16 (per channel):7.0%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.95%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.81%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.65%
==========M=488==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.09293556213378906
TIME INT8 * INT8 -> FP16 (per token): 0.13473033905029297
TIME INT8 * INT8 -> FP16 (per channel) 0.1329183578491211
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1346111297607422
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17228126525878906
TIME INT8 * FP16 -> Fp16 (WI bias): 0.14944076538085938
TIME Linear: 0.13473033905029297
Speed Up INT8 * INT8 -> FP16 (per tensor):31.02%
Speed Up INT8 * INT8 -> FP16 (per token):0.0%
Speed Up INT8 * INT8 -> FP16 (per channel):1.34%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.09%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-27.87%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-10.92%
==========M=520==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.09741783142089844
TIME INT8 * INT8 -> FP16 (per token): 0.1447439193725586
TIME INT8 * INT8 -> FP16 (per channel) 0.14243125915527344
TIME INT8 * INT8 -> FP16 (per token per channel): 0.14352798461914062
TIME INT8 * FP16 -> Fp16 (WO bias): 0.1653909683227539
TIME INT8 * FP16 -> Fp16 (WI bias): 0.14483928680419922
TIME Linear: 0.15060901641845703
Speed Up INT8 * INT8 -> FP16 (per tensor):35.32%
Speed Up INT8 * INT8 -> FP16 (per token):3.89%
Speed Up INT8 * INT8 -> FP16 (per channel):5.43%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.7%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-9.81%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.83%
==========M=552==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.10101795196533203
TIME INT8 * INT8 -> FP16 (per token): 0.14913082122802734
TIME INT8 * INT8 -> FP16 (per channel) 0.14786720275878906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.14829635620117188
TIME INT8 * FP16 -> Fp16 (WO bias): 0.16682147979736328
TIME INT8 * FP16 -> Fp16 (WI bias): 0.14472007751464844
TIME Linear: 0.15103816986083984
Speed Up INT8 * INT8 -> FP16 (per tensor):33.12%
Speed Up INT8 * INT8 -> FP16 (per token):1.26%
Speed Up INT8 * INT8 -> FP16 (per channel):2.1%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.82%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-10.45%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.18%
==========M=584==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1020669937133789
TIME INT8 * INT8 -> FP16 (per token): 0.15769004821777344
TIME INT8 * INT8 -> FP16 (per channel) 0.15554428100585938
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1584768295288086
TIME INT8 * FP16 -> Fp16 (WO bias): 0.15895366668701172
TIME INT8 * FP16 -> Fp16 (WI bias): 0.13179779052734375
TIME Linear: 0.15189647674560547
Speed Up INT8 * INT8 -> FP16 (per tensor):32.8%
Speed Up INT8 * INT8 -> FP16 (per token):-3.81%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.4%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.23%
==========M=616==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.10159015655517578
TIME INT8 * INT8 -> FP16 (per token): 0.1614093780517578
TIME INT8 * INT8 -> FP16 (per channel) 0.15969276428222656
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1609325408935547
TIME INT8 * FP16 -> Fp16 (WO bias): 0.15909671783447266
TIME INT8 * FP16 -> Fp16 (WI bias): 0.13494491577148438
TIME Linear: 0.15664100646972656
Speed Up INT8 * INT8 -> FP16 (per tensor):35.14%
Speed Up INT8 * INT8 -> FP16 (per token):-3.04%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.95%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.74%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.57%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.85%
==========M=648==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1173257827758789
TIME INT8 * INT8 -> FP16 (per token): 0.17063617706298828
TIME INT8 * INT8 -> FP16 (per channel) 0.16911029815673828
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1699686050415039
TIME INT8 * FP16 -> Fp16 (WO bias): 0.19292831420898438
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1662731170654297
TIME Linear: 0.1730203628540039
Speed Up INT8 * INT8 -> FP16 (per tensor):32.19%
Speed Up INT8 * INT8 -> FP16 (per token):1.38%
Speed Up INT8 * INT8 -> FP16 (per channel):2.26%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.51%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.9%
==========M=680==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1184225082397461
TIME INT8 * INT8 -> FP16 (per token): 0.1779794692993164
TIME INT8 * INT8 -> FP16 (per channel) 0.1731395721435547
TIME INT8 * INT8 -> FP16 (per token per channel): 0.17664432525634766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.19452571868896484
TIME INT8 * FP16 -> Fp16 (WI bias): 0.16722679138183594
TIME Linear: 0.17201900482177734
Speed Up INT8 * INT8 -> FP16 (per tensor):31.16%
Speed Up INT8 * INT8 -> FP16 (per token):-3.47%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.65%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.69%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-13.08%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.79%
==========M=712==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12273788452148438
TIME INT8 * INT8 -> FP16 (per token): 0.1822948455810547
TIME INT8 * INT8 -> FP16 (per channel) 0.1804828643798828
TIME INT8 * INT8 -> FP16 (per token per channel): 0.18186569213867188
TIME INT8 * FP16 -> Fp16 (WO bias): 0.19600391387939453
TIME INT8 * FP16 -> Fp16 (WI bias): 0.16586780548095703
TIME Linear: 0.1737833023071289
Speed Up INT8 * INT8 -> FP16 (per tensor):29.37%
Speed Up INT8 * INT8 -> FP16 (per token):-4.9%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.86%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-12.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.55%
==========M=744==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12576580047607422
TIME INT8 * INT8 -> FP16 (per token): 0.19047260284423828
TIME INT8 * INT8 -> FP16 (per channel) 0.1882791519165039
TIME INT8 * INT8 -> FP16 (per token per channel): 0.189971923828125
TIME INT8 * FP16 -> Fp16 (WO bias): 0.27413368225097656
TIME INT8 * FP16 -> Fp16 (WI bias): 0.23953914642333984
TIME Linear: 0.17099380493164062
Speed Up INT8 * INT8 -> FP16 (per tensor):26.45%
Speed Up INT8 * INT8 -> FP16 (per token):-11.39%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.11%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-60.32%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-40.09%
==========M=776==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1288890838623047
TIME INT8 * INT8 -> FP16 (per token): 0.19233226776123047
TIME INT8 * INT8 -> FP16 (per channel) 0.19125938415527344
TIME INT8 * INT8 -> FP16 (per token per channel): 0.19347667694091797
TIME INT8 * FP16 -> Fp16 (WO bias): 0.20530223846435547
TIME INT8 * FP16 -> Fp16 (WI bias): 0.17440319061279297
TIME Linear: 0.20830631256103516
Speed Up INT8 * INT8 -> FP16 (per tensor):38.13%
Speed Up INT8 * INT8 -> FP16 (per token):7.67%
Speed Up INT8 * INT8 -> FP16 (per channel):8.18%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):1.44%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.28%
==========M=808==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12881755828857422
TIME INT8 * INT8 -> FP16 (per token): 0.20134449005126953
TIME INT8 * INT8 -> FP16 (per channel) 0.2000570297241211
TIME INT8 * INT8 -> FP16 (per token per channel): 0.20229816436767578
TIME INT8 * FP16 -> Fp16 (WO bias): 0.20749568939208984
TIME INT8 * FP16 -> Fp16 (WI bias): 0.17468929290771484
TIME Linear: 0.20627975463867188
Speed Up INT8 * INT8 -> FP16 (per tensor):37.55%
Speed Up INT8 * INT8 -> FP16 (per token):2.39%
Speed Up INT8 * INT8 -> FP16 (per channel):3.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.59%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.31%
==========M=840==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.13072490692138672
TIME INT8 * INT8 -> FP16 (per token): 0.20685195922851562
TIME INT8 * INT8 -> FP16 (per channel) 0.20799636840820312
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2079486846923828
TIME INT8 * FP16 -> Fp16 (WO bias): 0.24001598358154297
TIME INT8 * FP16 -> Fp16 (WI bias): 0.2012014389038086
TIME Linear: 0.20208358764648438
Speed Up INT8 * INT8 -> FP16 (per tensor):35.31%
Speed Up INT8 * INT8 -> FP16 (per token):-2.36%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.9%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.77%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.44%
==========M=872==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1331329345703125
TIME INT8 * INT8 -> FP16 (per token): 0.2140045166015625
TIME INT8 * INT8 -> FP16 (per channel) 0.2104043960571289
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2147197723388672
TIME INT8 * FP16 -> Fp16 (WO bias): 0.22211074829101562
TIME INT8 * FP16 -> Fp16 (WI bias): 0.18553733825683594
TIME Linear: 0.2022266387939453
Speed Up INT8 * INT8 -> FP16 (per tensor):34.17%
Speed Up INT8 * INT8 -> FP16 (per token):-5.82%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.04%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.18%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-9.83%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.25%
==========M=904==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.13573169708251953
TIME INT8 * INT8 -> FP16 (per token): 0.21793842315673828
TIME INT8 * INT8 -> FP16 (per channel) 0.21474361419677734
TIME INT8 * INT8 -> FP16 (per token per channel): 0.21812915802001953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3921031951904297
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3451824188232422
TIME Linear: 0.22242069244384766
Speed Up INT8 * INT8 -> FP16 (per tensor):38.98%
Speed Up INT8 * INT8 -> FP16 (per token):2.02%
Speed Up INT8 * INT8 -> FP16 (per channel):3.45%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-76.29%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-55.19%
==========M=936==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.13866424560546875
TIME INT8 * INT8 -> FP16 (per token): 0.22518634796142578
TIME INT8 * INT8 -> FP16 (per channel) 0.22137165069580078
TIME INT8 * INT8 -> FP16 (per token per channel): 0.22430419921875
TIME INT8 * FP16 -> Fp16 (WO bias): 0.40035247802734375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3510475158691406
TIME Linear: 0.22089481353759766
Speed Up INT8 * INT8 -> FP16 (per tensor):37.23%
Speed Up INT8 * INT8 -> FP16 (per token):-1.94%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.54%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-81.24%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-58.92%
==========M=968==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1428365707397461
TIME INT8 * INT8 -> FP16 (per token): 0.23245811462402344
TIME INT8 * INT8 -> FP16 (per channel) 0.22835731506347656
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2321481704711914
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4023551940917969
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3529071807861328
TIME Linear: 0.2210855484008789
Speed Up INT8 * INT8 -> FP16 (per tensor):35.39%
Speed Up INT8 * INT8 -> FP16 (per token):-5.14%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.0%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-81.99%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-59.62%
==========M=1000==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1436471939086914
TIME INT8 * INT8 -> FP16 (per token): 0.23949146270751953
TIME INT8 * INT8 -> FP16 (per channel) 0.2336740493774414
TIME INT8 * INT8 -> FP16 (per token per channel): 0.23739337921142578
TIME INT8 * FP16 -> Fp16 (WO bias): 0.41027069091796875
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3590106964111328
TIME Linear: 0.2214193344116211
Speed Up INT8 * INT8 -> FP16 (per tensor):35.12%
Speed Up INT8 * INT8 -> FP16 (per token):-8.16%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.53%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.21%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-85.29%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-62.14%
==========M=1032==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.15366077423095703
TIME INT8 * INT8 -> FP16 (per token): 0.24619102478027344
TIME INT8 * INT8 -> FP16 (per channel) 0.243377685546875
TIME INT8 * INT8 -> FP16 (per token per channel): 0.24614334106445312
TIME INT8 * FP16 -> Fp16 (WO bias): 0.2894401550292969
TIME INT8 * FP16 -> Fp16 (WI bias): 0.2460479736328125
TIME Linear: 0.2399921417236328
Speed Up INT8 * INT8 -> FP16 (per tensor):35.97%
Speed Up INT8 * INT8 -> FP16 (per token):-2.58%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.41%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.52%
==========M=1064==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1544952392578125
TIME INT8 * INT8 -> FP16 (per token): 0.25420188903808594
TIME INT8 * INT8 -> FP16 (per channel) 0.2513408660888672
TIME INT8 * INT8 -> FP16 (per token per channel): 0.25446414947509766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3787994384765625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.32889842987060547
TIME Linear: 0.2411365509033203
Speed Up INT8 * INT8 -> FP16 (per tensor):35.93%
Speed Up INT8 * INT8 -> FP16 (per token):-5.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.53%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-57.09%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-36.4%
==========M=1096==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.15590190887451172
TIME INT8 * INT8 -> FP16 (per token): 0.2622842788696289
TIME INT8 * INT8 -> FP16 (per channel) 0.25866031646728516
TIME INT8 * INT8 -> FP16 (per token per channel): 0.26056766510009766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3104686737060547
TIME INT8 * FP16 -> Fp16 (WI bias): 0.42111873626708984
TIME Linear: 0.24273395538330078
Speed Up INT8 * INT8 -> FP16 (per tensor):35.77%
Speed Up INT8 * INT8 -> FP16 (per token):-8.05%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.56%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.35%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-27.9%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-73.49%
==========M=1128==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.15845298767089844
TIME INT8 * INT8 -> FP16 (per token): 0.2694368362426758
TIME INT8 * INT8 -> FP16 (per channel) 0.2673625946044922
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2675294876098633
TIME INT8 * FP16 -> Fp16 (WO bias): 0.38611888885498047
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3326416015625
TIME Linear: 0.24249553680419922
Speed Up INT8 * INT8 -> FP16 (per tensor):34.66%
Speed Up INT8 * INT8 -> FP16 (per token):-11.11%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.25%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.32%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-59.23%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-37.17%
==========M=1160==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1770496368408203
TIME INT8 * INT8 -> FP16 (per token): 0.27158260345458984
TIME INT8 * INT8 -> FP16 (per channel) 0.2701282501220703
TIME INT8 * INT8 -> FP16 (per token per channel): 0.27091503143310547
TIME INT8 * FP16 -> Fp16 (WO bias): 0.2845287322998047
TIME INT8 * FP16 -> Fp16 (WI bias): 0.23555755615234375
TIME Linear: 0.24700164794921875
Speed Up INT8 * INT8 -> FP16 (per tensor):28.32%
Speed Up INT8 * INT8 -> FP16 (per token):-9.95%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.68%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.19%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.63%
==========M=1192==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.16887187957763672
TIME INT8 * INT8 -> FP16 (per token): 0.2794027328491211
TIME INT8 * INT8 -> FP16 (per channel) 0.27849674224853516
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2795696258544922
TIME INT8 * FP16 -> Fp16 (WO bias): 0.28564929962158203
TIME INT8 * FP16 -> Fp16 (WI bias): 0.2355813980102539
TIME Linear: 0.24535655975341797
Speed Up INT8 * INT8 -> FP16 (per tensor):31.17%
Speed Up INT8 * INT8 -> FP16 (per token):-13.88%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.94%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.98%
==========M=1224==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1693248748779297
TIME INT8 * INT8 -> FP16 (per token): 0.2851724624633789
TIME INT8 * INT8 -> FP16 (per channel) 0.2831697463989258
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2871513366699219
TIME INT8 * FP16 -> Fp16 (WO bias): 0.28705596923828125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.23548603057861328
TIME Linear: 0.2430438995361328
Speed Up INT8 * INT8 -> FP16 (per tensor):30.33%
Speed Up INT8 * INT8 -> FP16 (per token):-17.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.15%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.11%
==========M=1256==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1718282699584961
TIME INT8 * INT8 -> FP16 (per token): 0.29227733612060547
TIME INT8 * INT8 -> FP16 (per channel) 0.29120445251464844
TIME INT8 * INT8 -> FP16 (per token per channel): 0.29556751251220703
TIME INT8 * FP16 -> Fp16 (WO bias): 0.2884387969970703
TIME INT8 * FP16 -> Fp16 (WI bias): 0.2357959747314453
TIME Linear: 0.24766921997070312
Speed Up INT8 * INT8 -> FP16 (per tensor):30.62%
Speed Up INT8 * INT8 -> FP16 (per token):-18.01%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.58%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.34%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.46%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.79%
==========M=1288==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18622875213623047
TIME INT8 * INT8 -> FP16 (per token): 0.29714107513427734
TIME INT8 * INT8 -> FP16 (per channel) 0.29265880584716797
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2980470657348633
TIME INT8 * FP16 -> Fp16 (WO bias): 0.43768882751464844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.371551513671875
TIME Linear: 0.2894401550292969
Speed Up INT8 * INT8 -> FP16 (per tensor):35.66%
Speed Up INT8 * INT8 -> FP16 (per token):-2.66%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.11%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.97%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-51.22%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-28.37%
==========M=1320==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18308162689208984
TIME INT8 * INT8 -> FP16 (per token): 0.3015756607055664
TIME INT8 * INT8 -> FP16 (per channel) 0.2993345260620117
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3016471862792969
TIME INT8 * FP16 -> Fp16 (WO bias): 0.43883323669433594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.37505626678466797
TIME Linear: 0.2871513366699219
Speed Up INT8 * INT8 -> FP16 (per tensor):36.24%
Speed Up INT8 * INT8 -> FP16 (per token):-5.02%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.24%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.05%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-52.82%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-30.61%
==========M=1352==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18286705017089844
TIME INT8 * INT8 -> FP16 (per token): 0.3127574920654297
TIME INT8 * INT8 -> FP16 (per channel) 0.31104087829589844
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3118753433227539
TIME INT8 * FP16 -> Fp16 (WO bias): 0.40700435638427734
TIME INT8 * FP16 -> Fp16 (WI bias): 0.34651756286621094
TIME Linear: 0.2865314483642578
Speed Up INT8 * INT8 -> FP16 (per tensor):36.18%
Speed Up INT8 * INT8 -> FP16 (per token):-9.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-8.85%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-42.05%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.94%
==========M=1384==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1835346221923828
TIME INT8 * INT8 -> FP16 (per token): 0.31757354736328125
TIME INT8 * INT8 -> FP16 (per channel) 0.31578540802001953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.32036304473876953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.34592151641845703
TIME INT8 * FP16 -> Fp16 (WI bias): 0.28743743896484375
TIME Linear: 0.28717517852783203
Speed Up INT8 * INT8 -> FP16 (per tensor):36.09%
Speed Up INT8 * INT8 -> FP16 (per token):-10.59%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.96%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.46%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.09%
==========M=1416==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20227432250976562
TIME INT8 * INT8 -> FP16 (per token): 0.49026012420654297
TIME INT8 * INT8 -> FP16 (per channel) 0.32291412353515625
TIME INT8 * INT8 -> FP16 (per token per channel): 0.32465457916259766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3407478332519531
TIME INT8 * FP16 -> Fp16 (WI bias): 0.28553009033203125
TIME Linear: 0.3069639205932617
Speed Up INT8 * INT8 -> FP16 (per tensor):34.1%
Speed Up INT8 * INT8 -> FP16 (per token):-59.71%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.2%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.01%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.98%
==========M=1448==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20012855529785156
TIME INT8 * INT8 -> FP16 (per token): 0.3336668014526367
TIME INT8 * INT8 -> FP16 (per channel) 0.3288745880126953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.33147335052490234
TIME INT8 * FP16 -> Fp16 (WO bias): 0.34143924713134766
TIME INT8 * FP16 -> Fp16 (WI bias): 0.286102294921875
TIME Linear: 0.30694007873535156
Speed Up INT8 * INT8 -> FP16 (per tensor):34.8%
Speed Up INT8 * INT8 -> FP16 (per token):-8.71%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.15%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.99%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.24%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.79%
==========M=1480==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20101070404052734
TIME INT8 * INT8 -> FP16 (per token): 0.33721923828125
TIME INT8 * INT8 -> FP16 (per channel) 0.33583641052246094
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3363370895385742
TIME INT8 * FP16 -> Fp16 (WO bias): 0.42192935943603516
TIME INT8 * FP16 -> Fp16 (WI bias): 0.35605430603027344
TIME Linear: 0.3088712692260742
Speed Up INT8 * INT8 -> FP16 (per tensor):34.92%
Speed Up INT8 * INT8 -> FP16 (per token):-9.18%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-8.89%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.28%
==========M=1512==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20492076873779297
TIME INT8 * INT8 -> FP16 (per token): 0.3444671630859375
TIME INT8 * INT8 -> FP16 (per channel) 0.3422975540161133
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3442525863647461
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4252195358276367
TIME INT8 * FP16 -> Fp16 (WI bias): 0.36106109619140625
TIME Linear: 0.30672550201416016
Speed Up INT8 * INT8 -> FP16 (per tensor):33.19%
Speed Up INT8 * INT8 -> FP16 (per token):-12.3%
Speed Up INT8 * INT8 -> FP16 (per channel):-11.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-12.23%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-38.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-17.71%
==========M=1544==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2059459686279297
TIME INT8 * INT8 -> FP16 (per token): 0.34966468811035156
TIME INT8 * INT8 -> FP16 (per channel) 0.3488779067993164
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3500938415527344
TIME INT8 * FP16 -> Fp16 (WO bias): 0.36704540252685547
TIME INT8 * FP16 -> Fp16 (WI bias): 0.30388832092285156
TIME Linear: 0.32324790954589844
Speed Up INT8 * INT8 -> FP16 (per tensor):36.29%
Speed Up INT8 * INT8 -> FP16 (per token):-8.17%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-8.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-13.55%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.99%
==========M=1576==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20780563354492188
TIME INT8 * INT8 -> FP16 (per token): 0.3565788269042969
TIME INT8 * INT8 -> FP16 (per channel) 0.35538673400878906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.35750865936279297
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3706216812133789
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3041505813598633
TIME Linear: 0.3238677978515625
Speed Up INT8 * INT8 -> FP16 (per tensor):35.84%
Speed Up INT8 * INT8 -> FP16 (per token):-10.1%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.39%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.44%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.09%
==========M=1608==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20363330841064453
TIME INT8 * INT8 -> FP16 (per token): 0.3629446029663086
TIME INT8 * INT8 -> FP16 (per channel) 0.3596782684326172
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3622770309448242
TIME INT8 * FP16 -> Fp16 (WO bias): 0.36988258361816406
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3079414367675781
TIME Linear: 0.3336906433105469
Speed Up INT8 * INT8 -> FP16 (per tensor):38.98%
Speed Up INT8 * INT8 -> FP16 (per token):-8.77%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-8.57%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-10.85%
Speed Up INT8 * FP16 -> Fp16 (WI bias):7.72%
==========M=1640==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2042531967163086
TIME INT8 * INT8 -> FP16 (per token): 0.5353689193725586
TIME INT8 * INT8 -> FP16 (per channel) 0.3667593002319336
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3724336624145508
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3741025924682617
TIME INT8 * FP16 -> Fp16 (WI bias): 0.30357837677001953
TIME Linear: 0.3248929977416992
Speed Up INT8 * INT8 -> FP16 (per tensor):37.13%
Speed Up INT8 * INT8 -> FP16 (per token):-64.78%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.15%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.56%
==========M=1672==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.20804405212402344
TIME INT8 * INT8 -> FP16 (per token): 0.37560462951660156
TIME INT8 * INT8 -> FP16 (per channel) 0.3726482391357422
TIME INT8 * INT8 -> FP16 (per token per channel): 0.37534236907958984
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3870964050292969
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3235340118408203
TIME Linear: 0.34415721893310547
Speed Up INT8 * INT8 -> FP16 (per tensor):39.55%
Speed Up INT8 * INT8 -> FP16 (per token):-9.14%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.28%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.06%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-12.48%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.99%
==========M=1704==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2090930938720703
TIME INT8 * INT8 -> FP16 (per token): 0.3818511962890625
TIME INT8 * INT8 -> FP16 (per channel) 0.3822803497314453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.38208961486816406
TIME INT8 * FP16 -> Fp16 (WO bias): 0.38979053497314453
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3239154815673828
TIME Linear: 0.34332275390625
Speed Up INT8 * INT8 -> FP16 (per tensor):39.1%
Speed Up INT8 * INT8 -> FP16 (per token):-11.22%
Speed Up INT8 * INT8 -> FP16 (per channel):-11.35%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.29%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-13.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.65%
==========M=1736==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.24349689483642578
TIME INT8 * INT8 -> FP16 (per token): 0.3847837448120117
TIME INT8 * INT8 -> FP16 (per channel) 0.3795146942138672
TIME INT8 * INT8 -> FP16 (per token per channel): 0.38902759552001953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.46668052673339844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.39458274841308594
TIME Linear: 0.3462791442871094
Speed Up INT8 * INT8 -> FP16 (per tensor):29.68%
Speed Up INT8 * INT8 -> FP16 (per token):-11.12%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-12.35%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-34.77%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.95%
==========M=1768==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.244140625
TIME INT8 * INT8 -> FP16 (per token): 0.3918886184692383
TIME INT8 * INT8 -> FP16 (per channel) 0.38635730743408203
TIME INT8 * INT8 -> FP16 (per token per channel): 0.39124488830566406
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5753278732299805
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4984617233276367
TIME Linear: 0.34432411193847656
Speed Up INT8 * INT8 -> FP16 (per tensor):29.1%
Speed Up INT8 * INT8 -> FP16 (per token):-13.81%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.21%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-67.09%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-44.77%
==========M=1800==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2538442611694336
TIME INT8 * INT8 -> FP16 (per token): 0.3983497619628906
TIME INT8 * INT8 -> FP16 (per channel) 0.3925800323486328
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3984689712524414
TIME INT8 * FP16 -> Fp16 (WO bias): 0.45533180236816406
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3857612609863281
TIME Linear: 0.36046504974365234
Speed Up INT8 * INT8 -> FP16 (per tensor):29.58%
Speed Up INT8 * INT8 -> FP16 (per token):-10.51%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.91%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.54%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.32%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-7.02%
==========M=1832==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2551078796386719
TIME INT8 * INT8 -> FP16 (per token): 0.4055976867675781
TIME INT8 * INT8 -> FP16 (per channel) 0.399017333984375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4052877426147461
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4564523696899414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3866434097290039
TIME Linear: 0.36170482635498047
Speed Up INT8 * INT8 -> FP16 (per tensor):29.47%
Speed Up INT8 * INT8 -> FP16 (per token):-12.13%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.32%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-12.05%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.19%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.89%
==========M=1864==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2573966979980469
TIME INT8 * INT8 -> FP16 (per token): 0.41327476501464844
TIME INT8 * INT8 -> FP16 (per channel) 0.40640830993652344
TIME INT8 * INT8 -> FP16 (per token per channel): 0.41174888610839844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4193305969238281
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3437042236328125
TIME Linear: 0.3623485565185547
Speed Up INT8 * INT8 -> FP16 (per tensor):28.96%
Speed Up INT8 * INT8 -> FP16 (per token):-14.05%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.16%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.73%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.15%
==========M=1896==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2583742141723633
TIME INT8 * INT8 -> FP16 (per token): 0.4202842712402344
TIME INT8 * INT8 -> FP16 (per channel) 0.4193544387817383
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4199028015136719
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4212379455566406
TIME INT8 * FP16 -> Fp16 (WI bias): 0.34329891204833984
TIME Linear: 0.36394596099853516
Speed Up INT8 * INT8 -> FP16 (per tensor):29.01%
Speed Up INT8 * INT8 -> FP16 (per token):-15.48%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.74%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.67%
==========M=1928==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2691030502319336
TIME INT8 * INT8 -> FP16 (per token): 0.42488574981689453
TIME INT8 * INT8 -> FP16 (per channel) 0.4197120666503906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.42726993560791016
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6367206573486328
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5548238754272461
TIME Linear: 0.3850221633911133
Speed Up INT8 * INT8 -> FP16 (per tensor):30.11%
Speed Up INT8 * INT8 -> FP16 (per token):-10.35%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.01%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.97%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-65.37%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-44.1%
==========M=1960==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2709388732910156
TIME INT8 * INT8 -> FP16 (per token): 0.4308938980102539
TIME INT8 * INT8 -> FP16 (per channel) 0.4265785217285156
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4335641860961914
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6391048431396484
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5554914474487305
TIME Linear: 0.3792285919189453
Speed Up INT8 * INT8 -> FP16 (per tensor):28.56%
Speed Up INT8 * INT8 -> FP16 (per token):-13.62%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-68.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-46.48%
==========M=1992==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27463436126708984
TIME INT8 * INT8 -> FP16 (per token): 0.4369020462036133
TIME INT8 * INT8 -> FP16 (per channel) 0.4315614700317383
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4370689392089844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6409168243408203
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5560398101806641
TIME Linear: 0.3803253173828125
Speed Up INT8 * INT8 -> FP16 (per tensor):27.79%
Speed Up INT8 * INT8 -> FP16 (per token):-14.88%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.47%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.92%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-68.52%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-46.2%
==========M=2024==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27451515197753906
TIME INT8 * INT8 -> FP16 (per token): 0.44269561767578125
TIME INT8 * INT8 -> FP16 (per channel) 0.4372596740722656
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4428863525390625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6559610366821289
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5605220794677734
TIME Linear: 0.3819465637207031
Speed Up INT8 * INT8 -> FP16 (per tensor):28.13%
Speed Up INT8 * INT8 -> FP16 (per token):-15.91%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.48%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-71.74%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-46.75%
==========M=2056==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2810955047607422
TIME INT8 * INT8 -> FP16 (per token): 0.4491090774536133
TIME INT8 * INT8 -> FP16 (per channel) 0.4444599151611328
TIME INT8 * INT8 -> FP16 (per token per channel): 0.44968128204345703
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4721403121948242
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3943443298339844
TIME Linear: 0.4113197326660156
Speed Up INT8 * INT8 -> FP16 (per tensor):31.66%
Speed Up INT8 * INT8 -> FP16 (per token):-9.19%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.13%
==========M=2088==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.28884410858154297
TIME INT8 * INT8 -> FP16 (per token): 0.4569053649902344
TIME INT8 * INT8 -> FP16 (per channel) 0.45130252838134766
TIME INT8 * INT8 -> FP16 (per token per channel): 0.45731067657470703
TIME INT8 * FP16 -> Fp16 (WO bias): 0.47392845153808594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.39577484130859375
TIME Linear: 0.41196346282958984
Speed Up INT8 * INT8 -> FP16 (per tensor):29.89%
Speed Up INT8 * INT8 -> FP16 (per token):-10.91%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.04%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.93%
==========M=2120==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27091503143310547
TIME INT8 * INT8 -> FP16 (per token): 0.46226978302001953
TIME INT8 * INT8 -> FP16 (per channel) 0.4558563232421875
TIME INT8 * INT8 -> FP16 (per token per channel): 0.46193599700927734
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5851030349731445
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4912376403808594
TIME Linear: 0.4129171371459961
Speed Up INT8 * INT8 -> FP16 (per tensor):34.39%
Speed Up INT8 * INT8 -> FP16 (per token):-11.95%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.4%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.87%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-41.7%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.97%
==========M=2152==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2704143524169922
TIME INT8 * INT8 -> FP16 (per token): 0.46977996826171875
TIME INT8 * INT8 -> FP16 (per channel) 0.4702568054199219
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4704475402832031
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5879878997802734
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4917621612548828
TIME Linear: 0.4135608673095703
Speed Up INT8 * INT8 -> FP16 (per tensor):34.61%
Speed Up INT8 * INT8 -> FP16 (per token):-13.59%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.71%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-42.18%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.91%
==========M=2184==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2797126770019531
TIME INT8 * INT8 -> FP16 (per token): 0.4757881164550781
TIME INT8 * INT8 -> FP16 (per channel) 0.4764080047607422
TIME INT8 * INT8 -> FP16 (per token per channel): 0.47631263732910156
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4847526550292969
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3957033157348633
TIME Linear: 0.4315614700317383
Speed Up INT8 * INT8 -> FP16 (per tensor):35.19%
Speed Up INT8 * INT8 -> FP16 (per token):-10.25%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.39%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.37%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-12.33%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.31%
==========M=2216==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27313232421875
TIME INT8 * INT8 -> FP16 (per token): 0.4816293716430664
TIME INT8 * INT8 -> FP16 (per channel) 0.48105716705322266
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4828929901123047
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4855155944824219
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3960132598876953
TIME Linear: 0.43201446533203125
Speed Up INT8 * INT8 -> FP16 (per tensor):36.78%
Speed Up INT8 * INT8 -> FP16 (per token):-11.48%
Speed Up INT8 * INT8 -> FP16 (per channel):-11.35%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.78%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-12.38%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.33%
==========M=2248==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27413368225097656
TIME INT8 * INT8 -> FP16 (per token): 0.4885673522949219
TIME INT8 * INT8 -> FP16 (per channel) 0.48744678497314453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.48928260803222656
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0244131088256836
TIME INT8 * FP16 -> Fp16 (WI bias): 0.918269157409668
TIME Linear: 0.43158531188964844
Speed Up INT8 * INT8 -> FP16 (per tensor):36.48%
Speed Up INT8 * INT8 -> FP16 (per token):-13.2%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.94%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.37%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-137.36%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-112.77%
==========M=2280==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2741813659667969
TIME INT8 * INT8 -> FP16 (per token): 0.49855709075927734
TIME INT8 * INT8 -> FP16 (per channel) 0.4975557327270508
TIME INT8 * INT8 -> FP16 (per token per channel): 0.49660205841064453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7897138595581055
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6801128387451172
TIME Linear: 0.4345417022705078
Speed Up INT8 * INT8 -> FP16 (per tensor):36.9%
Speed Up INT8 * INT8 -> FP16 (per token):-14.73%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.5%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.28%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-81.73%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-56.51%
==========M=2312==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.29189586639404297
TIME INT8 * INT8 -> FP16 (per token): 0.504302978515625
TIME INT8 * INT8 -> FP16 (per channel) 0.5031585693359375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5032539367675781
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5200386047363281
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4334688186645508
TIME Linear: 0.4510641098022461
Speed Up INT8 * INT8 -> FP16 (per tensor):35.29%
Speed Up INT8 * INT8 -> FP16 (per token):-11.8%
Speed Up INT8 * INT8 -> FP16 (per channel):-11.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.57%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.29%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.9%
==========M=2344==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2915620803833008
TIME INT8 * INT8 -> FP16 (per token): 0.5096435546875
TIME INT8 * INT8 -> FP16 (per channel) 0.5090475082397461
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5112171173095703
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5214452743530273
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4343986511230469
TIME Linear: 0.4506111145019531
Speed Up INT8 * INT8 -> FP16 (per tensor):35.3%
Speed Up INT8 * INT8 -> FP16 (per token):-13.1%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.45%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.72%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.6%
==========M=2376==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.29311180114746094
TIME INT8 * INT8 -> FP16 (per token): 0.5197525024414062
TIME INT8 * INT8 -> FP16 (per channel) 0.5159854888916016
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5174636840820312
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6231546401977539
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5247831344604492
TIME Linear: 0.4498481750488281
Speed Up INT8 * INT8 -> FP16 (per tensor):34.84%
Speed Up INT8 * INT8 -> FP16 (per token):-15.54%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.7%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.03%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-38.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-16.66%
==========M=2408==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2927064895629883
TIME INT8 * INT8 -> FP16 (per token): 0.5215167999267578
TIME INT8 * INT8 -> FP16 (per channel) 0.5204916000366211
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5221128463745117
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5379199981689453
TIME INT8 * FP16 -> Fp16 (WI bias): 0.44171810150146484
TIME Linear: 0.44944286346435547
Speed Up INT8 * INT8 -> FP16 (per tensor):34.87%
Speed Up INT8 * INT8 -> FP16 (per token):-16.04%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.81%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.17%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.72%
==========M=2440==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3308296203613281
TIME INT8 * INT8 -> FP16 (per token): 0.5288124084472656
TIME INT8 * INT8 -> FP16 (per channel) 0.5267620086669922
TIME INT8 * INT8 -> FP16 (per token per channel): 0.528407096862793
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5400657653808594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4430055618286133
TIME Linear: 0.4477977752685547
Speed Up INT8 * INT8 -> FP16 (per tensor):26.12%
Speed Up INT8 * INT8 -> FP16 (per token):-18.09%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.63%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.0%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.07%
==========M=2472==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3408670425415039
TIME INT8 * INT8 -> FP16 (per token): 0.5337715148925781
TIME INT8 * INT8 -> FP16 (per channel) 0.5324840545654297
TIME INT8 * INT8 -> FP16 (per token per channel): 0.534367561340332
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5408048629760742
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4420757293701172
TIME Linear: 0.44722557067871094
Speed Up INT8 * INT8 -> FP16 (per tensor):23.78%
Speed Up INT8 * INT8 -> FP16 (per token):-19.35%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.49%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.92%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.15%
==========M=2504==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3345489501953125
TIME INT8 * INT8 -> FP16 (per token): 0.5403041839599609
TIME INT8 * INT8 -> FP16 (per channel) 0.5397796630859375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5434036254882812
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5433797836303711
TIME INT8 * FP16 -> Fp16 (WI bias): 0.44243335723876953
TIME Linear: 0.4470348358154297
Speed Up INT8 * INT8 -> FP16 (per tensor):25.16%
Speed Up INT8 * INT8 -> FP16 (per token):-20.86%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.55%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.03%
==========M=2536==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3690481185913086
TIME INT8 * INT8 -> FP16 (per token): 0.5478858947753906
TIME INT8 * INT8 -> FP16 (per channel) 0.5449533462524414
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5477666854858398
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5447149276733398
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4426240921020508
TIME Linear: 0.44753551483154297
Speed Up INT8 * INT8 -> FP16 (per tensor):17.54%
Speed Up INT8 * INT8 -> FP16 (per token):-22.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-21.77%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.71%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.1%
==========M=2568==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.31960010528564453
TIME INT8 * INT8 -> FP16 (per token): 0.5541324615478516
TIME INT8 * INT8 -> FP16 (per channel) 0.553441047668457
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5578517913818359
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6728172302246094
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5632638931274414
TIME Linear: 0.48329830169677734
Speed Up INT8 * INT8 -> FP16 (per tensor):33.87%
Speed Up INT8 * INT8 -> FP16 (per token):-14.66%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-39.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-16.55%
==========M=2600==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.31778812408447266
TIME INT8 * INT8 -> FP16 (per token): 0.555419921875
TIME INT8 * INT8 -> FP16 (per channel) 0.5493402481079102
TIME INT8 * INT8 -> FP16 (per token per channel): 0.556492805480957
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8214712142944336
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7132053375244141
TIME Linear: 0.48427581787109375
Speed Up INT8 * INT8 -> FP16 (per tensor):34.38%
Speed Up INT8 * INT8 -> FP16 (per token):-14.69%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.44%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.91%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-69.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.27%
==========M=2632==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3178119659423828
TIME INT8 * INT8 -> FP16 (per token): 0.5630254745483398
TIME INT8 * INT8 -> FP16 (per channel) 0.5584716796875
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5650043487548828
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8249998092651367
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7148504257202148
TIME Linear: 0.4851818084716797
Speed Up INT8 * INT8 -> FP16 (per tensor):34.5%
Speed Up INT8 * INT8 -> FP16 (per token):-16.04%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.11%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.45%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-70.04%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.34%
==========M=2664==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3184080123901367
TIME INT8 * INT8 -> FP16 (per token): 0.5685567855834961
TIME INT8 * INT8 -> FP16 (per channel) 0.5621194839477539
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5709409713745117
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8287668228149414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7160663604736328
TIME Linear: 0.48623085021972656
Speed Up INT8 * INT8 -> FP16 (per tensor):34.52%
Speed Up INT8 * INT8 -> FP16 (per token):-16.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.42%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-70.45%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-47.27%
==========M=2696==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.33457279205322266
TIME INT8 * INT8 -> FP16 (per token): 0.5738973617553711
TIME INT8 * INT8 -> FP16 (per channel) 0.569462776184082
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5761384963989258
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6268024444580078
TIME INT8 * FP16 -> Fp16 (WI bias): 0.516510009765625
TIME Linear: 0.5138635635375977
Speed Up INT8 * INT8 -> FP16 (per tensor):34.89%
Speed Up INT8 * INT8 -> FP16 (per token):-11.68%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.82%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-12.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.98%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.52%
==========M=2728==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3346681594848633
TIME INT8 * INT8 -> FP16 (per token): 0.5867481231689453
TIME INT8 * INT8 -> FP16 (per channel) 0.5846738815307617
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5876779556274414
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6279706954956055
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5151748657226562
TIME Linear: 0.513768196105957
Speed Up INT8 * INT8 -> FP16 (per tensor):34.86%
Speed Up INT8 * INT8 -> FP16 (per token):-14.2%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.39%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.23%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.27%
==========M=2760==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.33593177795410156
TIME INT8 * INT8 -> FP16 (per token): 0.5955934524536133
TIME INT8 * INT8 -> FP16 (per channel) 0.5925655364990234
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5939483642578125
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7021427154541016
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5907535552978516
TIME Linear: 0.5130767822265625
Speed Up INT8 * INT8 -> FP16 (per tensor):34.53%
Speed Up INT8 * INT8 -> FP16 (per token):-16.08%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.85%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.14%
==========M=2792==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.33681392669677734
TIME INT8 * INT8 -> FP16 (per token): 0.5932807922363281
TIME INT8 * INT8 -> FP16 (per channel) 0.5878686904907227
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5965471267700195
TIME INT8 * FP16 -> Fp16 (WO bias): 0.751185417175293
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6281137466430664
TIME Linear: 0.5125999450683594
Speed Up INT8 * INT8 -> FP16 (per tensor):34.29%
Speed Up INT8 * INT8 -> FP16 (per token):-15.74%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.68%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-46.54%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-22.53%
==========M=2824==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.339508056640625
TIME INT8 * INT8 -> FP16 (per token): 0.6018877029418945
TIME INT8 * INT8 -> FP16 (per channel) 0.5939722061157227
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6009340286254883
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6222963333129883
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5106210708618164
TIME Linear: 0.5169868469238281
Speed Up INT8 * INT8 -> FP16 (per tensor):34.33%
Speed Up INT8 * INT8 -> FP16 (per token):-16.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.37%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.23%
==========M=2856==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3394126892089844
TIME INT8 * INT8 -> FP16 (per token): 0.6081819534301758
TIME INT8 * INT8 -> FP16 (per channel) 0.6017684936523438
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6070375442504883
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6234169006347656
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5101680755615234
TIME Linear: 0.5147695541381836
Speed Up INT8 * INT8 -> FP16 (per tensor):34.07%
Speed Up INT8 * INT8 -> FP16 (per token):-18.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.9%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.92%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.89%
==========M=2888==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.33996105194091797
TIME INT8 * INT8 -> FP16 (per token): 0.6139039993286133
TIME INT8 * INT8 -> FP16 (per channel) 0.6067037582397461
TIME INT8 * INT8 -> FP16 (per token per channel): 0.616908073425293
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7441997528076172
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6286859512329102
TIME Linear: 0.5143642425537109
Speed Up INT8 * INT8 -> FP16 (per tensor):33.91%
Speed Up INT8 * INT8 -> FP16 (per token):-19.35%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.95%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.94%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-44.68%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-22.23%
==========M=2920==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3472328186035156
TIME INT8 * INT8 -> FP16 (per token): 0.618433952331543
TIME INT8 * INT8 -> FP16 (per channel) 0.6140708923339844
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6220340728759766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6265163421630859
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5101680755615234
TIME Linear: 0.5147695541381836
Speed Up INT8 * INT8 -> FP16 (per tensor):32.55%
Speed Up INT8 * INT8 -> FP16 (per token):-20.14%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.84%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.71%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.89%
==========M=2952==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3673076629638672
TIME INT8 * INT8 -> FP16 (per token): 0.6318092346191406
TIME INT8 * INT8 -> FP16 (per channel) 0.6299257278442383
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6326913833618164
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6582498550415039
TIME INT8 * FP16 -> Fp16 (WI bias): 0.541234016418457
TIME Linear: 0.5563020706176758
Speed Up INT8 * INT8 -> FP16 (per tensor):33.97%
Speed Up INT8 * INT8 -> FP16 (per token):-13.57%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.73%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.33%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.71%
==========M=2984==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.36110877990722656
TIME INT8 * INT8 -> FP16 (per token): 0.6369352340698242
TIME INT8 * INT8 -> FP16 (per channel) 0.6371974945068359
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6382942199707031
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6519794464111328
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5425453186035156
TIME Linear: 0.5513191223144531
Speed Up INT8 * INT8 -> FP16 (per tensor):34.5%
Speed Up INT8 * INT8 -> FP16 (per token):-15.53%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.58%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.78%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.26%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.59%
==========M=3016==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3618955612182617
TIME INT8 * INT8 -> FP16 (per token): 0.6398677825927734
TIME INT8 * INT8 -> FP16 (per channel) 0.6338119506835938
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6437063217163086
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6947994232177734
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5718231201171875
TIME Linear: 0.5528688430786133
Speed Up INT8 * INT8 -> FP16 (per tensor):34.54%
Speed Up INT8 * INT8 -> FP16 (per token):-15.74%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.64%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.67%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.43%
==========M=3048==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3621339797973633
TIME INT8 * INT8 -> FP16 (per token): 0.6467819213867188
TIME INT8 * INT8 -> FP16 (per channel) 0.6380796432495117
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6478071212768555
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6959676742553711
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5708456039428711
TIME Linear: 0.5525588989257812
Speed Up INT8 * INT8 -> FP16 (per tensor):34.46%
Speed Up INT8 * INT8 -> FP16 (per token):-17.05%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.48%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.95%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.31%
==========M=3080==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3640890121459961
TIME INT8 * INT8 -> FP16 (per token): 0.6517648696899414
TIME INT8 * INT8 -> FP16 (per channel) 0.6454944610595703
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6536006927490234
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7376670837402344
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6244659423828125
TIME Linear: 0.5688905715942383
Speed Up INT8 * INT8 -> FP16 (per tensor):36.0%
Speed Up INT8 * INT8 -> FP16 (per token):-14.57%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.47%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.89%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.67%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.77%
==========M=3112==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3645658493041992
TIME INT8 * INT8 -> FP16 (per token): 0.6574153900146484
TIME INT8 * INT8 -> FP16 (per channel) 0.6529092788696289
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6598472595214844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7372140884399414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6254673004150391
TIME Linear: 0.5697488784790039
Speed Up INT8 * INT8 -> FP16 (per tensor):36.01%
Speed Up INT8 * INT8 -> FP16 (per token):-15.39%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.39%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.78%
==========M=3144==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3651857376098633
TIME INT8 * INT8 -> FP16 (per token): 0.6655216217041016
TIME INT8 * INT8 -> FP16 (per channel) 0.65765380859375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6676197052001953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6779193878173828
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5531787872314453
TIME Linear: 0.5683183670043945
Speed Up INT8 * INT8 -> FP16 (per tensor):35.74%
Speed Up INT8 * INT8 -> FP16 (per token):-17.1%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.72%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.47%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.29%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.66%
==========M=3176==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.36530494689941406
TIME INT8 * INT8 -> FP16 (per token): 0.6716012954711914
TIME INT8 * INT8 -> FP16 (per channel) 0.6624698638916016
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6717681884765625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6795883178710938
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5570888519287109
TIME Linear: 0.6564617156982422
Speed Up INT8 * INT8 -> FP16 (per tensor):44.35%
Speed Up INT8 * INT8 -> FP16 (per token):-2.31%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.52%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.14%
==========M=3208==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3826141357421875
TIME INT8 * INT8 -> FP16 (per token): 0.6766796112060547
TIME INT8 * INT8 -> FP16 (per channel) 0.6699800491333008
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6787776947021484
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8083581924438477
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6803274154663086
TIME Linear: 0.5806207656860352
Speed Up INT8 * INT8 -> FP16 (per tensor):34.1%
Speed Up INT8 * INT8 -> FP16 (per token):-16.54%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.39%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.91%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-39.22%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-17.17%
==========M=3240==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.38335323333740234
TIME INT8 * INT8 -> FP16 (per token): 0.6891489028930664
TIME INT8 * INT8 -> FP16 (per channel) 0.6875514984130859
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6898880004882812
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0052919387817383
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8733987808227539
TIME Linear: 0.5819559097290039
Speed Up INT8 * INT8 -> FP16 (per tensor):34.13%
Speed Up INT8 * INT8 -> FP16 (per token):-18.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-18.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.55%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-72.74%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-50.08%
==========M=3272==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.38390159606933594
TIME INT8 * INT8 -> FP16 (per token): 0.6963729858398438
TIME INT8 * INT8 -> FP16 (per channel) 0.6937980651855469
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8142709732055664
TIME INT8 * FP16 -> Fp16 (WO bias): 1.009225845336914
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8746623992919922
TIME Linear: 0.5814552307128906
Speed Up INT8 * INT8 -> FP16 (per tensor):33.98%
Speed Up INT8 * INT8 -> FP16 (per token):-19.76%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.32%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-40.04%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-73.57%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-50.43%
==========M=3304==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.38444995880126953
TIME INT8 * INT8 -> FP16 (per token): 0.7017850875854492
TIME INT8 * INT8 -> FP16 (per channel) 0.7014989852905273
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7041215896606445
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0129690170288086
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8759021759033203
TIME Linear: 0.5813360214233398
Speed Up INT8 * INT8 -> FP16 (per tensor):33.87%
Speed Up INT8 * INT8 -> FP16 (per token):-20.72%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.67%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-74.25%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-50.67%
==========M=3336==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3890037536621094
TIME INT8 * INT8 -> FP16 (per token): 0.7111549377441406
TIME INT8 * INT8 -> FP16 (per channel) 0.7061958312988281
TIME INT8 * INT8 -> FP16 (per token per channel): 0.710749626159668
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7927417755126953
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6710529327392578
TIME Linear: 0.5899190902709961
Speed Up INT8 * INT8 -> FP16 (per tensor):34.06%
Speed Up INT8 * INT8 -> FP16 (per token):-20.55%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.71%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-34.38%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.75%
==========M=3368==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3881216049194336
TIME INT8 * INT8 -> FP16 (per token): 0.716853141784668
TIME INT8 * INT8 -> FP16 (per channel) 0.7138252258300781
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7175922393798828
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7935047149658203
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6710052490234375
TIME Linear: 0.5968093872070312
Speed Up INT8 * INT8 -> FP16 (per tensor):34.97%
Speed Up INT8 * INT8 -> FP16 (per token):-20.11%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-32.96%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-12.43%
==========M=3400==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.38776397705078125
TIME INT8 * INT8 -> FP16 (per token): 0.7233858108520508
TIME INT8 * INT8 -> FP16 (per channel) 0.7207393646240234
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7250070571899414
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7972240447998047
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6716012954711914
TIME Linear: 0.5884170532226562
Speed Up INT8 * INT8 -> FP16 (per tensor):34.1%
Speed Up INT8 * INT8 -> FP16 (per token):-22.94%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.21%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-35.49%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.14%
==========M=3432==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3900289535522461
TIME INT8 * INT8 -> FP16 (per token): 0.7381677627563477
TIME INT8 * INT8 -> FP16 (per channel) 0.7336616516113281
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7333993911743164
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7957935333251953
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6719350814819336
TIME Linear: 0.5889415740966797
Speed Up INT8 * INT8 -> FP16 (per tensor):33.77%
Speed Up INT8 * INT8 -> FP16 (per token):-25.34%
Speed Up INT8 * INT8 -> FP16 (per channel):-24.57%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-24.53%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-35.12%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.09%
==========M=3464==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.42312145233154297
TIME INT8 * INT8 -> FP16 (per token): 0.730443000793457
TIME INT8 * INT8 -> FP16 (per channel) 0.723576545715332
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7346153259277344
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7419586181640625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6065607070922852
TIME Linear: 0.6369829177856445
Speed Up INT8 * INT8 -> FP16 (per tensor):33.57%
Speed Up INT8 * INT8 -> FP16 (per token):-14.67%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.48%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.78%
==========M=3496==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.42481422424316406
TIME INT8 * INT8 -> FP16 (per token): 0.7357120513916016
TIME INT8 * INT8 -> FP16 (per channel) 0.7288217544555664
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7403850555419922
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7445335388183594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6079435348510742
TIME Linear: 0.6460428237915039
Speed Up INT8 * INT8 -> FP16 (per tensor):34.24%
Speed Up INT8 * INT8 -> FP16 (per token):-13.88%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.81%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.6%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.25%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.9%
==========M=3528==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.41713714599609375
TIME INT8 * INT8 -> FP16 (per token): 0.7401227951049805
TIME INT8 * INT8 -> FP16 (per channel) 0.7336139678955078
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7447242736816406
TIME INT8 * FP16 -> Fp16 (WO bias): 0.901031494140625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7606983184814453
TIME Linear: 0.7325887680053711
Speed Up INT8 * INT8 -> FP16 (per tensor):43.06%
Speed Up INT8 * INT8 -> FP16 (per token):-1.03%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.66%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.99%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.84%
==========M=3560==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4086732864379883
TIME INT8 * INT8 -> FP16 (per token): 0.7476568222045898
TIME INT8 * INT8 -> FP16 (per channel) 0.7396936416625977
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7500171661376953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8362531661987305
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7067441940307617
TIME Linear: 0.7331609725952148
Speed Up INT8 * INT8 -> FP16 (per tensor):44.26%
Speed Up INT8 * INT8 -> FP16 (per token):-1.98%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.06%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.6%
==========M=3592==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.42743682861328125
TIME INT8 * INT8 -> FP16 (per token): 0.7567644119262695
TIME INT8 * INT8 -> FP16 (per channel) 0.74615478515625
TIME INT8 * INT8 -> FP16 (per token per channel): 0.75836181640625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7831096649169922
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6522893905639648
TIME Linear: 0.6543874740600586
Speed Up INT8 * INT8 -> FP16 (per tensor):34.68%
Speed Up INT8 * INT8 -> FP16 (per token):-15.64%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.89%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.67%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.32%
==========M=3624==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4271507263183594
TIME INT8 * INT8 -> FP16 (per token): 0.7691383361816406
TIME INT8 * INT8 -> FP16 (per channel) 0.7677316665649414
TIME INT8 * INT8 -> FP16 (per token per channel): 0.77056884765625
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7848262786865234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6526470184326172
TIME Linear: 0.6543397903442383
Speed Up INT8 * INT8 -> FP16 (per tensor):34.72%
Speed Up INT8 * INT8 -> FP16 (per token):-17.54%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.33%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.76%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.94%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.26%
==========M=3656==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.43616294860839844
TIME INT8 * INT8 -> FP16 (per token): 0.7664680480957031
TIME INT8 * INT8 -> FP16 (per channel) 0.7588624954223633
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7697105407714844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8332490921020508
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6822109222412109
TIME Linear: 0.6529569625854492
Speed Up INT8 * INT8 -> FP16 (per tensor):33.2%
Speed Up INT8 * INT8 -> FP16 (per token):-17.38%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-27.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-4.48%
==========M=3688==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.43637752532958984
TIME INT8 * INT8 -> FP16 (per token): 0.7739782333374023
TIME INT8 * INT8 -> FP16 (per channel) 0.7645845413208008
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7756233215332031
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8313894271850586
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6810188293457031
TIME Linear: 0.6559610366821289
Speed Up INT8 * INT8 -> FP16 (per tensor):33.48%
Speed Up INT8 * INT8 -> FP16 (per token):-17.99%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.56%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-26.74%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.82%
==========M=3720==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.43964385986328125
TIME INT8 * INT8 -> FP16 (per token): 0.7812023162841797
TIME INT8 * INT8 -> FP16 (per channel) 0.7733345031738281
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7837772369384766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7930517196655273
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6500482559204102
TIME Linear: 0.6540298461914062
Speed Up INT8 * INT8 -> FP16 (per tensor):32.78%
Speed Up INT8 * INT8 -> FP16 (per token):-19.44%
Speed Up INT8 * INT8 -> FP16 (per channel):-18.24%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.84%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.26%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.61%
==========M=3752==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.44035911560058594
TIME INT8 * INT8 -> FP16 (per token): 0.7867336273193359
TIME INT8 * INT8 -> FP16 (per channel) 0.776982307434082
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7887363433837891
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7944822311401367
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6485939025878906
TIME Linear: 0.6527423858642578
Speed Up INT8 * INT8 -> FP16 (per tensor):32.54%
Speed Up INT8 * INT8 -> FP16 (per token):-20.53%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.83%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.71%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.64%
==========M=3784==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4406929016113281
TIME INT8 * INT8 -> FP16 (per token): 0.8048057556152344
TIME INT8 * INT8 -> FP16 (per channel) 0.7997751235961914
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8040666580200195
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7961034774780273
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6496667861938477
TIME Linear: 0.6555318832397461
Speed Up INT8 * INT8 -> FP16 (per tensor):32.77%
Speed Up INT8 * INT8 -> FP16 (per token):-22.77%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.0%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.66%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.44%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.89%
==========M=3816==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4405975341796875
TIME INT8 * INT8 -> FP16 (per token): 0.809025764465332
TIME INT8 * INT8 -> FP16 (per channel) 0.8051872253417969
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8085727691650391
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7967710494995117
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6484508514404297
TIME Linear: 0.6517648696899414
Speed Up INT8 * INT8 -> FP16 (per tensor):32.4%
Speed Up INT8 * INT8 -> FP16 (per token):-24.13%
Speed Up INT8 * INT8 -> FP16 (per channel):-23.54%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-24.06%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.25%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.51%
==========M=3848==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.45180320739746094
TIME INT8 * INT8 -> FP16 (per token): 0.8210659027099609
TIME INT8 * INT8 -> FP16 (per channel) 0.8133888244628906
TIME INT8 * INT8 -> FP16 (per token per channel): 0.818634033203125
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9611129760742188
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8070468902587891
TIME Linear: 0.6943941116333008
Speed Up INT8 * INT8 -> FP16 (per tensor):34.94%
Speed Up INT8 * INT8 -> FP16 (per token):-18.24%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.89%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-38.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-16.22%
==========M=3880==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.45239925384521484
TIME INT8 * INT8 -> FP16 (per token): 0.8133172988891602
TIME INT8 * INT8 -> FP16 (per channel) 0.8055686950683594
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8212804794311523
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1914253234863281
TIME INT8 * FP16 -> Fp16 (WI bias): 1.035141944885254
TIME Linear: 0.6982088088989258
Speed Up INT8 * INT8 -> FP16 (per tensor):35.21%
Speed Up INT8 * INT8 -> FP16 (per token):-16.49%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.38%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-70.64%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-48.26%
==========M=3912==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4538297653198242
TIME INT8 * INT8 -> FP16 (per token): 0.8222103118896484
TIME INT8 * INT8 -> FP16 (per channel) 0.8106231689453125
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8225202560424805
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0313987731933594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8640766143798828
TIME Linear: 0.6972074508666992
Speed Up INT8 * INT8 -> FP16 (per tensor):34.91%
Speed Up INT8 * INT8 -> FP16 (per token):-17.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.27%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-17.97%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-47.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-23.93%
==========M=3944==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4630565643310547
TIME INT8 * INT8 -> FP16 (per token): 0.8261442184448242
TIME INT8 * INT8 -> FP16 (per channel) 0.8179664611816406
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8292198181152344
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0302305221557617
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8638143539428711
TIME Linear: 0.6975412368774414
Speed Up INT8 * INT8 -> FP16 (per tensor):33.62%
Speed Up INT8 * INT8 -> FP16 (per token):-18.44%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.26%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-47.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-23.84%
==========M=3976==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4647254943847656
TIME INT8 * INT8 -> FP16 (per token): 0.835728645324707
TIME INT8 * INT8 -> FP16 (per channel) 0.8267641067504883
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8381843566894531
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9367704391479492
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7887840270996094
TIME Linear: 0.7307529449462891
Speed Up INT8 * INT8 -> FP16 (per tensor):36.4%
Speed Up INT8 * INT8 -> FP16 (per token):-14.37%
Speed Up INT8 * INT8 -> FP16 (per channel):-13.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.7%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-28.19%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-7.94%
==========M=4008==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46808719635009766
TIME INT8 * INT8 -> FP16 (per token): 0.8456707000732422
TIME INT8 * INT8 -> FP16 (per channel) 0.8335351943969727
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8446455001831055
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9382247924804688
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7904767990112305
TIME Linear: 0.7269144058227539
Speed Up INT8 * INT8 -> FP16 (per tensor):35.61%
Speed Up INT8 * INT8 -> FP16 (per token):-16.34%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.67%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.2%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.07%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-8.74%
==========M=4040==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46660900115966797
TIME INT8 * INT8 -> FP16 (per token): 0.8459329605102539
TIME INT8 * INT8 -> FP16 (per channel) 0.8368492126464844
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8489131927490234
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9325981140136719
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7881641387939453
TIME Linear: 0.7177829742431641
Speed Up INT8 * INT8 -> FP16 (per tensor):34.99%
Speed Up INT8 * INT8 -> FP16 (per token):-17.85%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.27%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.81%
==========M=4072==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46694278717041016
TIME INT8 * INT8 -> FP16 (per token): 0.8630514144897461
TIME INT8 * INT8 -> FP16 (per channel) 0.8606433868408203
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8645534515380859
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9351253509521484
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7883548736572266
TIME Linear: 0.7189035415649414
Speed Up INT8 * INT8 -> FP16 (per tensor):35.05%
Speed Up INT8 * INT8 -> FP16 (per token):-20.05%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.72%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.26%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-30.08%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-9.66%
==========M=4104==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4839658737182617
TIME INT8 * INT8 -> FP16 (per token): 0.857996940612793
TIME INT8 * INT8 -> FP16 (per channel) 0.8516550064086914
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8615493774414062
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1353731155395508
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9648323059082031
TIME Linear: 0.7222652435302734
Speed Up INT8 * INT8 -> FP16 (per tensor):32.99%
Speed Up INT8 * INT8 -> FP16 (per token):-18.79%
Speed Up INT8 * INT8 -> FP16 (per channel):-17.91%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.28%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-57.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-33.58%
==========M=4136==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4853487014770508
TIME INT8 * INT8 -> FP16 (per token): 0.8645772933959961
TIME INT8 * INT8 -> FP16 (per channel) 0.8564233779907227
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8679866790771484
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8773565292358398
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7174015045166016
TIME Linear: 0.7229089736938477
Speed Up INT8 * INT8 -> FP16 (per tensor):32.86%
Speed Up INT8 * INT8 -> FP16 (per token):-19.6%
Speed Up INT8 * INT8 -> FP16 (per channel):-18.47%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.07%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.36%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.76%
==========M=4168==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.48558712005615234
TIME INT8 * INT8 -> FP16 (per token): 0.8716344833374023
TIME INT8 * INT8 -> FP16 (per channel) 0.8641958236694336
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8735179901123047
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8783578872680664
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7170677185058594
TIME Linear: 0.7234573364257812
Speed Up INT8 * INT8 -> FP16 (per tensor):32.88%
Speed Up INT8 * INT8 -> FP16 (per token):-20.48%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.45%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.74%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.88%
==========M=4200==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.48558712005615234
TIME INT8 * INT8 -> FP16 (per token): 0.876164436340332
TIME INT8 * INT8 -> FP16 (per channel) 0.8690595626831055
TIME INT8 * INT8 -> FP16 (per token per channel): 0.879979133605957
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8795976638793945
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7174968719482422
TIME Linear: 0.7237911224365234
Speed Up INT8 * INT8 -> FP16 (per tensor):32.91%
Speed Up INT8 * INT8 -> FP16 (per token):-21.05%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.07%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.58%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.87%
==========M=4232==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5046844482421875
TIME INT8 * INT8 -> FP16 (per token): 0.8853673934936523
TIME INT8 * INT8 -> FP16 (per channel) 0.8766651153564453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8868932723999023
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9140729904174805
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7619857788085938
TIME Linear: 0.7594585418701172
Speed Up INT8 * INT8 -> FP16 (per tensor):33.55%
Speed Up INT8 * INT8 -> FP16 (per token):-16.58%
Speed Up INT8 * INT8 -> FP16 (per channel):-15.43%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-16.78%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-20.36%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.33%
==========M=4264==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5048274993896484
TIME INT8 * INT8 -> FP16 (per token): 0.8931398391723633
TIME INT8 * INT8 -> FP16 (per channel) 0.8840084075927734
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8979320526123047
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9164810180664062
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7627248764038086
TIME Linear: 0.8865594863891602
Speed Up INT8 * INT8 -> FP16 (per tensor):43.06%
Speed Up INT8 * INT8 -> FP16 (per token):-0.74%
Speed Up INT8 * INT8 -> FP16 (per channel):0.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.28%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.38%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.97%
==========M=4296==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5050897598266602
TIME INT8 * INT8 -> FP16 (per token): 0.9098291397094727
TIME INT8 * INT8 -> FP16 (per channel) 0.9067296981811523
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9110689163208008
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0715484619140625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8997201919555664
TIME Linear: 0.8812904357910156
Speed Up INT8 * INT8 -> FP16 (per tensor):42.69%
Speed Up INT8 * INT8 -> FP16 (per token):-3.24%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.59%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.09%
==========M=4328==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5054473876953125
TIME INT8 * INT8 -> FP16 (per token): 0.9174823760986328
TIME INT8 * INT8 -> FP16 (per channel) 0.9130716323852539
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9181022644042969
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9678363800048828
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7928848266601562
TIME Linear: 0.8794069290161133
Speed Up INT8 * INT8 -> FP16 (per tensor):42.52%
Speed Up INT8 * INT8 -> FP16 (per token):-4.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.83%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-10.06%
Speed Up INT8 * FP16 -> Fp16 (WI bias):9.84%
==========M=4360==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5102396011352539
TIME INT8 * INT8 -> FP16 (per token): 0.9279489517211914
TIME INT8 * INT8 -> FP16 (per channel) 0.9217500686645508
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9277820587158203
TIME INT8 * FP16 -> Fp16 (WO bias): 1.9270658493041992
TIME INT8 * FP16 -> Fp16 (WI bias): 1.724863052368164
TIME Linear: 0.8587360382080078
Speed Up INT8 * INT8 -> FP16 (per tensor):40.58%
Speed Up INT8 * INT8 -> FP16 (per token):-8.06%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.34%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-8.04%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-124.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-100.86%
==========M=4392==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.48673152923583984
TIME INT8 * INT8 -> FP16 (per token): 0.8931398391723633
TIME INT8 * INT8 -> FP16 (per channel) 0.8836507797241211
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8877038955688477
TIME INT8 * FP16 -> Fp16 (WO bias): 1.8540143966674805
TIME INT8 * FP16 -> Fp16 (WI bias): 1.6587018966674805
TIME Linear: 0.8219480514526367
Speed Up INT8 * INT8 -> FP16 (per tensor):40.78%
Speed Up INT8 * INT8 -> FP16 (per token):-8.66%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-8.0%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-125.56%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-101.8%
==========M=4424==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4651308059692383
TIME INT8 * INT8 -> FP16 (per token): 0.8551359176635742
TIME INT8 * INT8 -> FP16 (per channel) 0.8487939834594727
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8537530899047852
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7848730087280273
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5978574752807617
TIME Linear: 0.8232593536376953
Speed Up INT8 * INT8 -> FP16 (per tensor):43.5%
Speed Up INT8 * INT8 -> FP16 (per token):-3.87%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.1%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.7%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-116.81%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-94.09%
==========M=4456==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46539306640625
TIME INT8 * INT8 -> FP16 (per token): 0.8730649948120117
TIME INT8 * INT8 -> FP16 (per channel) 0.8693933486938477
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8702278137207031
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7921209335327148
TIME INT8 * FP16 -> Fp16 (WI bias): 1.6019821166992188
TIME Linear: 0.9073972702026367
Speed Up INT8 * INT8 -> FP16 (per tensor):48.71%
Speed Up INT8 * INT8 -> FP16 (per token):3.78%
Speed Up INT8 * INT8 -> FP16 (per channel):4.19%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-97.5%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-76.55%
==========M=4488==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5296230316162109
TIME INT8 * INT8 -> FP16 (per token): 0.9500741958618164
TIME INT8 * INT8 -> FP16 (per channel) 0.9466409683227539
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9517431259155273
TIME INT8 * FP16 -> Fp16 (WO bias): 1.114034652709961
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9363412857055664
TIME Linear: 0.7895708084106445
Speed Up INT8 * INT8 -> FP16 (per tensor):32.92%
Speed Up INT8 * INT8 -> FP16 (per token):-20.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.54%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-41.09%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.59%
==========M=4520==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5299806594848633
TIME INT8 * INT8 -> FP16 (per token): 0.9478569030761719
TIME INT8 * INT8 -> FP16 (per channel) 0.9345054626464844
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9481668472290039
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3905525207519531
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2098073959350586
TIME Linear: 0.7873058319091797
Speed Up INT8 * INT8 -> FP16 (per tensor):32.68%
Speed Up INT8 * INT8 -> FP16 (per token):-20.39%
Speed Up INT8 * INT8 -> FP16 (per channel):-18.7%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-76.62%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-53.66%
==========M=4552==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.530242919921875
TIME INT8 * INT8 -> FP16 (per token): 0.9511709213256836
TIME INT8 * INT8 -> FP16 (per channel) 0.9404897689819336
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9532690048217773
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1883735656738281
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9962797164916992
TIME Linear: 0.7877826690673828
Speed Up INT8 * INT8 -> FP16 (per tensor):32.69%
Speed Up INT8 * INT8 -> FP16 (per token):-20.74%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.38%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-50.85%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-26.47%
==========M=4584==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5319833755493164
TIME INT8 * INT8 -> FP16 (per token): 0.9712696075439453
TIME INT8 * INT8 -> FP16 (per channel) 0.9694099426269531
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9730100631713867
TIME INT8 * FP16 -> Fp16 (WO bias): 1.189732551574707
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9991645812988281
TIME Linear: 0.7880210876464844
Speed Up INT8 * INT8 -> FP16 (per tensor):32.49%
Speed Up INT8 * INT8 -> FP16 (per token):-23.25%
Speed Up INT8 * INT8 -> FP16 (per channel):-23.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-50.98%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-26.79%
==========M=4616==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5335330963134766
TIME INT8 * INT8 -> FP16 (per token): 0.9800910949707031
TIME INT8 * INT8 -> FP16 (per channel) 0.9769201278686523
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9808778762817383
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9673833847045898
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7881879806518555
TIME Linear: 0.9419679641723633
Speed Up INT8 * INT8 -> FP16 (per tensor):43.36%
Speed Up INT8 * INT8 -> FP16 (per token):-4.05%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.71%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.13%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.7%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.33%
==========M=4648==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5343914031982422
TIME INT8 * INT8 -> FP16 (per token): 0.993657112121582
TIME INT8 * INT8 -> FP16 (per channel) 0.9944915771484375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9944438934326172
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9700775146484375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7890224456787109
TIME Linear: 0.9420156478881836
Speed Up INT8 * INT8 -> FP16 (per tensor):43.27%
Speed Up INT8 * INT8 -> FP16 (per token):-5.48%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.57%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.57%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.98%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.24%
==========M=4680==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5350351333618164
TIME INT8 * INT8 -> FP16 (per token): 0.9909868240356445
TIME INT8 * INT8 -> FP16 (per channel) 0.9886264801025391
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9926319122314453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9725809097290039
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7877826690673828
TIME Linear: 0.9417533874511719
Speed Up INT8 * INT8 -> FP16 (per tensor):43.19%
Speed Up INT8 * INT8 -> FP16 (per token):-5.23%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.98%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.35%
==========M=4712==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5347013473510742
TIME INT8 * INT8 -> FP16 (per token): 0.9985208511352539
TIME INT8 * INT8 -> FP16 (per channel) 0.9954214096069336
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0006904602050781
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9717226028442383
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7882118225097656
TIME Linear: 0.9424448013305664
Speed Up INT8 * INT8 -> FP16 (per tensor):43.26%
Speed Up INT8 * INT8 -> FP16 (per token):-5.95%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.62%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.18%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.37%
==========M=4744==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5532979965209961
TIME INT8 * INT8 -> FP16 (per token): 0.9912014007568359
TIME INT8 * INT8 -> FP16 (per channel) 0.980687141418457
TIME INT8 * INT8 -> FP16 (per token per channel): 0.9919643402099609
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5180587768554688
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2874603271484375
TIME Linear: 0.972437858581543
Speed Up INT8 * INT8 -> FP16 (per tensor):43.1%
Speed Up INT8 * INT8 -> FP16 (per token):-1.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.85%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-56.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-32.4%
==========M=4776==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5540847778320312
TIME INT8 * INT8 -> FP16 (per token): 0.997614860534668
TIME INT8 * INT8 -> FP16 (per channel) 0.9872198104858398
TIME INT8 * INT8 -> FP16 (per token per channel): 0.99945068359375
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5187263488769531
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2882471084594727
TIME Linear: 0.9723186492919922
Speed Up INT8 * INT8 -> FP16 (per tensor):43.01%
Speed Up INT8 * INT8 -> FP16 (per token):-2.6%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.53%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-56.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-32.49%
==========M=4808==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5546331405639648
TIME INT8 * INT8 -> FP16 (per token): 1.0039806365966797
TIME INT8 * INT8 -> FP16 (per channel) 0.9933948516845703
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0065078735351562
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2123823165893555
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0243892669677734
TIME Linear: 0.9718179702758789
Speed Up INT8 * INT8 -> FP16 (per tensor):42.93%
Speed Up INT8 * INT8 -> FP16 (per token):-3.31%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.57%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.75%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.41%
==========M=4840==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5557060241699219
TIME INT8 * INT8 -> FP16 (per token): 1.0341405868530273
TIME INT8 * INT8 -> FP16 (per channel) 1.0333061218261719
TIME INT8 * INT8 -> FP16 (per token per channel): 1.033949851989746
TIME INT8 * FP16 -> Fp16 (WO bias): 1.116800308227539
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9463071823120117
TIME Linear: 0.9720325469970703
Speed Up INT8 * INT8 -> FP16 (per tensor):42.83%
Speed Up INT8 * INT8 -> FP16 (per token):-6.39%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.3%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.37%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.89%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.65%
==========M=4872==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5723714828491211
TIME INT8 * INT8 -> FP16 (per token): 1.031804084777832
TIME INT8 * INT8 -> FP16 (per channel) 1.0283470153808594
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0351896286010742
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0472774505615234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.876164436340332
TIME Linear: 0.8603096008300781
Speed Up INT8 * INT8 -> FP16 (per tensor):33.47%
Speed Up INT8 * INT8 -> FP16 (per token):-19.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.53%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.73%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.84%
==========M=4904==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5728483200073242
TIME INT8 * INT8 -> FP16 (per token): 1.0423898696899414
TIME INT8 * INT8 -> FP16 (per channel) 1.0359764099121094
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0421991348266602
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0504722595214844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8749723434448242
TIME Linear: 0.8591175079345703
Speed Up INT8 * INT8 -> FP16 (per tensor):33.32%
Speed Up INT8 * INT8 -> FP16 (per token):-21.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.85%
==========M=4936==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5741357803344727
TIME INT8 * INT8 -> FP16 (per token): 1.0463953018188477
TIME INT8 * INT8 -> FP16 (per channel) 1.041102409362793
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0478734970092773
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2216567993164062
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0273456573486328
TIME Linear: 0.8577585220336914
Speed Up INT8 * INT8 -> FP16 (per tensor):33.07%
Speed Up INT8 * INT8 -> FP16 (per token):-21.99%
Speed Up INT8 * INT8 -> FP16 (per channel):-21.37%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-42.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-19.77%
==========M=4968==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5741596221923828
TIME INT8 * INT8 -> FP16 (per token): 1.0567903518676758
TIME INT8 * INT8 -> FP16 (per channel) 1.0489225387573242
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0544776916503906
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1029720306396484
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9055852890014648
TIME Linear: 0.8569240570068359
Speed Up INT8 * INT8 -> FP16 (per tensor):33.0%
Speed Up INT8 * INT8 -> FP16 (per token):-23.32%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.41%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.05%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-28.71%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.68%
==========M=5000==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5774259567260742
TIME INT8 * INT8 -> FP16 (per token): 1.0654926300048828
TIME INT8 * INT8 -> FP16 (per channel) 1.0552167892456055
TIME INT8 * INT8 -> FP16 (per token per channel): 1.060628890991211
TIME INT8 * FP16 -> Fp16 (WO bias): 1.049041748046875
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8561134338378906
TIME Linear: 0.8596181869506836
Speed Up INT8 * INT8 -> FP16 (per tensor):32.83%
Speed Up INT8 * INT8 -> FP16 (per token):-23.95%
Speed Up INT8 * INT8 -> FP16 (per channel):-22.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-23.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.04%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.41%
==========M=5032==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5776643753051758
TIME INT8 * INT8 -> FP16 (per token): 1.0773181915283203
TIME INT8 * INT8 -> FP16 (per channel) 1.0722160339355469
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0745525360107422
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0504722595214844
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8555412292480469
TIME Linear: 0.8591175079345703
Speed Up INT8 * INT8 -> FP16 (per tensor):32.76%
Speed Up INT8 * INT8 -> FP16 (per token):-25.4%
Speed Up INT8 * INT8 -> FP16 (per channel):-24.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-25.08%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-22.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.42%
==========M=5064==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5796432495117188
TIME INT8 * INT8 -> FP16 (per token): 1.0745525360107422
TIME INT8 * INT8 -> FP16 (per channel) 1.0692596435546875
TIME INT8 * INT8 -> FP16 (per token per channel): 1.075291633605957
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0503053665161133
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8584022521972656
TIME Linear: 0.8868694305419922
Speed Up INT8 * INT8 -> FP16 (per tensor):34.64%
Speed Up INT8 * INT8 -> FP16 (per token):-21.16%
Speed Up INT8 * INT8 -> FP16 (per channel):-20.57%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.43%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.21%
==========M=5096==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.579071044921875
TIME INT8 * INT8 -> FP16 (per token): 1.0813713073730469
TIME INT8 * INT8 -> FP16 (per channel) 1.0776996612548828
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0834932327270508
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0518789291381836
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8556365966796875
TIME Linear: 1.0198354721069336
Speed Up INT8 * INT8 -> FP16 (per tensor):43.22%
Speed Up INT8 * INT8 -> FP16 (per token):-6.03%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.67%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.14%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.1%
==========M=5128==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5980491638183594
TIME INT8 * INT8 -> FP16 (per token): 1.0874271392822266
TIME INT8 * INT8 -> FP16 (per channel) 1.082754135131836
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0876178741455078
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0982751846313477
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9156942367553711
TIME Linear: 1.0632514953613281
Speed Up INT8 * INT8 -> FP16 (per tensor):43.75%
Speed Up INT8 * INT8 -> FP16 (per token):-2.27%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.83%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.29%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.29%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.88%
==========M=5160==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5988836288452148
TIME INT8 * INT8 -> FP16 (per token): 1.0962486267089844
TIME INT8 * INT8 -> FP16 (per channel) 1.0901927947998047
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0960578918457031
TIME INT8 * FP16 -> Fp16 (WO bias): 1.100301742553711
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9168624877929688
TIME Linear: 1.062631607055664
Speed Up INT8 * INT8 -> FP16 (per tensor):43.64%
Speed Up INT8 * INT8 -> FP16 (per token):-3.16%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.15%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.54%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.72%
==========M=5192==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5994081497192383
TIME INT8 * INT8 -> FP16 (per token): 1.0831594467163086
TIME INT8 * INT8 -> FP16 (per channel) 1.0721921920776367
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0858774185180664
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3533592224121094
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1316776275634766
TIME Linear: 1.0631322860717773
Speed Up INT8 * INT8 -> FP16 (per tensor):43.62%
Speed Up INT8 * INT8 -> FP16 (per token):-1.88%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.85%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.14%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-27.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.45%
==========M=5224==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6012439727783203
TIME INT8 * INT8 -> FP16 (per token): 1.0995864868164062
TIME INT8 * INT8 -> FP16 (per channel) 1.0960578918457031
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1001348495483398
TIME INT8 * FP16 -> Fp16 (WO bias): 1.354360580444336
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1327266693115234
TIME Linear: 1.064157485961914
Speed Up INT8 * INT8 -> FP16 (per tensor):43.5%
Speed Up INT8 * INT8 -> FP16 (per token):-3.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.0%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.38%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-27.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.44%
==========M=5256==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6032705307006836
TIME INT8 * INT8 -> FP16 (per token): 1.096963882446289
TIME INT8 * INT8 -> FP16 (per channel) 1.0884284973144531
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0993719100952148
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2138843536376953
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0242938995361328
TIME Linear: 1.0647773742675781
Speed Up INT8 * INT8 -> FP16 (per tensor):43.34%
Speed Up INT8 * INT8 -> FP16 (per token):-3.02%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.8%
==========M=5288==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.603032112121582
TIME INT8 * INT8 -> FP16 (per token): 1.1069774627685547
TIME INT8 * INT8 -> FP16 (per channel) 1.093459129333496
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1075973510742188
TIME INT8 * FP16 -> Fp16 (WO bias): 1.213836669921875
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0258197784423828
TIME Linear: 1.0637521743774414
Speed Up INT8 * INT8 -> FP16 (per tensor):43.31%
Speed Up INT8 * INT8 -> FP16 (per token):-4.06%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.57%
==========M=5320==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6035327911376953
TIME INT8 * INT8 -> FP16 (per token): 1.1139631271362305
TIME INT8 * INT8 -> FP16 (per channel) 1.099538803100586
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1131048202514648
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2191295623779297
TIME INT8 * FP16 -> Fp16 (WI bias): 1.027822494506836
TIME Linear: 1.0658979415893555
Speed Up INT8 * INT8 -> FP16 (per tensor):43.38%
Speed Up INT8 * INT8 -> FP16 (per token):-4.51%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.16%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.38%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.57%
==========M=5352==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.605320930480957
TIME INT8 * INT8 -> FP16 (per token): 1.1176586151123047
TIME INT8 * INT8 -> FP16 (per channel) 1.106572151184082
TIME INT8 * INT8 -> FP16 (per token per channel): 1.119065284729004
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2153148651123047
TIME INT8 * FP16 -> Fp16 (WI bias): 1.026296615600586
TIME Linear: 1.0661125183105469
Speed Up INT8 * INT8 -> FP16 (per tensor):43.22%
Speed Up INT8 * INT8 -> FP16 (per token):-4.83%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.97%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-13.99%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.73%
==========M=5384==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6221294403076172
TIME INT8 * INT8 -> FP16 (per token): 1.1429309844970703
TIME INT8 * INT8 -> FP16 (per channel) 1.1370420455932617
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1446237564086914
TIME INT8 * FP16 -> Fp16 (WO bias): 1.628279685974121
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4110803604125977
TIME Linear: 1.0885000228881836
Speed Up INT8 * INT8 -> FP16 (per tensor):42.85%
Speed Up INT8 * INT8 -> FP16 (per token):-5.0%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.46%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-49.59%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-29.64%
==========M=5416==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.623321533203125
TIME INT8 * INT8 -> FP16 (per token): 1.1538267135620117
TIME INT8 * INT8 -> FP16 (per channel) 1.1526107788085938
TIME INT8 * INT8 -> FP16 (per token per channel): 1.154327392578125
TIME INT8 * FP16 -> Fp16 (WO bias): 1.63726806640625
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4141321182250977
TIME Linear: 1.0950088500976562
Speed Up INT8 * INT8 -> FP16 (per tensor):43.08%
Speed Up INT8 * INT8 -> FP16 (per token):-5.37%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.26%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.42%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-49.52%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-29.14%
==========M=5448==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6235837936401367
TIME INT8 * INT8 -> FP16 (per token): 1.1720895767211914
TIME INT8 * INT8 -> FP16 (per channel) 1.1530876159667969
TIME INT8 * INT8 -> FP16 (per token per channel): 1.158595085144043
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1395931243896484
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9270429611206055
TIME Linear: 1.0912895202636719
Speed Up INT8 * INT8 -> FP16 (per tensor):42.86%
Speed Up INT8 * INT8 -> FP16 (per token):-7.4%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.66%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.17%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.43%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.05%
==========M=5480==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6156444549560547
TIME INT8 * INT8 -> FP16 (per token): 1.1510848999023438
TIME INT8 * INT8 -> FP16 (per channel) 1.144552230834961
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1504411697387695
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1258363723754883
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9157419204711914
TIME Linear: 1.079726219177246
Speed Up INT8 * INT8 -> FP16 (per tensor):42.98%
Speed Up INT8 * INT8 -> FP16 (per token):-6.61%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.0%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.55%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.19%
==========M=5512==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6337165832519531
TIME INT8 * INT8 -> FP16 (per token): 1.1591196060180664
TIME INT8 * INT8 -> FP16 (per channel) 1.1498689651489258
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1583328247070312
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1687517166137695
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9759426116943359
TIME Linear: 1.132369041442871
Speed Up INT8 * INT8 -> FP16 (per tensor):44.04%
Speed Up INT8 * INT8 -> FP16 (per token):-2.36%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.55%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.29%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.81%
==========M=5544==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6438255310058594
TIME INT8 * INT8 -> FP16 (per token): 1.1780977249145508
TIME INT8 * INT8 -> FP16 (per channel) 1.1715173721313477
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1958599090576172
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2055635452270508
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9919643402099609
TIME Linear: 1.0850906372070312
Speed Up INT8 * INT8 -> FP16 (per tensor):40.67%
Speed Up INT8 * INT8 -> FP16 (per token):-8.57%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.96%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.21%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.1%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.58%
==========M=5576==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6199836730957031
TIME INT8 * INT8 -> FP16 (per token): 1.1443138122558594
TIME INT8 * INT8 -> FP16 (per channel) 1.139688491821289
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1424779891967773
TIME INT8 * FP16 -> Fp16 (WO bias): 1.324772834777832
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2514591217041016
TIME Linear: 1.0874032974243164
Speed Up INT8 * INT8 -> FP16 (per tensor):42.98%
Speed Up INT8 * INT8 -> FP16 (per token):-5.23%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.81%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.06%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.83%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.09%
==========M=5608==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6214380264282227
TIME INT8 * INT8 -> FP16 (per token): 1.1324405670166016
TIME INT8 * INT8 -> FP16 (per channel) 1.1177778244018555
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1326074600219727
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1963129043579102
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9785175323486328
TIME Linear: 1.125025749206543
Speed Up INT8 * INT8 -> FP16 (per tensor):44.76%
Speed Up INT8 * INT8 -> FP16 (per token):-0.66%
Speed Up INT8 * INT8 -> FP16 (per channel):0.64%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.67%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.34%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.02%
==========M=5640==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6467819213867188
TIME INT8 * INT8 -> FP16 (per token): 1.178741455078125
TIME INT8 * INT8 -> FP16 (per channel) 1.1692285537719727
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1846542358398438
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4201164245605469
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2004375457763672
TIME Linear: 1.0353565216064453
Speed Up INT8 * INT8 -> FP16 (per tensor):37.53%
Speed Up INT8 * INT8 -> FP16 (per token):-13.85%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.42%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.16%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-15.94%
==========M=5672==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5901575088500977
TIME INT8 * INT8 -> FP16 (per token): 1.0989904403686523
TIME INT8 * INT8 -> FP16 (per channel) 1.0916948318481445
TIME INT8 * INT8 -> FP16 (per token per channel): 1.095890998840332
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1911392211914062
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0079622268676758
TIME Linear: 1.036381721496582
Speed Up INT8 * INT8 -> FP16 (per tensor):43.06%
Speed Up INT8 * INT8 -> FP16 (per token):-6.04%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.34%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.74%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.74%
==========M=5704==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.589752197265625
TIME INT8 * INT8 -> FP16 (per token): 1.1059999465942383
TIME INT8 * INT8 -> FP16 (per channel) 1.098036766052246
TIME INT8 * INT8 -> FP16 (per token per channel): 1.107168197631836
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0892868041992188
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8848190307617188
TIME Linear: 1.1347055435180664
Speed Up INT8 * INT8 -> FP16 (per tensor):48.03%
Speed Up INT8 * INT8 -> FP16 (per token):2.53%
Speed Up INT8 * INT8 -> FP16 (per channel):3.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):2.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):4.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):22.02%
==========M=5736==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6488800048828125
TIME INT8 * INT8 -> FP16 (per token): 1.2213468551635742
TIME INT8 * INT8 -> FP16 (per channel) 1.2179136276245117
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2283802032470703
TIME INT8 * FP16 -> Fp16 (WO bias): 1.198577880859375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9738445281982422
TIME Linear: 1.101827621459961
Speed Up INT8 * INT8 -> FP16 (per tensor):41.11%
Speed Up INT8 * INT8 -> FP16 (per token):-10.85%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.54%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-11.49%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.78%
Speed Up INT8 * FP16 -> Fp16 (WI bias):11.62%
==========M=5768==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6278514862060547
TIME INT8 * INT8 -> FP16 (per token): 1.1548757553100586
TIME INT8 * INT8 -> FP16 (per channel) 1.1479616165161133
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1532306671142578
TIME INT8 * FP16 -> Fp16 (WO bias): 1.135087013244629
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9247541427612305
TIME Linear: 1.1026382446289062
Speed Up INT8 * INT8 -> FP16 (per tensor):43.06%
Speed Up INT8 * INT8 -> FP16 (per token):-4.74%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.11%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.59%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.94%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.13%
==========M=5800==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6327152252197266
TIME INT8 * INT8 -> FP16 (per token): 1.161503791809082
TIME INT8 * INT8 -> FP16 (per channel) 1.157546043395996
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1619806289672852
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1385440826416016
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9246110916137695
TIME Linear: 1.164412498474121
Speed Up INT8 * INT8 -> FP16 (per tensor):45.66%
Speed Up INT8 * INT8 -> FP16 (per token):0.25%
Speed Up INT8 * INT8 -> FP16 (per channel):0.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.21%
Speed Up INT8 * FP16 -> Fp16 (WO bias):2.22%
Speed Up INT8 * FP16 -> Fp16 (WI bias):20.59%
==========M=5832==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6677389144897461
TIME INT8 * INT8 -> FP16 (per token): 1.2405633926391602
TIME INT8 * INT8 -> FP16 (per channel) 1.2380123138427734
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2413263320922852
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2171745300292969
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9931325912475586
TIME Linear: 1.1641502380371094
Speed Up INT8 * INT8 -> FP16 (per tensor):42.64%
Speed Up INT8 * INT8 -> FP16 (per token):-6.56%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.34%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.63%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.55%
Speed Up INT8 * FP16 -> Fp16 (WI bias):14.69%
==========M=5864==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.668025016784668
TIME INT8 * INT8 -> FP16 (per token): 1.2478828430175781
TIME INT8 * INT8 -> FP16 (per channel) 1.332259178161621
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2477874755859375
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2192249298095703
TIME INT8 * FP16 -> Fp16 (WI bias): 0.993037223815918
TIME Linear: 1.1127233505249023
Speed Up INT8 * INT8 -> FP16 (per tensor):39.96%
Speed Up INT8 * INT8 -> FP16 (per token):-12.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-12.14%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-9.57%
Speed Up INT8 * FP16 -> Fp16 (WI bias):10.76%
==========M=5896==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6399631500244141
TIME INT8 * INT8 -> FP16 (per token): 1.1949539184570312
TIME INT8 * INT8 -> FP16 (per channel) 1.1898994445800781
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1946678161621094
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1662483215332031
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9484529495239258
TIME Linear: 1.1259794235229492
Speed Up INT8 * INT8 -> FP16 (per tensor):43.16%
Speed Up INT8 * INT8 -> FP16 (per token):-6.13%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.68%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.58%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.77%
==========M=5928==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6441354751586914
TIME INT8 * INT8 -> FP16 (per token): 1.2107133865356445
TIME INT8 * INT8 -> FP16 (per channel) 1.2025117874145508
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2111663818359375
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1740446090698242
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9530305862426758
TIME Linear: 1.2086153030395508
Speed Up INT8 * INT8 -> FP16 (per tensor):46.7%
Speed Up INT8 * INT8 -> FP16 (per token):-0.17%
Speed Up INT8 * INT8 -> FP16 (per channel):0.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.21%
Speed Up INT8 * FP16 -> Fp16 (WO bias):2.86%
Speed Up INT8 * FP16 -> Fp16 (WI bias):21.15%
==========M=5960==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6725072860717773
TIME INT8 * INT8 -> FP16 (per token): 1.271677017211914
TIME INT8 * INT8 -> FP16 (per channel) 1.260232925415039
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2676477432250977
TIME INT8 * FP16 -> Fp16 (WO bias): 1.222681999206543
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9943723678588867
TIME Linear: 1.2070417404174805
Speed Up INT8 * INT8 -> FP16 (per tensor):44.28%
Speed Up INT8 * INT8 -> FP16 (per token):-5.35%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.41%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.02%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):17.62%
==========M=5992==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6734848022460938
TIME INT8 * INT8 -> FP16 (per token): 1.280832290649414
TIME INT8 * INT8 -> FP16 (per channel) 1.2676715850830078
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2797117233276367
TIME INT8 * FP16 -> Fp16 (WO bias): 1.225113868713379
TIME INT8 * FP16 -> Fp16 (WI bias): 0.994873046875
TIME Linear: 1.2202978134155273
Speed Up INT8 * INT8 -> FP16 (per tensor):44.81%
Speed Up INT8 * INT8 -> FP16 (per token):-4.96%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.88%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.87%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.39%
Speed Up INT8 * FP16 -> Fp16 (WI bias):18.47%
==========M=6024==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.69122314453125
TIME INT8 * INT8 -> FP16 (per token): 1.2843608856201172
TIME INT8 * INT8 -> FP16 (per channel) 1.2760162353515625
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2830495834350586
TIME INT8 * FP16 -> Fp16 (WO bias): 1.482558250427246
TIME INT8 * FP16 -> Fp16 (WI bias): 1.429152488708496
TIME Linear: 1.0643243789672852
Speed Up INT8 * INT8 -> FP16 (per tensor):35.06%
Speed Up INT8 * INT8 -> FP16 (per token):-20.67%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.55%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-39.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-34.28%
==========M=6056==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6041049957275391
TIME INT8 * INT8 -> FP16 (per token): 1.117563247680664
TIME INT8 * INT8 -> FP16 (per channel) 1.0977745056152344
TIME INT8 * INT8 -> FP16 (per token per channel): 1.103067398071289
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5989303588867188
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3853073120117188
TIME Linear: 1.0605573654174805
Speed Up INT8 * INT8 -> FP16 (per tensor):43.04%
Speed Up INT8 * INT8 -> FP16 (per token):-5.38%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.51%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-50.76%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-30.62%
==========M=6088==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6023406982421875
TIME INT8 * INT8 -> FP16 (per token): 1.1066913604736328
TIME INT8 * INT8 -> FP16 (per channel) 1.0931968688964844
TIME INT8 * INT8 -> FP16 (per token per channel): 1.206374168395996
TIME INT8 * FP16 -> Fp16 (WO bias): 1.108717918395996
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8958101272583008
TIME Linear: 1.200413703918457
Speed Up INT8 * INT8 -> FP16 (per tensor):49.82%
Speed Up INT8 * INT8 -> FP16 (per token):7.81%
Speed Up INT8 * INT8 -> FP16 (per channel):8.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.5%
Speed Up INT8 * FP16 -> Fp16 (WO bias):7.64%
Speed Up INT8 * FP16 -> Fp16 (WI bias):25.37%
==========M=6120==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6929874420166016
TIME INT8 * INT8 -> FP16 (per token): 1.2776613235473633
TIME INT8 * INT8 -> FP16 (per channel) 1.265263557434082
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2808561325073242
TIME INT8 * FP16 -> Fp16 (WO bias): 1.266622543334961
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0295867919921875
TIME Linear: 1.0829687118530273
Speed Up INT8 * INT8 -> FP16 (per tensor):36.01%
Speed Up INT8 * INT8 -> FP16 (per token):-17.98%
Speed Up INT8 * INT8 -> FP16 (per channel):-16.83%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-18.27%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.96%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.93%
==========M=6152==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6305694580078125
TIME INT8 * INT8 -> FP16 (per token): 1.3084173202514648
TIME INT8 * INT8 -> FP16 (per channel) 1.1324167251586914
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1461496353149414
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7697334289550781
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4901399612426758
TIME Linear: 1.0452508926391602
Speed Up INT8 * INT8 -> FP16 (per tensor):39.67%
Speed Up INT8 * INT8 -> FP16 (per token):-25.18%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.34%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-69.31%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-42.56%
==========M=6184==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5927801132202148
TIME INT8 * INT8 -> FP16 (per token): 1.0676383972167969
TIME INT8 * INT8 -> FP16 (per channel) 1.0559797286987305
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0680913925170898
TIME INT8 * FP16 -> Fp16 (WO bias): 1.6670703887939453
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4137506484985352
TIME Linear: 1.0430097579956055
Speed Up INT8 * INT8 -> FP16 (per tensor):43.17%
Speed Up INT8 * INT8 -> FP16 (per token):-2.36%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.24%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.4%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-59.83%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-35.55%
==========M=6216==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6323337554931641
TIME INT8 * INT8 -> FP16 (per token): 1.0769844055175781
TIME INT8 * INT8 -> FP16 (per channel) 1.0632038116455078
TIME INT8 * INT8 -> FP16 (per token per channel): 1.075577735900879
TIME INT8 * FP16 -> Fp16 (WO bias): 1.300215721130371
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1325597763061523
TIME Linear: 1.0424375534057617
Speed Up INT8 * INT8 -> FP16 (per tensor):39.34%
Speed Up INT8 * INT8 -> FP16 (per token):-3.31%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.99%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.18%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.73%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-8.65%
==========M=6248==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6172657012939453
TIME INT8 * INT8 -> FP16 (per token): 1.0787248611450195
TIME INT8 * INT8 -> FP16 (per channel) 1.0661602020263672
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0790586471557617
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7627716064453125
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5514612197875977
TIME Linear: 1.0818004608154297
Speed Up INT8 * INT8 -> FP16 (per tensor):42.94%
Speed Up INT8 * INT8 -> FP16 (per token):0.28%
Speed Up INT8 * INT8 -> FP16 (per channel):1.45%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-62.95%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-43.41%
==========M=6280==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6482839584350586
TIME INT8 * INT8 -> FP16 (per token): 1.0873079299926758
TIME INT8 * INT8 -> FP16 (per channel) 1.0738849639892578
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0869264602661133
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0985851287841797
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8889436721801758
TIME Linear: 1.052260398864746
Speed Up INT8 * INT8 -> FP16 (per tensor):38.39%
Speed Up INT8 * INT8 -> FP16 (per token):-3.33%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.29%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.52%
==========M=6312==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6244659423828125
TIME INT8 * INT8 -> FP16 (per token): 1.0930061340332031
TIME INT8 * INT8 -> FP16 (per channel) 1.0832786560058594
TIME INT8 * INT8 -> FP16 (per token per channel): 1.0900020599365234
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0874032974243164
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9235143661499023
TIME Linear: 1.2543439865112305
Speed Up INT8 * INT8 -> FP16 (per tensor):50.22%
Speed Up INT8 * INT8 -> FP16 (per token):12.86%
Speed Up INT8 * INT8 -> FP16 (per channel):13.64%
Speed Up INT8 * INT8 -> FP16 (per token per channel):13.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):13.31%
Speed Up INT8 * FP16 -> Fp16 (WI bias):26.37%
==========M=6344==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6935596466064453
TIME INT8 * INT8 -> FP16 (per token): 1.3263225555419922
TIME INT8 * INT8 -> FP16 (per channel) 1.3138055801391602
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3312578201293945
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7556428909301758
TIME INT8 * FP16 -> Fp16 (WI bias): 1.4215946197509766
TIME Linear: 1.0991811752319336
Speed Up INT8 * INT8 -> FP16 (per tensor):36.9%
Speed Up INT8 * INT8 -> FP16 (per token):-20.66%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.53%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-21.11%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-59.72%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-29.33%
==========M=6376==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6325244903564453
TIME INT8 * INT8 -> FP16 (per token): 1.1594295501708984
TIME INT8 * INT8 -> FP16 (per channel) 1.1482477188110352
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1595964431762695
TIME INT8 * FP16 -> Fp16 (WO bias): 1.1438369750976562
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9268522262573242
TIME Linear: 1.1012077331542969
Speed Up INT8 * INT8 -> FP16 (per tensor):42.56%
Speed Up INT8 * INT8 -> FP16 (per token):-5.29%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.27%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.87%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.83%
==========M=6408==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6402969360351562
TIME INT8 * INT8 -> FP16 (per token): 1.165628433227539
TIME INT8 * INT8 -> FP16 (per channel) 1.1519670486450195
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1662006378173828
TIME INT8 * FP16 -> Fp16 (WO bias): 1.163482666015625
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9386301040649414
TIME Linear: 1.2646913528442383
Speed Up INT8 * INT8 -> FP16 (per tensor):49.37%
Speed Up INT8 * INT8 -> FP16 (per token):7.83%
Speed Up INT8 * INT8 -> FP16 (per channel):8.91%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):8.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):25.78%
==========M=6440==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7380962371826172
TIME INT8 * INT8 -> FP16 (per token): 1.3553380966186523
TIME INT8 * INT8 -> FP16 (per channel) 1.3465404510498047
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3544082641601562
TIME INT8 * FP16 -> Fp16 (WO bias): 1.329660415649414
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0810613632202148
TIME Linear: 1.2985467910766602
Speed Up INT8 * INT8 -> FP16 (per tensor):43.16%
Speed Up INT8 * INT8 -> FP16 (per token):-4.37%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.7%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.75%
==========M=6472==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7415294647216797
TIME INT8 * INT8 -> FP16 (per token): 1.3821840286254883
TIME INT8 * INT8 -> FP16 (per channel) 1.3723373413085938
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3857126235961914
TIME INT8 * FP16 -> Fp16 (WO bias): 2.8018712997436523
TIME INT8 * FP16 -> Fp16 (WI bias): 2.5049209594726562
TIME Linear: 1.1484622955322266
Speed Up INT8 * INT8 -> FP16 (per tensor):35.43%
Speed Up INT8 * INT8 -> FP16 (per token):-20.35%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-20.66%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-143.97%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-118.11%
==========M=6504==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6498813629150391
TIME INT8 * INT8 -> FP16 (per token): 1.2209177017211914
TIME INT8 * INT8 -> FP16 (per channel) 1.2143850326538086
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2214183807373047
TIME INT8 * FP16 -> Fp16 (WO bias): 2.5113344192504883
TIME INT8 * FP16 -> Fp16 (WI bias): 2.24761962890625
TIME Linear: 1.0805368423461914
Speed Up INT8 * INT8 -> FP16 (per tensor):39.86%
Speed Up INT8 * INT8 -> FP16 (per token):-12.99%
Speed Up INT8 * INT8 -> FP16 (per channel):-12.39%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-13.04%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-132.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-108.01%
==========M=6536==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6444692611694336
TIME INT8 * INT8 -> FP16 (per token): 1.1567354202270508
TIME INT8 * INT8 -> FP16 (per channel) 1.1473655700683594
TIME INT8 * INT8 -> FP16 (per token per channel): 1.155853271484375
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4847040176391602
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3092041015625
TIME Linear: 1.0817527770996094
Speed Up INT8 * INT8 -> FP16 (per tensor):40.42%
Speed Up INT8 * INT8 -> FP16 (per token):-6.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.07%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.85%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-37.25%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-21.03%
==========M=6568==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6451129913330078
TIME INT8 * INT8 -> FP16 (per token): 1.1617660522460938
TIME INT8 * INT8 -> FP16 (per channel) 1.1519432067871094
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1588096618652344
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2592077255249023
TIME INT8 * FP16 -> Fp16 (WI bias): 1.073455810546875
TIME Linear: 1.079869270324707
Speed Up INT8 * INT8 -> FP16 (per tensor):40.26%
Speed Up INT8 * INT8 -> FP16 (per token):-7.58%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.67%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.59%
==========M=6600==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6390094757080078
TIME INT8 * INT8 -> FP16 (per token): 1.1679887771606445
TIME INT8 * INT8 -> FP16 (per channel) 1.160740852355957
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1699199676513672
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2542486190795898
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0568857192993164
TIME Linear: 1.3011932373046875
Speed Up INT8 * INT8 -> FP16 (per tensor):50.89%
Speed Up INT8 * INT8 -> FP16 (per token):10.24%
Speed Up INT8 * INT8 -> FP16 (per channel):10.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.09%
Speed Up INT8 * FP16 -> Fp16 (WO bias):3.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):18.78%
==========M=6632==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7420063018798828
TIME INT8 * INT8 -> FP16 (per token): 1.4168262481689453
TIME INT8 * INT8 -> FP16 (per channel) 1.4098405838012695
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4174222946166992
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5088558197021484
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2789726257324219
TIME Linear: 1.082611083984375
Speed Up INT8 * INT8 -> FP16 (per tensor):31.46%
Speed Up INT8 * INT8 -> FP16 (per token):-30.87%
Speed Up INT8 * INT8 -> FP16 (per channel):-30.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-30.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-39.37%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.14%
==========M=6664==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7080793380737305
TIME INT8 * INT8 -> FP16 (per token): 1.181483268737793
TIME INT8 * INT8 -> FP16 (per channel) 1.171278953552246
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1768817901611328
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3962984085083008
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1804580688476562
TIME Linear: 1.1279821395874023
Speed Up INT8 * INT8 -> FP16 (per tensor):37.23%
Speed Up INT8 * INT8 -> FP16 (per token):-4.74%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.84%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.34%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-23.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-4.65%
==========M=6696==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6629467010498047
TIME INT8 * INT8 -> FP16 (per token): 1.1869430541992188
TIME INT8 * INT8 -> FP16 (per channel) 1.1868953704833984
TIME INT8 * INT8 -> FP16 (per token per channel): 1.1856555938720703
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4633893966674805
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2478828430175781
TIME Linear: 1.1182308197021484
Speed Up INT8 * INT8 -> FP16 (per tensor):40.71%
Speed Up INT8 * INT8 -> FP16 (per token):-6.14%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.14%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.03%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-30.87%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-11.59%
==========M=6728==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7642030715942383
TIME INT8 * INT8 -> FP16 (per token): 1.4455556869506836
TIME INT8 * INT8 -> FP16 (per channel) 1.439976692199707
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4427423477172852
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3915300369262695
TIME INT8 * FP16 -> Fp16 (WI bias): 1.134181022644043
TIME Linear: 1.2602567672729492
Speed Up INT8 * INT8 -> FP16 (per tensor):39.36%
Speed Up INT8 * INT8 -> FP16 (per token):-14.7%
Speed Up INT8 * INT8 -> FP16 (per channel):-14.26%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-14.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-10.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):10.0%
==========M=6760==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7100820541381836
TIME INT8 * INT8 -> FP16 (per token): 1.3461828231811523
TIME INT8 * INT8 -> FP16 (per channel) 1.3401508331298828
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3442516326904297
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3007402420043945
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0553836822509766
TIME Linear: 1.125788688659668
Speed Up INT8 * INT8 -> FP16 (per tensor):36.93%
Speed Up INT8 * INT8 -> FP16 (per token):-19.58%
Speed Up INT8 * INT8 -> FP16 (per channel):-19.04%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-19.41%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.54%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.25%
==========M=6792==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6666898727416992
TIME INT8 * INT8 -> FP16 (per token): 1.203155517578125
TIME INT8 * INT8 -> FP16 (per channel) 1.1982917785644531
TIME INT8 * INT8 -> FP16 (per token per channel): 1.204848289489746
TIME INT8 * FP16 -> Fp16 (WO bias): 1.305222511291504
TIME INT8 * FP16 -> Fp16 (WI bias): 1.117110252380371
TIME Linear: 1.1365652084350586
Speed Up INT8 * INT8 -> FP16 (per tensor):41.34%
Speed Up INT8 * INT8 -> FP16 (per token):-5.86%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.43%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.84%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.71%
==========M=6824==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7780551910400391
TIME INT8 * INT8 -> FP16 (per token): 1.2127161026000977
TIME INT8 * INT8 -> FP16 (per channel) 1.2083768844604492
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2076616287231445
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2952089309692383
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1338233947753906
TIME Linear: 1.1195659637451172
Speed Up INT8 * INT8 -> FP16 (per tensor):30.5%
Speed Up INT8 * INT8 -> FP16 (per token):-8.32%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.93%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.87%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.69%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.27%
==========M=6856==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6607770919799805
TIME INT8 * INT8 -> FP16 (per token): 1.2148618698120117
TIME INT8 * INT8 -> FP16 (per channel) 1.2085199356079102
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2115955352783203
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4270544052124023
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1436223983764648
TIME Linear: 1.133561134338379
Speed Up INT8 * INT8 -> FP16 (per tensor):41.71%
Speed Up INT8 * INT8 -> FP16 (per token):-7.17%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.89%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.89%
==========M=6888==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6807804107666016
TIME INT8 * INT8 -> FP16 (per token): 1.2369155883789062
TIME INT8 * INT8 -> FP16 (per channel) 1.2329339981079102
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2336969375610352
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3296842575073242
TIME INT8 * FP16 -> Fp16 (WI bias): 1.148843765258789
TIME Linear: 1.1206865310668945
Speed Up INT8 * INT8 -> FP16 (per tensor):39.25%
Speed Up INT8 * INT8 -> FP16 (per token):-10.37%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.08%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-18.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.51%
==========M=6920==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7014274597167969
TIME INT8 * INT8 -> FP16 (per token): 1.1984586715698242
TIME INT8 * INT8 -> FP16 (per channel) 1.1848926544189453
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2048721313476562
TIME INT8 * FP16 -> Fp16 (WO bias): 1.475214958190918
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3170719146728516
TIME Linear: 1.1597633361816406
Speed Up INT8 * INT8 -> FP16 (per tensor):39.52%
Speed Up INT8 * INT8 -> FP16 (per token):-3.34%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.17%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.89%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-27.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.56%
==========M=6952==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6865024566650391
TIME INT8 * INT8 -> FP16 (per token): 1.207113265991211
TIME INT8 * INT8 -> FP16 (per channel) 1.1991024017333984
TIME INT8 * INT8 -> FP16 (per token per channel): 1.204824447631836
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3417720794677734
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1548995971679688
TIME Linear: 1.3148307800292969
Speed Up INT8 * INT8 -> FP16 (per tensor):47.79%
Speed Up INT8 * INT8 -> FP16 (per token):8.19%
Speed Up INT8 * INT8 -> FP16 (per channel):8.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.37%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.05%
Speed Up INT8 * FP16 -> Fp16 (WI bias):12.16%
==========M=6984==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7867813110351562
TIME INT8 * INT8 -> FP16 (per token): 1.4642715454101562
TIME INT8 * INT8 -> FP16 (per channel) 1.4504671096801758
TIME INT8 * INT8 -> FP16 (per token per channel): 1.467132568359375
TIME INT8 * FP16 -> Fp16 (WO bias): 1.792001724243164
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5050411224365234
TIME Linear: 1.159834861755371
Speed Up INT8 * INT8 -> FP16 (per tensor):32.16%
Speed Up INT8 * INT8 -> FP16 (per token):-26.25%
Speed Up INT8 * INT8 -> FP16 (per channel):-25.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-26.49%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-54.5%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-29.76%
==========M=7016==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.6849527359008789
TIME INT8 * INT8 -> FP16 (per token): 1.2137174606323242
TIME INT8 * INT8 -> FP16 (per channel) 1.2032508850097656
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2140274047851562
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5317201614379883
TIME INT8 * FP16 -> Fp16 (WI bias): 1.320505142211914
TIME Linear: 1.1591672897338867
Speed Up INT8 * INT8 -> FP16 (per tensor):40.91%
Speed Up INT8 * INT8 -> FP16 (per token):-4.71%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.73%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-32.14%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.92%
==========M=7048==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7071971893310547
TIME INT8 * INT8 -> FP16 (per token): 1.2476682662963867
TIME INT8 * INT8 -> FP16 (per channel) 1.2421131134033203
TIME INT8 * INT8 -> FP16 (per token per channel): 1.246809959411621
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2420415878295898
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0431528091430664
TIME Linear: 1.3021469116210938
Speed Up INT8 * INT8 -> FP16 (per tensor):45.69%
Speed Up INT8 * INT8 -> FP16 (per token):4.18%
Speed Up INT8 * INT8 -> FP16 (per channel):4.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):4.62%
Speed Up INT8 * FP16 -> Fp16 (WI bias):19.89%
==========M=7080==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8054494857788086
TIME INT8 * INT8 -> FP16 (per token): 1.5156984329223633
TIME INT8 * INT8 -> FP16 (per channel) 1.510167121887207
TIME INT8 * INT8 -> FP16 (per token per channel): 1.5179157257080078
TIME INT8 * FP16 -> Fp16 (WO bias): 1.459360122680664
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1870622634887695
TIME Linear: 1.4142036437988281
Speed Up INT8 * INT8 -> FP16 (per tensor):43.05%
Speed Up INT8 * INT8 -> FP16 (per token):-7.18%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.33%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-3.19%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.06%
==========M=7112==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8086204528808594
TIME INT8 * INT8 -> FP16 (per token): 1.4888525009155273
TIME INT8 * INT8 -> FP16 (per channel) 1.4747858047485352
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4926433563232422
TIME INT8 * FP16 -> Fp16 (WO bias): 3.086543083190918
TIME INT8 * FP16 -> Fp16 (WI bias): 2.788424491882324
TIME Linear: 1.1617660522460938
Speed Up INT8 * INT8 -> FP16 (per tensor):30.4%
Speed Up INT8 * INT8 -> FP16 (per token):-28.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-26.94%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-28.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-165.68%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-140.02%
==========M=7144==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7018566131591797
TIME INT8 * INT8 -> FP16 (per token): 1.2351751327514648
TIME INT8 * INT8 -> FP16 (per channel) 1.222372055053711
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2366294860839844
TIME INT8 * FP16 -> Fp16 (WO bias): 2.0227432250976562
TIME INT8 * FP16 -> Fp16 (WI bias): 1.7756223678588867
TIME Linear: 1.164841651916504
Speed Up INT8 * INT8 -> FP16 (per tensor):39.75%
Speed Up INT8 * INT8 -> FP16 (per token):-6.04%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.94%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-73.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-52.43%
==========M=7176==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7194280624389648
TIME INT8 * INT8 -> FP16 (per token): 1.2410163879394531
TIME INT8 * INT8 -> FP16 (per channel) 1.2272834777832031
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2435436248779297
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2416601181030273
TIME INT8 * FP16 -> Fp16 (WI bias): 1.048135757446289
TIME Linear: 1.3880014419555664
Speed Up INT8 * INT8 -> FP16 (per tensor):48.17%
Speed Up INT8 * INT8 -> FP16 (per token):10.59%
Speed Up INT8 * INT8 -> FP16 (per channel):11.58%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.41%
Speed Up INT8 * FP16 -> Fp16 (WO bias):10.54%
Speed Up INT8 * FP16 -> Fp16 (WI bias):24.49%
==========M=7208==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7529020309448242
TIME INT8 * INT8 -> FP16 (per token): 1.5176773071289062
TIME INT8 * INT8 -> FP16 (per channel) 1.5094280242919922
TIME INT8 * INT8 -> FP16 (per token per channel): 1.5190362930297852
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4777183532714844
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2034416198730469
TIME Linear: 1.2375354766845703
Speed Up INT8 * INT8 -> FP16 (per tensor):39.16%
Speed Up INT8 * INT8 -> FP16 (per token):-22.64%
Speed Up INT8 * INT8 -> FP16 (per channel):-21.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-22.75%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.75%
==========M=7240==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7204294204711914
TIME INT8 * INT8 -> FP16 (per token): 1.3247966766357422
TIME INT8 * INT8 -> FP16 (per channel) 1.3167619705200195
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3220548629760742
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2718439102172852
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0481595993041992
TIME Linear: 1.2356281280517578
Speed Up INT8 * INT8 -> FP16 (per tensor):41.7%
Speed Up INT8 * INT8 -> FP16 (per token):-7.22%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.57%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.99%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.17%
==========M=7272==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7285594940185547
TIME INT8 * INT8 -> FP16 (per token): 1.331162452697754
TIME INT8 * INT8 -> FP16 (per channel) 1.323390007019043
TIME INT8 * INT8 -> FP16 (per token per channel): 1.386570930480957
TIME INT8 * FP16 -> Fp16 (WO bias): 1.2744426727294922
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0335683822631836
TIME Linear: 1.200413703918457
Speed Up INT8 * INT8 -> FP16 (per tensor):39.31%
Speed Up INT8 * INT8 -> FP16 (per token):-10.89%
Speed Up INT8 * INT8 -> FP16 (per channel):-10.24%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-15.51%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.17%
Speed Up INT8 * FP16 -> Fp16 (WI bias):13.9%
==========M=7304==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.733494758605957
TIME INT8 * INT8 -> FP16 (per token): 1.265573501586914
TIME INT8 * INT8 -> FP16 (per channel) 1.250457763671875
TIME INT8 * INT8 -> FP16 (per token per channel): 1.28021240234375
TIME INT8 * FP16 -> Fp16 (WO bias): 1.6129255294799805
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3802289962768555
TIME Linear: 1.2035846710205078
Speed Up INT8 * INT8 -> FP16 (per tensor):39.06%
Speed Up INT8 * INT8 -> FP16 (per token):-5.15%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.37%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-34.01%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.68%
==========M=7336==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7391214370727539
TIME INT8 * INT8 -> FP16 (per token): 1.2693166732788086
TIME INT8 * INT8 -> FP16 (per channel) 1.2578725814819336
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2686729431152344
TIME INT8 * FP16 -> Fp16 (WO bias): 1.6079902648925781
TIME INT8 * FP16 -> Fp16 (WI bias): 1.373124122619629
TIME Linear: 1.2883186340332031
Speed Up INT8 * INT8 -> FP16 (per tensor):42.63%
Speed Up INT8 * INT8 -> FP16 (per token):1.47%
Speed Up INT8 * INT8 -> FP16 (per channel):2.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.52%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.81%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.58%
==========M=7368==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7173538208007812
TIME INT8 * INT8 -> FP16 (per token): 1.2772321701049805
TIME INT8 * INT8 -> FP16 (per channel) 1.262831687927246
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2795686721801758
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3103485107421875
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0679960250854492
TIME Linear: 1.212167739868164
Speed Up INT8 * INT8 -> FP16 (per tensor):40.82%
Speed Up INT8 * INT8 -> FP16 (per token):-5.37%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.18%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.56%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.1%
Speed Up INT8 * FP16 -> Fp16 (WI bias):11.89%
==========M=7400==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7586956024169922
TIME INT8 * INT8 -> FP16 (per token): 1.2813806533813477
TIME INT8 * INT8 -> FP16 (per channel) 1.2681961059570312
TIME INT8 * INT8 -> FP16 (per token per channel): 1.2931108474731445
TIME INT8 * FP16 -> Fp16 (WO bias): 1.308441162109375
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0907649993896484
TIME Linear: 1.2069940567016602
Speed Up INT8 * INT8 -> FP16 (per tensor):37.14%
Speed Up INT8 * INT8 -> FP16 (per token):-6.16%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.07%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.13%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):9.63%
==========M=7432==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7425069808959961
TIME INT8 * INT8 -> FP16 (per token): 1.2918472290039062
TIME INT8 * INT8 -> FP16 (per channel) 1.2728691101074219
TIME INT8 * INT8 -> FP16 (per token per channel): 1.28631591796875
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4273881912231445
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2228012084960938
TIME Linear: 1.236724853515625
Speed Up INT8 * INT8 -> FP16 (per tensor):39.96%
Speed Up INT8 * INT8 -> FP16 (per token):-4.46%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-15.42%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.13%
==========M=7464==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.727534294128418
TIME INT8 * INT8 -> FP16 (per token): 1.2966394424438477
TIME INT8 * INT8 -> FP16 (per channel) 1.2885570526123047
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4104843139648438
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4378786087036133
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2442350387573242
TIME Linear: 1.252603530883789
Speed Up INT8 * INT8 -> FP16 (per tensor):41.92%
Speed Up INT8 * INT8 -> FP16 (per token):-3.52%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.87%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-12.6%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.79%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.67%
==========M=7496==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7198572158813477
TIME INT8 * INT8 -> FP16 (per token): 1.313924789428711
TIME INT8 * INT8 -> FP16 (per channel) 1.2984991073608398
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3118982315063477
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4309167861938477
TIME INT8 * FP16 -> Fp16 (WI bias): 1.236891746520996
TIME Linear: 1.2519359588623047
Speed Up INT8 * INT8 -> FP16 (per tensor):42.5%
Speed Up INT8 * INT8 -> FP16 (per token):-4.95%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.72%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):1.2%
==========M=7528==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7287263870239258
TIME INT8 * INT8 -> FP16 (per token): 1.3183355331420898
TIME INT8 * INT8 -> FP16 (per channel) 1.3039350509643555
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3200759887695312
TIME INT8 * FP16 -> Fp16 (WO bias): 1.439833641052246
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2511491775512695
TIME Linear: 1.4883041381835938
Speed Up INT8 * INT8 -> FP16 (per tensor):51.04%
Speed Up INT8 * INT8 -> FP16 (per token):11.42%
Speed Up INT8 * INT8 -> FP16 (per channel):12.39%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):3.26%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.93%
==========M=7560==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8553504943847656
TIME INT8 * INT8 -> FP16 (per token): 1.6221046447753906
TIME INT8 * INT8 -> FP16 (per channel) 1.613473892211914
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6233205795288086
TIME INT8 * FP16 -> Fp16 (WO bias): 1.559281349182129
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2709379196166992
TIME Linear: 1.2531518936157227
Speed Up INT8 * INT8 -> FP16 (per tensor):31.74%
Speed Up INT8 * INT8 -> FP16 (per token):-29.44%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-29.54%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.43%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.42%
==========M=7592==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7544755935668945
TIME INT8 * INT8 -> FP16 (per token): 1.362013816833496
TIME INT8 * INT8 -> FP16 (per channel) 1.353621482849121
TIME INT8 * INT8 -> FP16 (per token per channel): 1.360630989074707
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3158082962036133
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1190414428710938
TIME Linear: 1.2389898300170898
Speed Up INT8 * INT8 -> FP16 (per tensor):39.11%
Speed Up INT8 * INT8 -> FP16 (per token):-9.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.25%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.82%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):9.68%
==========M=7624==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7630825042724609
TIME INT8 * INT8 -> FP16 (per token): 1.3538837432861328
TIME INT8 * INT8 -> FP16 (per channel) 1.3449430465698242
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3580322265625
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3151168823242188
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1282682418823242
TIME Linear: 1.239609718322754
Speed Up INT8 * INT8 -> FP16 (per tensor):38.44%
Speed Up INT8 * INT8 -> FP16 (per token):-9.22%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.5%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.55%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.09%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.98%
==========M=7656==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7454872131347656
TIME INT8 * INT8 -> FP16 (per token): 1.3617277145385742
TIME INT8 * INT8 -> FP16 (per channel) 1.3551712036132812
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3589143753051758
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3167381286621094
TIME INT8 * FP16 -> Fp16 (WI bias): 1.0628700256347656
TIME Linear: 1.3824462890625
Speed Up INT8 * INT8 -> FP16 (per tensor):46.07%
Speed Up INT8 * INT8 -> FP16 (per token):1.5%
Speed Up INT8 * INT8 -> FP16 (per channel):1.97%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.7%
Speed Up INT8 * FP16 -> Fp16 (WO bias):4.75%
Speed Up INT8 * FP16 -> Fp16 (WI bias):23.12%
==========M=7688==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.876927375793457
TIME INT8 * INT8 -> FP16 (per token): 1.651597023010254
TIME INT8 * INT8 -> FP16 (per channel) 1.6416549682617188
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6542673110961914
TIME INT8 * FP16 -> Fp16 (WO bias): 1.5900373458862305
TIME INT8 * FP16 -> Fp16 (WI bias): 1.296067237854004
TIME Linear: 1.278090476989746
Speed Up INT8 * INT8 -> FP16 (per tensor):31.39%
Speed Up INT8 * INT8 -> FP16 (per token):-29.22%
Speed Up INT8 * INT8 -> FP16 (per channel):-28.45%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-29.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.41%
==========M=7720==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8161306381225586
TIME INT8 * INT8 -> FP16 (per token): 1.3748884201049805
TIME INT8 * INT8 -> FP16 (per channel) 1.3644695281982422
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3775348663330078
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3855218887329102
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1533021926879883
TIME Linear: 1.2980222702026367
Speed Up INT8 * INT8 -> FP16 (per tensor):37.13%
Speed Up INT8 * INT8 -> FP16 (per token):-5.92%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.12%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-6.13%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.74%
Speed Up INT8 * FP16 -> Fp16 (WI bias):11.15%
==========M=7752==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8245468139648438
TIME INT8 * INT8 -> FP16 (per token): 1.3844966888427734
TIME INT8 * INT8 -> FP16 (per channel) 1.3720273971557617
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3761043548583984
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7357826232910156
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5471935272216797
TIME Linear: 1.275324821472168
Speed Up INT8 * INT8 -> FP16 (per tensor):35.35%
Speed Up INT8 * INT8 -> FP16 (per token):-8.56%
Speed Up INT8 * INT8 -> FP16 (per channel):-7.58%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.9%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.11%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-21.32%
==========M=7784==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8358955383300781
TIME INT8 * INT8 -> FP16 (per token): 1.3545751571655273
TIME INT8 * INT8 -> FP16 (per channel) 1.3370990753173828
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3490676879882812
TIME INT8 * FP16 -> Fp16 (WO bias): 2.3447751998901367
TIME INT8 * FP16 -> Fp16 (WI bias): 2.116680145263672
TIME Linear: 1.520538330078125
Speed Up INT8 * INT8 -> FP16 (per tensor):45.03%
Speed Up INT8 * INT8 -> FP16 (per token):10.91%
Speed Up INT8 * INT8 -> FP16 (per channel):12.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.28%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-54.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-39.21%
==========M=7816==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.883793830871582
TIME INT8 * INT8 -> FP16 (per token): 1.6460180282592773
TIME INT8 * INT8 -> FP16 (per channel) 1.6305923461914062
TIME INT8 * INT8 -> FP16 (per token per channel): 1.6497611999511719
TIME INT8 * FP16 -> Fp16 (WO bias): 3.3896684646606445
TIME INT8 * FP16 -> Fp16 (WI bias): 3.0434370040893555
TIME Linear: 1.2794733047485352
Speed Up INT8 * INT8 -> FP16 (per tensor):30.93%
Speed Up INT8 * INT8 -> FP16 (per token):-28.65%
Speed Up INT8 * INT8 -> FP16 (per channel):-27.44%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-28.94%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-164.93%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-137.87%
==========M=7848==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7365703582763672
TIME INT8 * INT8 -> FP16 (per token): 1.3626575469970703
TIME INT8 * INT8 -> FP16 (per channel) 1.3478517532348633
TIME INT8 * INT8 -> FP16 (per token per channel): 1.367020606994629
TIME INT8 * FP16 -> Fp16 (WO bias): 2.905154228210449
TIME INT8 * FP16 -> Fp16 (WI bias): 2.599334716796875
TIME Linear: 1.2763738632202148
Speed Up INT8 * INT8 -> FP16 (per tensor):42.29%
Speed Up INT8 * INT8 -> FP16 (per token):-6.76%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-127.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-103.65%
==========M=7880==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7982969284057617
TIME INT8 * INT8 -> FP16 (per token): 1.3698577880859375
TIME INT8 * INT8 -> FP16 (per channel) 1.3536930084228516
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3750791549682617
TIME INT8 * FP16 -> Fp16 (WO bias): 1.455545425415039
TIME INT8 * FP16 -> Fp16 (WI bias): 1.232743263244629
TIME Linear: 1.2780189514160156
Speed Up INT8 * INT8 -> FP16 (per tensor):37.54%
Speed Up INT8 * INT8 -> FP16 (per token):-7.19%
Speed Up INT8 * INT8 -> FP16 (per channel):-5.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.59%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-13.89%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.54%
==========M=7912==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.7750511169433594
TIME INT8 * INT8 -> FP16 (per token): 1.3738632202148438
TIME INT8 * INT8 -> FP16 (per channel) 1.357722282409668
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3705968856811523
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4613628387451172
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2109756469726562
TIME Linear: 1.28021240234375
Speed Up INT8 * INT8 -> FP16 (per tensor):39.46%
Speed Up INT8 * INT8 -> FP16 (per token):-7.32%
Speed Up INT8 * INT8 -> FP16 (per channel):-6.05%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-7.06%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.15%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.41%
==========M=7944==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8775949478149414
TIME INT8 * INT8 -> FP16 (per token): 1.3814926147460938
TIME INT8 * INT8 -> FP16 (per channel) 1.3677358627319336
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3905048370361328
TIME INT8 * FP16 -> Fp16 (WO bias): 1.7162084579467773
TIME INT8 * FP16 -> Fp16 (WI bias): 1.5236377716064453
TIME Linear: 1.3276338577270508
Speed Up INT8 * INT8 -> FP16 (per tensor):33.9%
Speed Up INT8 * INT8 -> FP16 (per token):-4.06%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.02%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.74%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.76%
==========M=7976==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8394718170166016
TIME INT8 * INT8 -> FP16 (per token): 1.387333869934082
TIME INT8 * INT8 -> FP16 (per channel) 1.3717889785766602
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3852119445800781
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4080524444580078
TIME INT8 * FP16 -> Fp16 (WI bias): 1.167917251586914
TIME Linear: 1.3132095336914062
Speed Up INT8 * INT8 -> FP16 (per tensor):36.07%
Speed Up INT8 * INT8 -> FP16 (per token):-5.64%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.46%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.22%
Speed Up INT8 * FP16 -> Fp16 (WI bias):11.06%
==========M=8008==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8206605911254883
TIME INT8 * INT8 -> FP16 (per token): 1.395416259765625
TIME INT8 * INT8 -> FP16 (per channel) 1.3776779174804688
TIME INT8 * INT8 -> FP16 (per token per channel): 1.3939380645751953
TIME INT8 * FP16 -> Fp16 (WO bias): 1.517939567565918
TIME INT8 * FP16 -> Fp16 (WI bias): 1.2889385223388672
TIME Linear: 1.3254165649414062
Speed Up INT8 * INT8 -> FP16 (per tensor):38.08%
Speed Up INT8 * INT8 -> FP16 (per token):-5.28%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.94%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-5.17%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-14.53%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.75%
==========M=8040==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8587121963500977
TIME INT8 * INT8 -> FP16 (per token): 1.3972997665405273
TIME INT8 * INT8 -> FP16 (per channel) 1.3808727264404297
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4099836349487305
TIME INT8 * FP16 -> Fp16 (WO bias): 1.536703109741211
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3071775436401367
TIME Linear: 1.5275239944458008
Speed Up INT8 * INT8 -> FP16 (per tensor):43.78%
Speed Up INT8 * INT8 -> FP16 (per token):8.53%
Speed Up INT8 * INT8 -> FP16 (per channel):9.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.69%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):14.43%
==========M=8072==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.9057521820068359
TIME INT8 * INT8 -> FP16 (per token): 1.7004013061523438
TIME INT8 * INT8 -> FP16 (per channel) 1.6831636428833008
TIME INT8 * INT8 -> FP16 (per token per channel): 1.702713966369629
TIME INT8 * FP16 -> Fp16 (WO bias): 1.650691032409668
TIME INT8 * FP16 -> Fp16 (WI bias): 1.3404369354248047
TIME Linear: 1.3201713562011719
Speed Up INT8 * INT8 -> FP16 (per tensor):31.39%
Speed Up INT8 * INT8 -> FP16 (per token):-28.8%
Speed Up INT8 * INT8 -> FP16 (per channel):-27.5%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-28.98%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.04%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.54%
==========M=8104==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8366823196411133
TIME INT8 * INT8 -> FP16 (per token): 1.4442920684814453
TIME INT8 * INT8 -> FP16 (per channel) 1.4339685440063477
TIME INT8 * INT8 -> FP16 (per token per channel): 1.449751853942871
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4099597930908203
TIME INT8 * FP16 -> Fp16 (WI bias): 1.178288459777832
TIME Linear: 1.3205289840698242
Speed Up INT8 * INT8 -> FP16 (per tensor):36.64%
Speed Up INT8 * INT8 -> FP16 (per token):-9.37%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.79%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.77%
Speed Up INT8 * FP16 -> Fp16 (WI bias):10.77%
==========M=8136==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8358240127563477
TIME INT8 * INT8 -> FP16 (per token): 1.4523983001708984
TIME INT8 * INT8 -> FP16 (per channel) 1.4406919479370117
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4483928680419922
TIME INT8 * FP16 -> Fp16 (WO bias): 1.4017581939697266
TIME INT8 * FP16 -> Fp16 (WI bias): 1.1657476425170898
TIME Linear: 1.3247013092041016
Speed Up INT8 * INT8 -> FP16 (per tensor):36.9%
Speed Up INT8 * INT8 -> FP16 (per token):-9.64%
Speed Up INT8 * INT8 -> FP16 (per channel):-8.76%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-9.34%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.82%
Speed Up INT8 * FP16 -> Fp16 (WI bias):12.0%
==========M=8168==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.8105039596557617
TIME INT8 * INT8 -> FP16 (per token): 1.4561891555786133
TIME INT8 * INT8 -> FP16 (per channel) 1.4471054077148438
TIME INT8 * INT8 -> FP16 (per token per channel): 1.4571666717529297
TIME INT8 * FP16 -> Fp16 (WO bias): 1.3914823532104492
TIME INT8 * FP16 -> Fp16 (WI bias): 1.123189926147461
TIME Linear: 1.3167142868041992
Speed Up INT8 * INT8 -> FP16 (per tensor):38.44%
Speed Up INT8 * INT8 -> FP16 (per token):-10.59%
Speed Up INT8 * INT8 -> FP16 (per channel):-9.9%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-10.67%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.68%
Speed Up INT8 * FP16 -> Fp16 (WI bias):14.7%
Namespace(m=8192, n=8192, k=2048, num_iters=10)
==========M=504==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.0962972640991211
TIME INT8 * INT8 -> FP16 (per token): 0.13899803161621094
TIME INT8 * INT8 -> FP16 (per channel) 0.1346588134765625
TIME INT8 * INT8 -> FP16 (per token per channel): 0.13599395751953125
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17659664154052734
TIME INT8 * FP16 -> Fp16 (WI bias): 0.15163421630859375
TIME Linear: 0.15192031860351562
Speed Up INT8 * INT8 -> FP16 (per tensor):36.61%
Speed Up INT8 * INT8 -> FP16 (per token):8.51%
Speed Up INT8 * INT8 -> FP16 (per channel):11.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-16.24%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.19%
