Namespace(m=8192, n=6144, k=8192, num_iters=10)
==========M=8==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.07712841033935547
TIME INT8 * INT8 -> FP16 (per token): 0.08857250213623047
TIME INT8 * INT8 -> FP16 (per channel) 0.08594989776611328
TIME INT8 * INT8 -> FP16 (per token per channel): 0.08149147033691406
TIME INT8 * FP16 -> Fp16 (WO bias): 0.07200241088867188
TIME INT8 * FP16 -> Fp16 (WI bias): 0.06504058837890625
TIME Linear: 0.11892318725585938
Speed Up INT8 * INT8 -> FP16 (per tensor):35.14%
Speed Up INT8 * INT8 -> FP16 (per token):25.52%
Speed Up INT8 * INT8 -> FP16 (per channel):27.73%
Speed Up INT8 * INT8 -> FP16 (per token per channel):31.48%
Speed Up INT8 * FP16 -> Fp16 (WO bias):39.45%
Speed Up INT8 * FP16 -> Fp16 (WI bias):45.31%
==========M=40==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.07450580596923828
TIME INT8 * INT8 -> FP16 (per token): 0.08873939514160156
TIME INT8 * INT8 -> FP16 (per channel) 0.08118152618408203
TIME INT8 * INT8 -> FP16 (per token per channel): 0.0826120376586914
TIME INT8 * FP16 -> Fp16 (WO bias): 0.08158683776855469
TIME INT8 * FP16 -> Fp16 (WI bias): 0.06978511810302734
TIME Linear: 0.10912418365478516
Speed Up INT8 * INT8 -> FP16 (per tensor):31.72%
Speed Up INT8 * INT8 -> FP16 (per token):18.68%
Speed Up INT8 * INT8 -> FP16 (per channel):25.61%
Speed Up INT8 * INT8 -> FP16 (per token per channel):24.3%
Speed Up INT8 * FP16 -> Fp16 (WO bias):25.23%
Speed Up INT8 * FP16 -> Fp16 (WI bias):36.05%
==========M=72==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.07634162902832031
TIME INT8 * INT8 -> FP16 (per token): 0.10743141174316406
TIME INT8 * INT8 -> FP16 (per channel) 0.10159015655517578
TIME INT8 * INT8 -> FP16 (per token per channel): 0.10209083557128906
TIME INT8 * FP16 -> Fp16 (WO bias): 0.11243820190429688
TIME INT8 * FP16 -> Fp16 (WI bias): 0.10552406311035156
TIME Linear: 0.12776851654052734
Speed Up INT8 * INT8 -> FP16 (per tensor):40.25%
Speed Up INT8 * INT8 -> FP16 (per token):15.92%
Speed Up INT8 * INT8 -> FP16 (per channel):20.49%
Speed Up INT8 * INT8 -> FP16 (per token per channel):20.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):12.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):17.41%
==========M=104==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.07598400115966797
TIME INT8 * INT8 -> FP16 (per token): 0.11148452758789062
TIME INT8 * INT8 -> FP16 (per channel) 0.10988712310791016
TIME INT8 * INT8 -> FP16 (per token per channel): 0.10945796966552734
TIME INT8 * FP16 -> Fp16 (WO bias): 0.11510848999023438
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1071929931640625
TIME Linear: 0.13434886932373047
Speed Up INT8 * INT8 -> FP16 (per tensor):43.44%
Speed Up INT8 * INT8 -> FP16 (per token):17.02%
Speed Up INT8 * INT8 -> FP16 (per channel):18.21%
Speed Up INT8 * INT8 -> FP16 (per token per channel):18.53%
Speed Up INT8 * FP16 -> Fp16 (WO bias):14.32%
Speed Up INT8 * FP16 -> Fp16 (WI bias):20.21%
==========M=136==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12826919555664062
TIME INT8 * INT8 -> FP16 (per token): 0.13952255249023438
TIME INT8 * INT8 -> FP16 (per channel) 0.13818740844726562
TIME INT8 * INT8 -> FP16 (per token per channel): 0.13926029205322266
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17578601837158203
TIME INT8 * FP16 -> Fp16 (WI bias): 0.16891956329345703
TIME Linear: 0.167083740234375
Speed Up INT8 * INT8 -> FP16 (per tensor):23.23%
Speed Up INT8 * INT8 -> FP16 (per token):16.5%
Speed Up INT8 * INT8 -> FP16 (per channel):17.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):16.65%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.21%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.1%
==========M=168==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.10716915130615234
TIME INT8 * INT8 -> FP16 (per token): 0.1425027847290039
TIME INT8 * INT8 -> FP16 (per channel) 0.14035701751708984
TIME INT8 * INT8 -> FP16 (per token per channel): 0.14066696166992188
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17600059509277344
TIME INT8 * FP16 -> Fp16 (WI bias): 0.16770362854003906
TIME Linear: 0.16922950744628906
Speed Up INT8 * INT8 -> FP16 (per tensor):36.67%
Speed Up INT8 * INT8 -> FP16 (per token):15.79%
Speed Up INT8 * INT8 -> FP16 (per channel):17.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):16.88%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.9%
==========M=200==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1291036605834961
TIME INT8 * INT8 -> FP16 (per token): 0.17240047454833984
TIME INT8 * INT8 -> FP16 (per channel) 0.1701831817626953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.17001628875732422
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17650127410888672
TIME INT8 * FP16 -> Fp16 (WI bias): 0.16634464263916016
TIME Linear: 0.1714944839477539
Speed Up INT8 * INT8 -> FP16 (per tensor):24.72%
Speed Up INT8 * INT8 -> FP16 (per token):-0.53%
Speed Up INT8 * INT8 -> FP16 (per channel):0.76%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.86%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-2.92%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.0%
==========M=232==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.12960433959960938
TIME INT8 * INT8 -> FP16 (per token): 0.17499923706054688
TIME INT8 * INT8 -> FP16 (per channel) 0.1732349395751953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1742839813232422
TIME INT8 * FP16 -> Fp16 (WO bias): 0.17735958099365234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.16620159149169922
TIME Linear: 0.17001628875732422
Speed Up INT8 * INT8 -> FP16 (per tensor):23.77%
Speed Up INT8 * INT8 -> FP16 (per token):-2.93%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.51%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-4.32%
Speed Up INT8 * FP16 -> Fp16 (WI bias):2.24%
==========M=264==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18112659454345703
TIME INT8 * INT8 -> FP16 (per token): 0.1773357391357422
TIME INT8 * INT8 -> FP16 (per channel) 0.17478466033935547
TIME INT8 * INT8 -> FP16 (per token per channel): 0.1745462417602539
TIME INT8 * FP16 -> Fp16 (WO bias): 0.2119302749633789
TIME INT8 * FP16 -> Fp16 (WI bias): 0.1997232437133789
TIME Linear: 0.25665760040283203
Speed Up INT8 * INT8 -> FP16 (per tensor):29.43%
Speed Up INT8 * INT8 -> FP16 (per token):30.91%
Speed Up INT8 * INT8 -> FP16 (per channel):31.9%
Speed Up INT8 * INT8 -> FP16 (per token per channel):31.99%
Speed Up INT8 * FP16 -> Fp16 (WO bias):17.43%
Speed Up INT8 * FP16 -> Fp16 (WI bias):22.18%
==========M=296==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18157958984375
TIME INT8 * INT8 -> FP16 (per token): 0.20918846130371094
TIME INT8 * INT8 -> FP16 (per channel) 0.20673274993896484
TIME INT8 * INT8 -> FP16 (per token per channel): 0.2073049545288086
TIME INT8 * FP16 -> Fp16 (WO bias): 0.20449161529541016
TIME INT8 * FP16 -> Fp16 (WI bias): 0.19059181213378906
TIME Linear: 0.23550987243652344
Speed Up INT8 * INT8 -> FP16 (per tensor):22.9%
Speed Up INT8 * INT8 -> FP16 (per token):11.18%
Speed Up INT8 * INT8 -> FP16 (per channel):12.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.98%
Speed Up INT8 * FP16 -> Fp16 (WO bias):13.17%
Speed Up INT8 * FP16 -> Fp16 (WI bias):19.07%
==========M=328==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.1834392547607422
TIME INT8 * INT8 -> FP16 (per token): 0.21185874938964844
TIME INT8 * INT8 -> FP16 (per channel) 0.2118825912475586
TIME INT8 * INT8 -> FP16 (per token per channel): 0.21071434020996094
TIME INT8 * FP16 -> Fp16 (WO bias): 0.24425983428955078
TIME INT8 * FP16 -> Fp16 (WI bias): 0.22993087768554688
TIME Linear: 0.23219585418701172
Speed Up INT8 * INT8 -> FP16 (per tensor):21.0%
Speed Up INT8 * INT8 -> FP16 (per token):8.76%
Speed Up INT8 * INT8 -> FP16 (per channel):8.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.25%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.2%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.98%
==========M=360==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.18324851989746094
TIME INT8 * INT8 -> FP16 (per token): 0.23407936096191406
TIME INT8 * INT8 -> FP16 (per channel) 0.23338794708251953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.23431777954101562
TIME INT8 * FP16 -> Fp16 (WO bias): 0.2467632293701172
TIME INT8 * FP16 -> Fp16 (WI bias): 0.23131370544433594
TIME Linear: 0.2328634262084961
Speed Up INT8 * INT8 -> FP16 (per tensor):21.31%
Speed Up INT8 * INT8 -> FP16 (per token):-0.52%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.23%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.62%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.97%
Speed Up INT8 * FP16 -> Fp16 (WI bias):0.67%
==========M=392==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.19099712371826172
TIME INT8 * INT8 -> FP16 (per token): 0.24487972259521484
TIME INT8 * INT8 -> FP16 (per channel) 0.2427816390991211
TIME INT8 * INT8 -> FP16 (per token per channel): 0.24311542510986328
TIME INT8 * FP16 -> Fp16 (WO bias): 0.30994415283203125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.29599666595458984
TIME Linear: 0.28634071350097656
Speed Up INT8 * INT8 -> FP16 (per tensor):33.3%
Speed Up INT8 * INT8 -> FP16 (per token):14.48%
Speed Up INT8 * INT8 -> FP16 (per channel):15.21%
Speed Up INT8 * INT8 -> FP16 (per token per channel):15.1%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.24%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-3.37%
==========M=424==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.19168853759765625
TIME INT8 * INT8 -> FP16 (per token): 0.26900768280029297
TIME INT8 * INT8 -> FP16 (per channel) 0.2684593200683594
TIME INT8 * INT8 -> FP16 (per token per channel): 0.26628971099853516
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3108978271484375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.29418468475341797
TIME Linear: 0.28738975524902344
Speed Up INT8 * INT8 -> FP16 (per tensor):33.3%
Speed Up INT8 * INT8 -> FP16 (per token):6.4%
Speed Up INT8 * INT8 -> FP16 (per channel):6.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.34%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.18%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.36%
==========M=456==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2026081085205078
TIME INT8 * INT8 -> FP16 (per token): 0.2783536911010742
TIME INT8 * INT8 -> FP16 (per channel) 0.2753019332885742
TIME INT8 * INT8 -> FP16 (per token per channel): 0.27747154235839844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3115415573120117
TIME INT8 * FP16 -> Fp16 (WI bias): 0.29506683349609375
TIME Linear: 0.2891063690185547
Speed Up INT8 * INT8 -> FP16 (per tensor):29.92%
Speed Up INT8 * INT8 -> FP16 (per token):3.72%
Speed Up INT8 * INT8 -> FP16 (per channel):4.77%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.02%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.76%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.06%
==========M=488==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.19633769989013672
TIME INT8 * INT8 -> FP16 (per token): 0.3012418746948242
TIME INT8 * INT8 -> FP16 (per channel) 0.29647350311279297
TIME INT8 * INT8 -> FP16 (per token per channel): 0.29931068420410156
TIME INT8 * FP16 -> Fp16 (WO bias): 0.31321048736572266
TIME INT8 * FP16 -> Fp16 (WI bias): 0.29604434967041016
TIME Linear: 0.2876758575439453
Speed Up INT8 * INT8 -> FP16 (per tensor):31.75%
Speed Up INT8 * INT8 -> FP16 (per token):-4.72%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.06%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.04%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-8.88%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-2.91%
==========M=520==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.23081302642822266
TIME INT8 * INT8 -> FP16 (per token): 0.30913352966308594
TIME INT8 * INT8 -> FP16 (per channel) 0.3085613250732422
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3075122833251953
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3181934356689453
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3049612045288086
TIME Linear: 0.3985881805419922
Speed Up INT8 * INT8 -> FP16 (per tensor):42.09%
Speed Up INT8 * INT8 -> FP16 (per token):22.44%
Speed Up INT8 * INT8 -> FP16 (per channel):22.59%
Speed Up INT8 * INT8 -> FP16 (per token per channel):22.85%
Speed Up INT8 * FP16 -> Fp16 (WO bias):20.17%
Speed Up INT8 * FP16 -> Fp16 (WI bias):23.49%
==========M=552==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.19505023956298828
TIME INT8 * INT8 -> FP16 (per token): 0.318145751953125
TIME INT8 * INT8 -> FP16 (per channel) 0.3155708312988281
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3175020217895508
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3184318542480469
TIME INT8 * FP16 -> Fp16 (WI bias): 0.30548572540283203
TIME Linear: 0.4015684127807617
Speed Up INT8 * INT8 -> FP16 (per tensor):51.43%
Speed Up INT8 * INT8 -> FP16 (per token):20.77%
Speed Up INT8 * INT8 -> FP16 (per channel):21.42%
Speed Up INT8 * INT8 -> FP16 (per token per channel):20.93%
Speed Up INT8 * FP16 -> Fp16 (WO bias):20.7%
Speed Up INT8 * FP16 -> Fp16 (WI bias):23.93%
==========M=584==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2572298049926758
TIME INT8 * INT8 -> FP16 (per token): 0.33872127532958984
TIME INT8 * INT8 -> FP16 (per channel) 0.3397703170776367
TIME INT8 * INT8 -> FP16 (per token per channel): 0.33605098724365234
TIME INT8 * FP16 -> Fp16 (WO bias): 0.3636598587036133
TIME INT8 * FP16 -> Fp16 (WI bias): 0.34236907958984375
TIME Linear: 0.4015684127807617
Speed Up INT8 * INT8 -> FP16 (per tensor):35.94%
Speed Up INT8 * INT8 -> FP16 (per token):15.65%
Speed Up INT8 * INT8 -> FP16 (per channel):15.39%
Speed Up INT8 * INT8 -> FP16 (per token per channel):16.32%
Speed Up INT8 * FP16 -> Fp16 (WO bias):9.44%
Speed Up INT8 * FP16 -> Fp16 (WI bias):14.74%
==========M=616==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2369403839111328
TIME INT8 * INT8 -> FP16 (per token): 0.3485679626464844
TIME INT8 * INT8 -> FP16 (per channel) 0.5081415176391602
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3481149673461914
TIME INT8 * FP16 -> Fp16 (WO bias): 0.36509037017822266
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3428459167480469
TIME Linear: 0.40781497955322266
Speed Up INT8 * INT8 -> FP16 (per tensor):41.9%
Speed Up INT8 * INT8 -> FP16 (per token):14.53%
Speed Up INT8 * INT8 -> FP16 (per channel):-24.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):14.64%
Speed Up INT8 * FP16 -> Fp16 (WO bias):10.48%
Speed Up INT8 * FP16 -> Fp16 (WI bias):15.93%
==========M=648==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2698183059692383
TIME INT8 * INT8 -> FP16 (per token): 0.3689765930175781
TIME INT8 * INT8 -> FP16 (per channel) 0.3700733184814453
TIME INT8 * INT8 -> FP16 (per token per channel): 0.36842823028564453
TIME INT8 * FP16 -> Fp16 (WO bias): 0.40802955627441406
TIME INT8 * FP16 -> Fp16 (WI bias): 0.386810302734375
TIME Linear: 0.4068136215209961
Speed Up INT8 * INT8 -> FP16 (per tensor):33.68%
Speed Up INT8 * INT8 -> FP16 (per token):9.3%
Speed Up INT8 * INT8 -> FP16 (per channel):9.03%
Speed Up INT8 * INT8 -> FP16 (per token per channel):9.44%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.92%
==========M=680==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2718210220336914
TIME INT8 * INT8 -> FP16 (per token): 0.3800392150878906
TIME INT8 * INT8 -> FP16 (per channel) 0.3771781921386719
TIME INT8 * INT8 -> FP16 (per token per channel): 0.3787040710449219
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4088401794433594
TIME INT8 * FP16 -> Fp16 (WI bias): 0.3887653350830078
TIME Linear: 0.40733814239501953
Speed Up INT8 * INT8 -> FP16 (per tensor):33.27%
Speed Up INT8 * INT8 -> FP16 (per token):6.7%
Speed Up INT8 * INT8 -> FP16 (per channel):7.4%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.03%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.37%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.56%
==========M=712==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2762317657470703
TIME INT8 * INT8 -> FP16 (per token): 0.4071950912475586
TIME INT8 * INT8 -> FP16 (per channel) 0.4037618637084961
TIME INT8 * INT8 -> FP16 (per token per channel): 0.40400028228759766
TIME INT8 * FP16 -> Fp16 (WO bias): 0.45452117919921875
TIME INT8 * FP16 -> Fp16 (WI bias): 0.43103694915771484
TIME Linear: 0.4072904586791992
Speed Up INT8 * INT8 -> FP16 (per tensor):32.18%
Speed Up INT8 * INT8 -> FP16 (per token):0.02%
Speed Up INT8 * INT8 -> FP16 (per channel):0.87%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-5.83%
==========M=744==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2751350402832031
TIME INT8 * INT8 -> FP16 (per token): 0.42548179626464844
TIME INT8 * INT8 -> FP16 (per channel) 0.42171478271484375
TIME INT8 * INT8 -> FP16 (per token per channel): 0.42197704315185547
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4587411880493164
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4317045211791992
TIME Linear: 0.4122734069824219
Speed Up INT8 * INT8 -> FP16 (per tensor):33.26%
Speed Up INT8 * INT8 -> FP16 (per token):-3.2%
Speed Up INT8 * INT8 -> FP16 (per channel):-2.29%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-2.35%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-11.27%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-4.71%
==========M=776==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.27604103088378906
TIME INT8 * INT8 -> FP16 (per token): 0.43790340423583984
TIME INT8 * INT8 -> FP16 (per channel) 0.4361391067504883
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4376411437988281
TIME INT8 * FP16 -> Fp16 (WO bias): 0.45990943908691406
TIME INT8 * FP16 -> Fp16 (WI bias): 0.43327808380126953
TIME Linear: 0.5167722702026367
Speed Up INT8 * INT8 -> FP16 (per tensor):46.58%
Speed Up INT8 * INT8 -> FP16 (per token):15.26%
Speed Up INT8 * INT8 -> FP16 (per channel):15.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):15.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):11.0%
Speed Up INT8 * FP16 -> Fp16 (WI bias):16.16%
==========M=808==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.2803325653076172
TIME INT8 * INT8 -> FP16 (per token): 0.45354366302490234
TIME INT8 * INT8 -> FP16 (per channel) 0.45058727264404297
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4525184631347656
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4590749740600586
TIME INT8 * FP16 -> Fp16 (WI bias): 0.4328727722167969
TIME Linear: 0.5295991897583008
Speed Up INT8 * INT8 -> FP16 (per tensor):47.07%
Speed Up INT8 * INT8 -> FP16 (per token):14.36%
Speed Up INT8 * INT8 -> FP16 (per channel):14.92%
Speed Up INT8 * INT8 -> FP16 (per token per channel):14.55%
Speed Up INT8 * FP16 -> Fp16 (WO bias):13.32%
Speed Up INT8 * FP16 -> Fp16 (WI bias):18.26%
==========M=840==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.30481815338134766
TIME INT8 * INT8 -> FP16 (per token): 0.48274993896484375
TIME INT8 * INT8 -> FP16 (per channel) 0.4808664321899414
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4786968231201172
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6000041961669922
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5705356597900391
TIME Linear: 0.4854440689086914
Speed Up INT8 * INT8 -> FP16 (per tensor):37.21%
Speed Up INT8 * INT8 -> FP16 (per token):0.55%
Speed Up INT8 * INT8 -> FP16 (per channel):0.94%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.39%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-23.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-17.53%
==========M=872==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.30639171600341797
TIME INT8 * INT8 -> FP16 (per token): 0.4892110824584961
TIME INT8 * INT8 -> FP16 (per channel) 0.4868030548095703
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4857063293457031
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5892276763916016
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5576133728027344
TIME Linear: 0.49326419830322266
Speed Up INT8 * INT8 -> FP16 (per tensor):37.88%
Speed Up INT8 * INT8 -> FP16 (per token):0.82%
Speed Up INT8 * INT8 -> FP16 (per channel):1.31%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.53%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-19.45%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-13.05%
==========M=904==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.31006336212158203
TIME INT8 * INT8 -> FP16 (per token): 0.49986839294433594
TIME INT8 * INT8 -> FP16 (per channel) 0.5002975463867188
TIME INT8 * INT8 -> FP16 (per token per channel): 0.4987955093383789
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5398750305175781
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5084514617919922
TIME Linear: 0.5425930023193359
Speed Up INT8 * INT8 -> FP16 (per tensor):42.86%
Speed Up INT8 * INT8 -> FP16 (per token):7.87%
Speed Up INT8 * INT8 -> FP16 (per channel):7.8%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.07%
Speed Up INT8 * FP16 -> Fp16 (WO bias):0.5%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.29%
==========M=936==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.31151771545410156
TIME INT8 * INT8 -> FP16 (per token): 0.5155086517333984
TIME INT8 * INT8 -> FP16 (per channel) 0.5141496658325195
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5153656005859375
TIME INT8 * FP16 -> Fp16 (WO bias): 0.5425930023193359
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5108118057250977
TIME Linear: 0.5458593368530273
Speed Up INT8 * INT8 -> FP16 (per tensor):42.93%
Speed Up INT8 * INT8 -> FP16 (per token):5.56%
Speed Up INT8 * INT8 -> FP16 (per channel):5.81%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.59%
Speed Up INT8 * FP16 -> Fp16 (WO bias):0.6%
Speed Up INT8 * FP16 -> Fp16 (WI bias):6.42%
==========M=968==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.34873485565185547
TIME INT8 * INT8 -> FP16 (per token): 0.5326032638549805
TIME INT8 * INT8 -> FP16 (per channel) 0.5324840545654297
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5314350128173828
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6906270980834961
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6598234176635742
TIME Linear: 0.549626350402832
Speed Up INT8 * INT8 -> FP16 (per tensor):36.55%
Speed Up INT8 * INT8 -> FP16 (per token):3.1%
Speed Up INT8 * INT8 -> FP16 (per channel):3.12%
Speed Up INT8 * INT8 -> FP16 (per token per channel):3.31%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-25.65%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-20.05%
==========M=1000==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3558635711669922
TIME INT8 * INT8 -> FP16 (per token): 0.5525827407836914
TIME INT8 * INT8 -> FP16 (per channel) 0.5496740341186523
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5501747131347656
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7461071014404297
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7133722305297852
TIME Linear: 0.5463838577270508
Speed Up INT8 * INT8 -> FP16 (per tensor):34.87%
Speed Up INT8 * INT8 -> FP16 (per token):-1.13%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.6%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.69%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-36.55%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-30.56%
==========M=1032==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3561258316040039
TIME INT8 * INT8 -> FP16 (per token): 0.5737543106079102
TIME INT8 * INT8 -> FP16 (per channel) 0.5675315856933594
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5676031112670898
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6283044815063477
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5972385406494141
TIME Linear: 0.5864143371582031
Speed Up INT8 * INT8 -> FP16 (per tensor):39.27%
Speed Up INT8 * INT8 -> FP16 (per token):2.16%
Speed Up INT8 * INT8 -> FP16 (per channel):3.22%
Speed Up INT8 * INT8 -> FP16 (per token per channel):3.21%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-7.14%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.85%
==========M=1064==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.5383014678955078
TIME INT8 * INT8 -> FP16 (per token): 0.5837202072143555
TIME INT8 * INT8 -> FP16 (per channel) 0.580906867980957
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5810737609863281
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6273269653320312
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5975246429443359
TIME Linear: 0.5895137786865234
Speed Up INT8 * INT8 -> FP16 (per tensor):8.69%
Speed Up INT8 * INT8 -> FP16 (per token):0.98%
Speed Up INT8 * INT8 -> FP16 (per channel):1.46%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.43%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.41%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-1.36%
==========M=1096==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.36177635192871094
TIME INT8 * INT8 -> FP16 (per token): 0.5986690521240234
TIME INT8 * INT8 -> FP16 (per channel) 0.5956172943115234
TIME INT8 * INT8 -> FP16 (per token per channel): 0.5968332290649414
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6291866302490234
TIME INT8 * FP16 -> Fp16 (WI bias): 0.595855712890625
TIME Linear: 0.594019889831543
Speed Up INT8 * INT8 -> FP16 (per tensor):39.1%
Speed Up INT8 * INT8 -> FP16 (per token):-0.78%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.27%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-0.47%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-5.92%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.31%
==========M=1128==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.3659248352050781
TIME INT8 * INT8 -> FP16 (per token): 0.6255626678466797
TIME INT8 * INT8 -> FP16 (per channel) 0.6231307983398438
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6226062774658203
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6323337554931641
TIME INT8 * FP16 -> Fp16 (WI bias): 0.5985260009765625
TIME Linear: 0.5948543548583984
Speed Up INT8 * INT8 -> FP16 (per tensor):38.48%
Speed Up INT8 * INT8 -> FP16 (per token):-5.16%
Speed Up INT8 * INT8 -> FP16 (per channel):-4.75%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-4.67%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-6.3%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-0.62%
==========M=1160==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4052162170410156
TIME INT8 * INT8 -> FP16 (per token): 0.6166934967041016
TIME INT8 * INT8 -> FP16 (per channel) 0.6155014038085938
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6164312362670898
TIME INT8 * FP16 -> Fp16 (WO bias): 0.780177116394043
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7397174835205078
TIME Linear: 0.6943941116333008
Speed Up INT8 * INT8 -> FP16 (per tensor):41.64%
Speed Up INT8 * INT8 -> FP16 (per token):11.19%
Speed Up INT8 * INT8 -> FP16 (per channel):11.36%
Speed Up INT8 * INT8 -> FP16 (per token per channel):11.23%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-12.35%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.53%
==========M=1192==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.39615631103515625
TIME INT8 * INT8 -> FP16 (per token): 0.6384849548339844
TIME INT8 * INT8 -> FP16 (per channel) 0.6356000900268555
TIME INT8 * INT8 -> FP16 (per token per channel): 0.637054443359375
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7795333862304688
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7401227951049805
TIME Linear: 0.6918191909790039
Speed Up INT8 * INT8 -> FP16 (per tensor):42.74%
Speed Up INT8 * INT8 -> FP16 (per token):7.71%
Speed Up INT8 * INT8 -> FP16 (per channel):8.13%
Speed Up INT8 * INT8 -> FP16 (per token per channel):7.92%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-12.68%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-6.98%
==========M=1224==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.42145252227783203
TIME INT8 * INT8 -> FP16 (per token): 0.6457090377807617
TIME INT8 * INT8 -> FP16 (per channel) 0.6441831588745117
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6433486938476562
TIME INT8 * FP16 -> Fp16 (WO bias): 0.673365592956543
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6349325180053711
TIME Linear: 0.7025241851806641
Speed Up INT8 * INT8 -> FP16 (per tensor):40.01%
Speed Up INT8 * INT8 -> FP16 (per token):8.09%
Speed Up INT8 * INT8 -> FP16 (per channel):8.3%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.42%
Speed Up INT8 * FP16 -> Fp16 (WO bias):4.15%
Speed Up INT8 * FP16 -> Fp16 (WI bias):9.62%
==========M=1256==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.42617321014404297
TIME INT8 * INT8 -> FP16 (per token): 0.6708621978759766
TIME INT8 * INT8 -> FP16 (per channel) 0.6649494171142578
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6659507751464844
TIME INT8 * FP16 -> Fp16 (WO bias): 0.6751775741577148
TIME INT8 * FP16 -> Fp16 (WI bias): 0.6349563598632812
TIME Linear: 0.6957530975341797
Speed Up INT8 * INT8 -> FP16 (per tensor):38.75%
Speed Up INT8 * INT8 -> FP16 (per token):3.58%
Speed Up INT8 * INT8 -> FP16 (per channel):4.43%
Speed Up INT8 * INT8 -> FP16 (per token per channel):4.28%
Speed Up INT8 * FP16 -> Fp16 (WO bias):2.96%
Speed Up INT8 * FP16 -> Fp16 (WI bias):8.74%
==========M=1288==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4060029983520508
TIME INT8 * INT8 -> FP16 (per token): 0.6811141967773438
TIME INT8 * INT8 -> FP16 (per channel) 0.6798267364501953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.680088996887207
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7735013961791992
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7359743118286133
TIME Linear: 0.7628440856933594
Speed Up INT8 * INT8 -> FP16 (per tensor):46.78%
Speed Up INT8 * INT8 -> FP16 (per token):10.71%
Speed Up INT8 * INT8 -> FP16 (per channel):10.88%
Speed Up INT8 * INT8 -> FP16 (per token per channel):10.85%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.4%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.52%
==========M=1320==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4029273986816406
TIME INT8 * INT8 -> FP16 (per token): 0.7014989852905273
TIME INT8 * INT8 -> FP16 (per channel) 0.7004976272583008
TIME INT8 * INT8 -> FP16 (per token per channel): 0.6994009017944336
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7745981216430664
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7360696792602539
TIME Linear: 0.7615327835083008
Speed Up INT8 * INT8 -> FP16 (per tensor):47.09%
Speed Up INT8 * INT8 -> FP16 (per token):7.88%
Speed Up INT8 * INT8 -> FP16 (per channel):8.01%
Speed Up INT8 * INT8 -> FP16 (per token per channel):8.16%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.72%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.34%
==========M=1352==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.40290355682373047
TIME INT8 * INT8 -> FP16 (per token): 0.7140636444091797
TIME INT8 * INT8 -> FP16 (per channel) 0.7112741470336914
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7155656814575195
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7754802703857422
TIME INT8 * FP16 -> Fp16 (WI bias): 0.735926628112793
TIME Linear: 0.7632255554199219
Speed Up INT8 * INT8 -> FP16 (per tensor):47.21%
Speed Up INT8 * INT8 -> FP16 (per token):6.44%
Speed Up INT8 * INT8 -> FP16 (per channel):6.81%
Speed Up INT8 * INT8 -> FP16 (per token per channel):6.24%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.61%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.58%
==========M=1384==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.40335655212402344
TIME INT8 * INT8 -> FP16 (per token): 0.7273197174072266
TIME INT8 * INT8 -> FP16 (per channel) 0.7261037826538086
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7247447967529297
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7771730422973633
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7367610931396484
TIME Linear: 0.7706880569458008
Speed Up INT8 * INT8 -> FP16 (per tensor):47.66%
Speed Up INT8 * INT8 -> FP16 (per token):5.63%
Speed Up INT8 * INT8 -> FP16 (per channel):5.78%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.96%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.84%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.4%
==========M=1416==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46303272247314453
TIME INT8 * INT8 -> FP16 (per token): 0.7735729217529297
TIME INT8 * INT8 -> FP16 (per channel) 0.7657766342163086
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7663488388061523
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9721994400024414
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9261608123779297
TIME Linear: 0.7805109024047852
Speed Up INT8 * INT8 -> FP16 (per tensor):40.68%
Speed Up INT8 * INT8 -> FP16 (per token):0.89%
Speed Up INT8 * INT8 -> FP16 (per channel):1.89%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.81%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-24.56%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-18.66%
==========M=1448==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46036243438720703
TIME INT8 * INT8 -> FP16 (per token): 0.7829427719116211
TIME INT8 * INT8 -> FP16 (per channel) 0.7820844650268555
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7803916931152344
TIME INT8 * FP16 -> Fp16 (WO bias): 0.7977485656738281
TIME INT8 * FP16 -> Fp16 (WI bias): 0.7538557052612305
TIME Linear: 0.7849693298339844
Speed Up INT8 * INT8 -> FP16 (per tensor):41.35%
Speed Up INT8 * INT8 -> FP16 (per token):0.26%
Speed Up INT8 * INT8 -> FP16 (per channel):0.37%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.58%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):3.96%
==========M=1480==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4597663879394531
TIME INT8 * INT8 -> FP16 (per token): 0.7988214492797852
TIME INT8 * INT8 -> FP16 (per channel) 0.8008480072021484
TIME INT8 * INT8 -> FP16 (per token per channel): 0.7988929748535156
TIME INT8 * FP16 -> Fp16 (WO bias): 1.0241508483886719
TIME INT8 * FP16 -> Fp16 (WI bias): 0.9843826293945312
TIME Linear: 0.7900476455688477
Speed Up INT8 * INT8 -> FP16 (per tensor):41.81%
Speed Up INT8 * INT8 -> FP16 (per token):-1.11%
Speed Up INT8 * INT8 -> FP16 (per channel):-1.37%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.12%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-29.63%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-24.6%
==========M=1512==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46470165252685547
TIME INT8 * INT8 -> FP16 (per token): 0.8117198944091797
TIME INT8 * INT8 -> FP16 (per channel) 0.8092403411865234
TIME INT8 * INT8 -> FP16 (per token per channel): 0.811314582824707
TIME INT8 * FP16 -> Fp16 (WO bias): 0.9548187255859375
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8978128433227539
TIME Linear: 0.7848501205444336
Speed Up INT8 * INT8 -> FP16 (per tensor):40.79%
Speed Up INT8 * INT8 -> FP16 (per token):-3.42%
Speed Up INT8 * INT8 -> FP16 (per channel):-3.11%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-3.37%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-21.66%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-14.39%
==========M=1544==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4610776901245117
TIME INT8 * INT8 -> FP16 (per token): 0.8304357528686523
TIME INT8 * INT8 -> FP16 (per channel) 0.8282899856567383
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8273124694824219
TIME INT8 * FP16 -> Fp16 (WO bias): 0.873565673828125
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8246183395385742
TIME Linear: 0.8765220642089844
Speed Up INT8 * INT8 -> FP16 (per tensor):47.4%
Speed Up INT8 * INT8 -> FP16 (per token):5.26%
Speed Up INT8 * INT8 -> FP16 (per channel):5.5%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.61%
Speed Up INT8 * FP16 -> Fp16 (WO bias):0.34%
Speed Up INT8 * FP16 -> Fp16 (WI bias):5.92%
==========M=1576==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4658699035644531
TIME INT8 * INT8 -> FP16 (per token): 0.8504152297973633
TIME INT8 * INT8 -> FP16 (per channel) 0.8457660675048828
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8489370346069336
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8741140365600586
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8220672607421875
TIME Linear: 0.860595703125
Speed Up INT8 * INT8 -> FP16 (per tensor):45.87%
Speed Up INT8 * INT8 -> FP16 (per token):1.18%
Speed Up INT8 * INT8 -> FP16 (per channel):1.72%
Speed Up INT8 * INT8 -> FP16 (per token per channel):1.35%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-1.57%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.48%
==========M=1608==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46269893646240234
TIME INT8 * INT8 -> FP16 (per token): 0.8628606796264648
TIME INT8 * INT8 -> FP16 (per channel) 0.8597612380981445
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8616209030151367
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8716106414794922
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8239507675170898
TIME Linear: 0.8646488189697266
Speed Up INT8 * INT8 -> FP16 (per tensor):46.49%
Speed Up INT8 * INT8 -> FP16 (per token):0.21%
Speed Up INT8 * INT8 -> FP16 (per channel):0.57%
Speed Up INT8 * INT8 -> FP16 (per token per channel):0.35%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.81%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.71%
==========M=1640==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.4628181457519531
TIME INT8 * INT8 -> FP16 (per token): 0.8796453475952148
TIME INT8 * INT8 -> FP16 (per channel) 0.8720636367797852
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8741855621337891
TIME INT8 * FP16 -> Fp16 (WO bias): 0.874018669128418
TIME INT8 * FP16 -> Fp16 (WI bias): 0.823521614074707
TIME Linear: 0.8654117584228516
Speed Up INT8 * INT8 -> FP16 (per tensor):46.52%
Speed Up INT8 * INT8 -> FP16 (per token):-1.64%
Speed Up INT8 * INT8 -> FP16 (per channel):-0.77%
Speed Up INT8 * INT8 -> FP16 (per token per channel):-1.01%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-0.99%
Speed Up INT8 * FP16 -> Fp16 (WI bias):4.84%
==========M=1672==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.46317577362060547
TIME INT8 * INT8 -> FP16 (per token): 0.8965253829956055
TIME INT8 * INT8 -> FP16 (per channel) 0.8927106857299805
TIME INT8 * INT8 -> FP16 (per token per channel): 0.8987665176391602
TIME INT8 * FP16 -> Fp16 (WO bias): 0.8894443511962891
TIME INT8 * FP16 -> Fp16 (WI bias): 0.8544921875
TIME Linear: 0.9588241577148438
Speed Up INT8 * INT8 -> FP16 (per tensor):51.69%
Speed Up INT8 * INT8 -> FP16 (per token):6.5%
Speed Up INT8 * INT8 -> FP16 (per channel):6.9%
Speed Up INT8 * INT8 -> FP16 (per token per channel):6.26%
Speed Up INT8 * FP16 -> Fp16 (WO bias):7.24%
Speed Up INT8 * FP16 -> Fp16 (WI bias):10.88%
Namespace(m=8192, n=8192, k=6144, num_iters=10)
==========M=504==========
TIME INT8 * INT8 -> FP16 (per tensor): 0.21638870239257812
TIME INT8 * INT8 -> FP16 (per token): 0.29921531677246094
TIME INT8 * INT8 -> FP16 (per channel) 0.29442310333251953
TIME INT8 * INT8 -> FP16 (per token per channel): 0.29625892639160156
TIME INT8 * FP16 -> Fp16 (WO bias): 0.4091501235961914
TIME INT8 * FP16 -> Fp16 (WI bias): 0.38259029388427734
TIME Linear: 0.3125190734863281
Speed Up INT8 * INT8 -> FP16 (per tensor):30.76%
Speed Up INT8 * INT8 -> FP16 (per token):4.26%
Speed Up INT8 * INT8 -> FP16 (per channel):5.79%
Speed Up INT8 * INT8 -> FP16 (per token per channel):5.2%
Speed Up INT8 * FP16 -> Fp16 (WO bias):-30.92%
Speed Up INT8 * FP16 -> Fp16 (WI bias):-22.42%
